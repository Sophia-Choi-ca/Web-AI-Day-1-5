{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 20~22 딥러닝 #2 CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOwlFDLIZ+qAO43m30mQBRs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futurebly/Web-AI/blob/main/Day20~22_%EB%94%A5%EB%9F%AC%EB%8B%9D_2_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLGSNIGTDxds"
      },
      "source": [
        "# 딥러닝 #2 CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq1dXmC3Fyc1"
      },
      "source": [
        "## 사용할 이미지 구경\n",
        "- MNIST\n",
        "- CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE5HirRuDrII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c6829e-de63-450f-9b96-181a0bcab60a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n",
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bP5T8HzEgs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0388199c-9a31-4feb-f63c-daac4c9e2653"
      },
      "source": [
        "help(tf.keras.datasets.mnist.load_data())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on tuple object:\n",
            "\n",
            "class tuple(object)\n",
            " |  tuple(iterable=(), /)\n",
            " |  \n",
            " |  Built-in immutable sequence.\n",
            " |  \n",
            " |  If no argument is given, the constructor returns an empty tuple.\n",
            " |  If iterable is specified the tuple is initialized from iterable's items.\n",
            " |  \n",
            " |  If the argument is a tuple, the return value is the same object.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __add__(self, value, /)\n",
            " |      Return self+value.\n",
            " |  \n",
            " |  __contains__(self, key, /)\n",
            " |      Return key in self.\n",
            " |  \n",
            " |  __eq__(self, value, /)\n",
            " |      Return self==value.\n",
            " |  \n",
            " |  __ge__(self, value, /)\n",
            " |      Return self>=value.\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __getitem__(self, key, /)\n",
            " |      Return self[key].\n",
            " |  \n",
            " |  __getnewargs__(self, /)\n",
            " |  \n",
            " |  __gt__(self, value, /)\n",
            " |      Return self>value.\n",
            " |  \n",
            " |  __hash__(self, /)\n",
            " |      Return hash(self).\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __le__(self, value, /)\n",
            " |      Return self<=value.\n",
            " |  \n",
            " |  __len__(self, /)\n",
            " |      Return len(self).\n",
            " |  \n",
            " |  __lt__(self, value, /)\n",
            " |      Return self<value.\n",
            " |  \n",
            " |  __mul__(self, value, /)\n",
            " |      Return self*value.\n",
            " |  \n",
            " |  __ne__(self, value, /)\n",
            " |      Return self!=value.\n",
            " |  \n",
            " |  __repr__(self, /)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __rmul__(self, value, /)\n",
            " |      Return value*self.\n",
            " |  \n",
            " |  count(self, value, /)\n",
            " |      Return number of occurrences of value.\n",
            " |  \n",
            " |  index(self, value, start=0, stop=9223372036854775807, /)\n",
            " |      Return first index of value.\n",
            " |      \n",
            " |      Raises ValueError if the value is not present.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3Upt45MFTvg",
        "outputId": "e8913445-f685-4de9-851f-c0427df694c0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "numbers = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "print(numbers)\n",
        "print(type(numbers))\n",
        "print(numbers.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
            "<class 'numpy.ndarray'>\n",
            "(12,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hloEp1e0GTw5",
        "outputId": "064bf019-19b7-4abd-8e53-00ad32c73e84"
      },
      "source": [
        "numbers = numbers.reshape(12, 1)\n",
        "print(numbers)\n",
        "print(numbers.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1]\n",
            " [ 2]\n",
            " [ 3]\n",
            " [ 4]\n",
            " [ 5]\n",
            " [ 6]\n",
            " [ 7]\n",
            " [ 8]\n",
            " [ 9]\n",
            " [10]\n",
            " [11]\n",
            " [12]]\n",
            "(12, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIlWSGXhGjFw",
        "outputId": "31c1800b-d82b-4f68-9705-a6fc8cb7b065"
      },
      "source": [
        "numbers = numbers.reshape(1, 12, 1)\n",
        "print(numbers)\n",
        "print(numbers.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 1]\n",
            "  [ 2]\n",
            "  [ 3]\n",
            "  [ 4]\n",
            "  [ 5]\n",
            "  [ 6]\n",
            "  [ 7]\n",
            "  [ 8]\n",
            "  [ 9]\n",
            "  [10]\n",
            "  [11]\n",
            "  [12]]]\n",
            "(1, 12, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVTkRdXFGxIl",
        "outputId": "245fe5a9-d73c-46cd-cf5c-8bd689dc86a2"
      },
      "source": [
        "numbers = numbers.reshape(3,2,2)\n",
        "print(numbers)\n",
        "print(numbers.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 1  2]\n",
            "  [ 3  4]]\n",
            "\n",
            " [[ 5  6]\n",
            "  [ 7  8]]\n",
            "\n",
            " [[ 9 10]\n",
            "  [11 12]]]\n",
            "(3, 2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzOEYMZrG3FL",
        "outputId": "91bea4ff-c977-4df3-b65e-456c89f44981"
      },
      "source": [
        "numbers = numbers.reshape(1,3,2,2)\n",
        "print(numbers)\n",
        "print(numbers.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[ 1  2]\n",
            "   [ 3  4]]\n",
            "\n",
            "  [[ 5  6]\n",
            "   [ 7  8]]\n",
            "\n",
            "  [[ 9 10]\n",
            "   [11 12]]]]\n",
            "(1, 3, 2, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQKZfT3-HLRK",
        "outputId": "849bb458-b54b-4c91-caf1-ebb9e6757391"
      },
      "source": [
        "numbers = numbers.reshape(1,3,2,2,1)\n",
        "print(numbers)\n",
        "print(numbers.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[[ 1]\n",
            "    [ 2]]\n",
            "\n",
            "   [[ 3]\n",
            "    [ 4]]]\n",
            "\n",
            "\n",
            "  [[[ 5]\n",
            "    [ 6]]\n",
            "\n",
            "   [[ 7]\n",
            "    [ 8]]]\n",
            "\n",
            "\n",
            "  [[[ 9]\n",
            "    [10]]\n",
            "\n",
            "   [[11]\n",
            "    [12]]]]]\n",
            "(1, 3, 2, 2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4s2Uf7hHPwg",
        "outputId": "36b258fc-2273-4926-9848-bbd957fa72c6"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "UE5_AoSnH8bW",
        "outputId": "845039b4-aedd-41cd-c6a3-9daf2ad490e6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd6700de650>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "_JCmgmquIFbo",
        "outputId": "827ec1af-14e3-409b-92a4-fb162ce65863"
      },
      "source": [
        "plt.imshow(x_train[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd670085b90>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "f5cFZ30kIQo5",
        "outputId": "538439a9-ffef-4dcc-9c39-0791a93dd1f9"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>126</td>\n",
              "      <td>136</td>\n",
              "      <td>175</td>\n",
              "      <td>26</td>\n",
              "      <td>166</td>\n",
              "      <td>255</td>\n",
              "      <td>247</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>36</td>\n",
              "      <td>94</td>\n",
              "      <td>154</td>\n",
              "      <td>170</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>225</td>\n",
              "      <td>172</td>\n",
              "      <td>253</td>\n",
              "      <td>242</td>\n",
              "      <td>195</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>238</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>251</td>\n",
              "      <td>93</td>\n",
              "      <td>82</td>\n",
              "      <td>82</td>\n",
              "      <td>56</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>219</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>198</td>\n",
              "      <td>182</td>\n",
              "      <td>247</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>156</td>\n",
              "      <td>107</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>205</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>154</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>154</td>\n",
              "      <td>253</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>253</td>\n",
              "      <td>190</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>190</td>\n",
              "      <td>253</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>241</td>\n",
              "      <td>225</td>\n",
              "      <td>160</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>81</td>\n",
              "      <td>240</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>119</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>186</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>150</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>93</td>\n",
              "      <td>252</td>\n",
              "      <td>253</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>249</td>\n",
              "      <td>253</td>\n",
              "      <td>249</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>130</td>\n",
              "      <td>183</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>207</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>148</td>\n",
              "      <td>229</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>250</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>114</td>\n",
              "      <td>221</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>201</td>\n",
              "      <td>78</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>66</td>\n",
              "      <td>213</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>198</td>\n",
              "      <td>81</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>171</td>\n",
              "      <td>219</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>195</td>\n",
              "      <td>80</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>172</td>\n",
              "      <td>226</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>244</td>\n",
              "      <td>133</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>136</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>212</td>\n",
              "      <td>135</td>\n",
              "      <td>132</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3    4    5    6    7   ...   20   21   22   23  24  25  26  27\n",
              "0    0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "1    0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "2    0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "3    0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "4    0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "5    0   0   0   0    0    0    0    0  ...  166  255  247  127   0   0   0   0\n",
              "6    0   0   0   0    0    0    0    0  ...  253  242  195   64   0   0   0   0\n",
              "7    0   0   0   0    0    0    0   49  ...   82   56   39    0   0   0   0   0\n",
              "8    0   0   0   0    0    0    0   18  ...    0    0    0    0   0   0   0   0\n",
              "9    0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "10   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "11   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "12   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "13   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "14   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "15   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "16   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "17   0   0   0   0    0    0    0    0  ...   64    0    0    0   0   0   0   0\n",
              "18   0   0   0   0    0    0    0    0  ...    2    0    0    0   0   0   0   0\n",
              "19   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "20   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "21   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "22   0   0   0   0    0    0   18  171  ...    0    0    0    0   0   0   0   0\n",
              "23   0   0   0   0   55  172  226  253  ...    0    0    0    0   0   0   0   0\n",
              "24   0   0   0   0  136  253  253  253  ...    0    0    0    0   0   0   0   0\n",
              "25   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "26   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "27   0   0   0   0    0    0    0    0  ...    0    0    0    0   0   0   0   0\n",
              "\n",
              "[28 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "6HfUMKVmIV9l",
        "outputId": "28ba046e-deef-4b69-88f0-dcbca23363f7"
      },
      "source": [
        "plt.imshow(x_train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd60787ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "31RuE2WHIlbs",
        "outputId": "f5d20802-c2d3-485a-ac6e-2dacb812e407"
      },
      "source": [
        "plt.imshow(x_train[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd6077e5bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ZgafkbbmInqo",
        "outputId": "29cc413d-020e-45cb-9f4e-3962e88085b0"
      },
      "source": [
        "print(y_train[2])\n",
        "plt.imshow(x_train[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd6077d2990>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPyzCHiEIqQA",
        "outputId": "9694ec47-84fb-4b7f-b25c-923bd76369e2"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "JIqvBpj7JI0R",
        "outputId": "49225949-245a-4765-86f1-55b05742bf0c"
      },
      "source": [
        "plt.imshow(x_train[83])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd60773d290>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c13phAnFPxl7"
      },
      "source": [
        "## Flatten Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kzUt0DkJfCf",
        "outputId": "b7516fb3-4f97-4cf5-e072-b5aec35ca6e9"
      },
      "source": [
        "#데이터를 준비\n",
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmIcG3mhP0eZ",
        "outputId": "c5206e57-cd08-4912-a5e3-70d60ea4e139"
      },
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28,28])\n",
        "H = tf.keras.layers.Flatten()(X)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy') #sparse 붙이면 앞에서 원핫인코딩 안해도 됨(숫자로 인덱싱 되어 있을때만)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 84)                65940     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,790\n",
            "Trainable params: 66,790\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS3aKEpxQ1fw",
        "outputId": "018a4be7-1bb3-4108-b899-0d40f638601c"
      },
      "source": [
        "# 모델을 데이터로 학습\n",
        "model.fit(x_train, y_train, batch_size=100, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "480/480 [==============================] - 3s 4ms/step - loss: 3.8234 - accuracy: 0.8204 - val_loss: 0.5772 - val_accuracy: 0.8834\n",
            "Epoch 2/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.5211 - accuracy: 0.9032 - val_loss: 0.4372 - val_accuracy: 0.9202\n",
            "Epoch 3/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.3742 - accuracy: 0.9276 - val_loss: 0.3889 - val_accuracy: 0.9293\n",
            "Epoch 4/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.3013 - accuracy: 0.9406 - val_loss: 0.3601 - val_accuracy: 0.9365\n",
            "Epoch 5/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.2568 - accuracy: 0.9472 - val_loss: 0.3842 - val_accuracy: 0.9347\n",
            "Epoch 6/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.2318 - accuracy: 0.9548 - val_loss: 0.3554 - val_accuracy: 0.9448\n",
            "Epoch 7/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.2181 - accuracy: 0.9568 - val_loss: 0.3347 - val_accuracy: 0.9460\n",
            "Epoch 8/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.2022 - accuracy: 0.9601 - val_loss: 0.3845 - val_accuracy: 0.9480\n",
            "Epoch 9/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.1850 - accuracy: 0.9630 - val_loss: 0.3498 - val_accuracy: 0.9474\n",
            "Epoch 10/10\n",
            "480/480 [==============================] - 2s 4ms/step - loss: 0.1731 - accuracy: 0.9646 - val_loss: 0.3904 - val_accuracy: 0.9461\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd604a4bc50>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bScBh2NZSBVr",
        "outputId": "cb1fe185-4a7c-4183-f3df-577b99af8dd4"
      },
      "source": [
        "#모델을 이용\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.9430\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.49268344044685364, 0.9430000185966492]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvhgi3_eUQn2",
        "outputId": "c1852136-6eec-4ffb-b15b-23d080b7766f"
      },
      "source": [
        "model.predict(x_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0000000e+00, 0.0000000e+00, 4.9540982e-24, 1.0694527e-21,\n",
              "        1.7296602e-28, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
              "        0.0000000e+00, 5.4279269e-18],\n",
              "       [0.0000000e+00, 3.1118257e-27, 1.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       [1.7278226e-33, 1.0000000e+00, 3.5129397e-10, 5.1995696e-13,\n",
              "        2.8686764e-10, 9.2231565e-16, 9.9394876e-17, 6.5377015e-09,\n",
              "        2.3478323e-08, 1.1708534e-17],\n",
              "       [9.9726832e-01, 1.9683997e-19, 1.1996191e-03, 1.1827372e-07,\n",
              "        2.0955621e-08, 6.4240560e-08, 1.5318111e-03, 8.3292511e-15,\n",
              "        8.7123073e-09, 2.5291615e-09],\n",
              "       [5.5252459e-30, 0.0000000e+00, 3.4214976e-25, 0.0000000e+00,\n",
              "        1.0000000e+00, 8.1061760e-27, 0.0000000e+00, 3.8383111e-21,\n",
              "        5.5332785e-31, 1.5813227e-11]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MECvgnyCUUnv",
        "outputId": "f61675cf-6a75-4eaf-fa46-5671fe7d739c"
      },
      "source": [
        "y_test[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "DiWJFBMPUkxT",
        "outputId": "3dc87404-270d-4ab6-9a67-19a3bc047e10"
      },
      "source": [
        "plt.imshow(x_test[0], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd6703f9e90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "yIYj7zeXUp5L",
        "outputId": "9f84f0da-98dc-4779-a27c-646410a62f89"
      },
      "source": [
        "plt.imshow(x_test[1], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd67022bd50>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "oP7_xR0nUtTS",
        "outputId": "8ea6b0ff-16b3-43d6-f514-7360a01d522d"
      },
      "source": [
        "plt.imshow(x_test[2], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd670225b50>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOI7ZJtBSlPX"
      },
      "source": [
        "## Convolution Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qUCsZ0YEP4l",
        "outputId": "2b58303b-def4-45ed-a92d-db0456829dcb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02vJobw2S9o4",
        "outputId": "5396626d-79f2-441b-e09f-90dfc7d17f3b"
      },
      "source": [
        "#모델 만들기\n",
        "X = tf.keras.Input(shape=[28,28,1])\n",
        "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation='swish')(X) #필터 사이즈는 (5, 5, 1) * 3 = (3, 5, 5, 1)\n",
        "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation='swish')(H) #필터 (6, 5, 5, 3)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "model.summary() #2400*84 + 84 = 첫번째 dense 레이어의 가중치 수 계산"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 24, 24, 3)         78        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 20, 20, 6)         456       \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2400)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 84)                201684    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203,068\n",
            "Trainable params: 203,068\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZW2H_SfUU45",
        "outputId": "4b07cf16-dbb8-473f-d8c3-7203f2dd96d6"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 11s 10ms/step - loss: 0.5407 - accuracy: 0.9029 - val_loss: 0.1382 - val_accuracy: 0.9621\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0826 - accuracy: 0.9770 - val_loss: 0.1095 - val_accuracy: 0.9708\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 0.1215 - val_accuracy: 0.9740\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.1493 - val_accuracy: 0.9711\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1540 - val_accuracy: 0.9754\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.1444 - val_accuracy: 0.9785\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.1697 - val_accuracy: 0.9763\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1889 - val_accuracy: 0.9774\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.1887 - val_accuracy: 0.9777\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 4s 9ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.2133 - val_accuracy: 0.9744\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5fe05c910>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkDn3kyzV2cu"
      },
      "source": [
        "### Q1. ConV모델의 식에 대해\n",
        "- image shape : (28, 28, 1)\n",
        "- filter size : (5, 5)\n",
        "- stride : 1 (default=1)\n",
        "output size? (24, 24, ?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nyxd6OAXYz8"
      },
      "source": [
        "### Q2. ConV모델의 식에 대해\n",
        "- image shape : (10, 10, 1)\n",
        "- filter size : (3, 3)\n",
        "- stride : 1 (default=1)\n",
        "output size? (8,8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1S18HCjXdzJ"
      },
      "source": [
        "### Q3. ConV모델의 식에 대해\n",
        "- image shape : (10, 10, 1)\n",
        "- filter size : (3, 3)\n",
        "- stride : 2 (default=1)\n",
        "- output size : (4,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7ORDdfBl6xG"
      },
      "source": [
        "## Pooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGy0_kDfVE9P",
        "outputId": "4d6b0da8-96ae-47ba-fbc3-65db4516fd1c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrvlywPObjoM",
        "outputId": "9426a7e3-2e5c-43a4-fd70-62432a9a85de"
      },
      "source": [
        "#모델 만들기\n",
        "X = tf.keras.Input(shape=[28,28,1])\n",
        "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation='swish')(X) #필터 사이즈는 (5, 5, 1) * 3 = (3, 5, 5, 1)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation='swish')(H) #필터 (6, 5, 5, 3)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 3)         78        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 3)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 6)           456       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 6)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 84)                8148      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,532\n",
            "Trainable params: 9,532\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vbu5rVyb9zg",
        "outputId": "eab5210d-df34-4217-e0e4-baa24c0cb8dd"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 4s 7ms/step - loss: 2.1724 - accuracy: 0.7732 - val_loss: 0.3171 - val_accuracy: 0.9126\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2454 - accuracy: 0.9309 - val_loss: 0.1828 - val_accuracy: 0.9463\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1582 - accuracy: 0.9539 - val_loss: 0.1554 - val_accuracy: 0.9530\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1196 - accuracy: 0.9645 - val_loss: 0.1217 - val_accuracy: 0.9644\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0999 - accuracy: 0.9699 - val_loss: 0.1204 - val_accuracy: 0.9640\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0848 - accuracy: 0.9736 - val_loss: 0.1065 - val_accuracy: 0.9708\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0752 - accuracy: 0.9776 - val_loss: 0.0983 - val_accuracy: 0.9732\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.1017 - val_accuracy: 0.9712\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0598 - accuracy: 0.9813 - val_loss: 0.0996 - val_accuracy: 0.9730\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.0980 - val_accuracy: 0.9733\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd6036cba10>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzWynGSViRqx"
      },
      "source": [
        "## LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LBXs0jFcAO3",
        "outputId": "291ace89-7b97-4376-8042-718a752b27ca"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lZ6K_cKibH_",
        "outputId": "665acb98-724c-4f48-90af-e44b21d779ab"
      },
      "source": [
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "H = tf.keras.layers.Conv2D(6, kernel_size=5, padding='same', activation='swish')(X)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(16, kernel_size=5, activation='swish')(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(120, activation='swish')(H)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 6)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp8Wg2pBi9sS",
        "outputId": "e1158904-dcdf-4ff9-dcb5-45758b68da79"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 5s 10ms/step - loss: 0.8224 - accuracy: 0.8752 - val_loss: 0.1507 - val_accuracy: 0.9532\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.1032 - accuracy: 0.9698 - val_loss: 0.0990 - val_accuracy: 0.9702\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0658 - accuracy: 0.9808 - val_loss: 0.0991 - val_accuracy: 0.9723\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0496 - accuracy: 0.9852 - val_loss: 0.0652 - val_accuracy: 0.9837\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0404 - accuracy: 0.9881 - val_loss: 0.0601 - val_accuracy: 0.9852\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 0.0669 - val_accuracy: 0.9833\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0273 - accuracy: 0.9914 - val_loss: 0.0781 - val_accuracy: 0.9828\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 0.0870 - val_accuracy: 0.9825\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.0910 - val_accuracy: 0.9837\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.1151 - val_accuracy: 0.9827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd603429d10>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUz7kOqIvG_N"
      },
      "source": [
        "## Lenet + fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsU-pm4WvkBu"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 데이터를 준비합니다. \n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "R0inck0zjvuu",
        "outputId": "f5013bf9-34cb-4e2c-f55c-25495e5bf94b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[2].reshape(28, 28), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd6034155d0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2yqcZ4dvoJu",
        "outputId": "bc9a0119-359d-4f9d-c0f4-9064ed336212"
      },
      "source": [
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "H = tf.keras.layers.Conv2D(6, kernel_size=5, padding='same')(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Dropout(0.4)(H) #0.6만큼만 랜덤으로 뽑아서 학습할 것, 데이터 충분하면 0.7까지도 씀. 높이면 오버피팅이 거의 안생기는 경우도 있음\n",
        "H = tf.keras.layers.Conv2D(16, kernel_size=5, activation='swish')(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "\n",
        "H = tf.keras.layers.Dropout(0.4)(H)\n",
        "H = tf.keras.layers.Dense(120, activation='swish')(H)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 28, 6)        24        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 14, 14, 6)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 14, 14, 6)         0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 16)       64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 5, 5, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,794\n",
            "Trainable params: 61,750\n",
            "Non-trainable params: 44\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhr3cQb1wXvx",
        "outputId": "89142578-5771-4551-d972-516dedd859f4"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 5s 11ms/step - loss: 0.4424 - accuracy: 0.8568 - val_loss: 0.0966 - val_accuracy: 0.9718\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.1710 - accuracy: 0.9469 - val_loss: 0.0731 - val_accuracy: 0.9793\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.1288 - accuracy: 0.9592 - val_loss: 0.0560 - val_accuracy: 0.9841\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.1111 - accuracy: 0.9649 - val_loss: 0.0590 - val_accuracy: 0.9829\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0978 - accuracy: 0.9695 - val_loss: 0.0529 - val_accuracy: 0.9842\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0886 - accuracy: 0.9719 - val_loss: 0.0468 - val_accuracy: 0.9872\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0810 - accuracy: 0.9744 - val_loss: 0.0488 - val_accuracy: 0.9852\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0754 - accuracy: 0.9759 - val_loss: 0.0395 - val_accuracy: 0.9886\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0679 - accuracy: 0.9787 - val_loss: 0.0400 - val_accuracy: 0.9880\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0660 - accuracy: 0.9787 - val_loss: 0.0389 - val_accuracy: 0.9883\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0664 - accuracy: 0.9789 - val_loss: 0.0347 - val_accuracy: 0.9898\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0629 - accuracy: 0.9802 - val_loss: 0.0356 - val_accuracy: 0.9898\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0591 - accuracy: 0.9820 - val_loss: 0.0345 - val_accuracy: 0.9902\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0558 - accuracy: 0.9825 - val_loss: 0.0350 - val_accuracy: 0.9902\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0558 - accuracy: 0.9821 - val_loss: 0.0321 - val_accuracy: 0.9910\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0311 - val_accuracy: 0.9920\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0540 - accuracy: 0.9828 - val_loss: 0.0317 - val_accuracy: 0.9910\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0496 - accuracy: 0.9840 - val_loss: 0.0356 - val_accuracy: 0.9899\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0330 - val_accuracy: 0.9897\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0462 - accuracy: 0.9853 - val_loss: 0.0319 - val_accuracy: 0.9907\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5893f4990>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NT9S_HjP2pwl",
        "outputId": "70730325-9aa5-4664-9db7-7da8b9253ee9"
      },
      "source": [
        "#(255x255) * 10000\n",
        "256-224"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABMMUXKt2vUA",
        "outputId": "d1d732e0-16fd-4ffe-c3e2-075161f1df5a"
      },
      "source": [
        "# 256 => 224\n",
        "32 * 32 * 10000 * 2 #좌우반전"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20480000"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEuSBlAoMbGv"
      },
      "source": [
        "## 복습용 실습문제\n",
        "\n",
        "- fashion mnist 학습 cnn 모델 만들기\n",
        "- conv layer 4개 이상 쓰기\n",
        "- 학습 가중치(parameter 개수)는 5만개 미만으로 사용하기\n",
        "\n",
        "- 학습 데이터에 대해서는 100$ fitting에 가깝게 해보기\n",
        "- overfitting 발생하는 것 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmsfm1g9O3Zj",
        "outputId": "4e592f0f-6dee-4551-9355-5223bab4e16b"
      },
      "source": [
        "# 데이터 준비하기\n",
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) #-1써주면 알아서 계산해서 줌\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4tVRBk2O-zQ",
        "outputId": "6fd1b983-bb0c-4534-ea3a-6055f67e2365"
      },
      "source": [
        "#conv layer\n",
        "X=tf.keras.Input(shape=[28,28,1])\n",
        "\n",
        "H=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(X)\n",
        "H=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(H)\n",
        "H=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Flatten()(H)\n",
        "H=tf.keras.layers.Dense(48, activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H)\n",
        "\n",
        "model=tf.keras.Model(X,Y)\n",
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 28, 28, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 14, 14, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 14, 14, 16)        2320      \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 14, 14, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 7, 7, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 48)                37680     \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 10)                490       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,290\n",
            "Trainable params: 45,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fip8yIvRDhc",
        "outputId": "83026838-0dc9-47fb-94ee-1ce8e7157179"
      },
      "source": [
        "result = model.fit(x_train, y_train, batch_size=256, epochs=30, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "188/188 [==============================] - 6s 26ms/step - loss: 0.7925 - accuracy: 0.7691 - val_loss: 0.4066 - val_accuracy: 0.8529\n",
            "Epoch 2/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.3640 - accuracy: 0.8662 - val_loss: 0.3543 - val_accuracy: 0.8730\n",
            "Epoch 3/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.2981 - accuracy: 0.8908 - val_loss: 0.3510 - val_accuracy: 0.8706\n",
            "Epoch 4/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.2612 - accuracy: 0.9057 - val_loss: 0.2948 - val_accuracy: 0.8923\n",
            "Epoch 5/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.2347 - accuracy: 0.9134 - val_loss: 0.3123 - val_accuracy: 0.8877\n",
            "Epoch 6/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.2134 - accuracy: 0.9199 - val_loss: 0.3216 - val_accuracy: 0.8820\n",
            "Epoch 7/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1953 - accuracy: 0.9280 - val_loss: 0.2794 - val_accuracy: 0.9013\n",
            "Epoch 8/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1798 - accuracy: 0.9340 - val_loss: 0.3070 - val_accuracy: 0.8925\n",
            "Epoch 9/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1660 - accuracy: 0.9385 - val_loss: 0.2987 - val_accuracy: 0.8997\n",
            "Epoch 10/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.1533 - accuracy: 0.9433 - val_loss: 0.3554 - val_accuracy: 0.8879\n",
            "Epoch 11/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.1404 - accuracy: 0.9485 - val_loss: 0.3208 - val_accuracy: 0.8928\n",
            "Epoch 12/30\n",
            "188/188 [==============================] - 5s 25ms/step - loss: 0.1298 - accuracy: 0.9519 - val_loss: 0.3440 - val_accuracy: 0.8907\n",
            "Epoch 13/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.1189 - accuracy: 0.9570 - val_loss: 0.3142 - val_accuracy: 0.8975\n",
            "Epoch 14/30\n",
            "188/188 [==============================] - 5s 25ms/step - loss: 0.1105 - accuracy: 0.9586 - val_loss: 0.3430 - val_accuracy: 0.8947\n",
            "Epoch 15/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.1014 - accuracy: 0.9623 - val_loss: 0.3880 - val_accuracy: 0.8977\n",
            "Epoch 16/30\n",
            "188/188 [==============================] - 5s 25ms/step - loss: 0.0958 - accuracy: 0.9649 - val_loss: 0.3962 - val_accuracy: 0.8948\n",
            "Epoch 17/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.0889 - accuracy: 0.9671 - val_loss: 0.4325 - val_accuracy: 0.8873\n",
            "Epoch 18/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.0814 - accuracy: 0.9700 - val_loss: 0.4362 - val_accuracy: 0.8893\n",
            "Epoch 19/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.0777 - accuracy: 0.9721 - val_loss: 0.4368 - val_accuracy: 0.8911\n",
            "Epoch 20/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.0727 - accuracy: 0.9734 - val_loss: 0.5224 - val_accuracy: 0.8818\n",
            "Epoch 21/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.0678 - accuracy: 0.9754 - val_loss: 0.4850 - val_accuracy: 0.8874\n",
            "Epoch 22/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.0631 - accuracy: 0.9771 - val_loss: 0.4636 - val_accuracy: 0.8927\n",
            "Epoch 23/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.0599 - accuracy: 0.9782 - val_loss: 0.4791 - val_accuracy: 0.8944\n",
            "Epoch 24/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 0.5541 - val_accuracy: 0.8889\n",
            "Epoch 25/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.0540 - accuracy: 0.9798 - val_loss: 0.5328 - val_accuracy: 0.8942\n",
            "Epoch 26/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.0509 - accuracy: 0.9807 - val_loss: 0.5328 - val_accuracy: 0.8956\n",
            "Epoch 27/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.0494 - accuracy: 0.9815 - val_loss: 0.5574 - val_accuracy: 0.8895\n",
            "Epoch 28/30\n",
            "188/188 [==============================] - 5s 26ms/step - loss: 0.0483 - accuracy: 0.9824 - val_loss: 0.5679 - val_accuracy: 0.8954\n",
            "Epoch 29/30\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.0458 - accuracy: 0.9833 - val_loss: 0.6070 - val_accuracy: 0.8896\n",
            "Epoch 30/30\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.0464 - accuracy: 0.9829 - val_loss: 0.5983 - val_accuracy: 0.8872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhvTPX0abIlU",
        "outputId": "8e3e5c19-9743-4c9b-a921-f8c488bf1474"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 5ms/step - loss: 0.6173 - accuracy: 0.8928\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6173160672187805, 0.892799973487854]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KxT58BJaOCk"
      },
      "source": [
        "### history plot\n",
        "- loss, val_loss\n",
        "- accuracy, val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "1qCjNjYDZwEK",
        "outputId": "1338c9da-50ec-4c76-ab5a-9fc7f3cc8c39"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(result.history['loss'])\n",
        "plt.plot(result.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f794d339cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Txe8L_V6aEaA",
        "outputId": "409af758-317a-43bc-e2f1-faf70fa98876"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(result.history['accuracy'])\n",
        "plt.plot(result.history['val_accuracy'])\n",
        "plt.legend(['accuracy', 'val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f794afd7850>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vjv2i6YcbN2"
      },
      "source": [
        "### early stopping\n",
        "- 특정 조건이 되었을때 알아서 학습을 멈추게 하는 기능(오버피팅이라고 판단될때 그만)\n",
        "- 모델을 최적의 상태로 되돌리기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCI2lGpDYqfm",
        "outputId": "ef6a6a40-9c6e-4aeb-eca7-2a1606161ab9"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) #-1써주면 알아서 계산해서 줌\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipz3W7LcfVVJ",
        "outputId": "d0e2e542-55e9-4d34-d31a-b49c23114ef5"
      },
      "source": [
        "X=tf.keras.Input(shape=[28,28,1])\n",
        "\n",
        "H=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(X)\n",
        "H=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(H)\n",
        "H=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Flatten()(H)\n",
        "H=tf.keras.layers.Dense(48, activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H)\n",
        "\n",
        "model=tf.keras.Model(X,Y)\n",
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 28, 28, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 14, 14, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 14, 14, 16)        2320      \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 14, 14, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 7, 7, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 48)                37680     \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                490       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,290\n",
            "Trainable params: 45,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLlt-nvNcdM6",
        "outputId": "cc6a637c-ac50-4c70-99ea-2a2d46448f72"
      },
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta = 0, #개선되고 있다고 판단하기 위한 최소 변화량\n",
        "    patience = 5, #개선이 없는 상태를 몇번이나 기다릴것이냐\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "result = model.fit(x_train, y_train, batch_size=256, epochs=1000, validation_split=0.2, callbacks=[early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "188/188 [==============================] - 7s 29ms/step - loss: 0.8915 - accuracy: 0.7499 - val_loss: 0.4553 - val_accuracy: 0.8335\n",
            "Epoch 2/1000\n",
            "188/188 [==============================] - 5s 25ms/step - loss: 0.3645 - accuracy: 0.8686 - val_loss: 0.3537 - val_accuracy: 0.8718\n",
            "Epoch 3/1000\n",
            "188/188 [==============================] - 5s 25ms/step - loss: 0.2976 - accuracy: 0.8900 - val_loss: 0.3653 - val_accuracy: 0.8687\n",
            "Epoch 4/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.2603 - accuracy: 0.9046 - val_loss: 0.2866 - val_accuracy: 0.8962\n",
            "Epoch 5/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.2332 - accuracy: 0.9154 - val_loss: 0.2955 - val_accuracy: 0.8952\n",
            "Epoch 6/1000\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.2118 - accuracy: 0.9208 - val_loss: 0.3298 - val_accuracy: 0.8805\n",
            "Epoch 7/1000\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.1956 - accuracy: 0.9287 - val_loss: 0.2882 - val_accuracy: 0.9003\n",
            "Epoch 8/1000\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.1797 - accuracy: 0.9331 - val_loss: 0.2813 - val_accuracy: 0.9018\n",
            "Epoch 9/1000\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.1658 - accuracy: 0.9386 - val_loss: 0.2934 - val_accuracy: 0.9004\n",
            "Epoch 10/1000\n",
            "188/188 [==============================] - 5s 25ms/step - loss: 0.1530 - accuracy: 0.9426 - val_loss: 0.2851 - val_accuracy: 0.9059\n",
            "Epoch 11/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1403 - accuracy: 0.9479 - val_loss: 0.3255 - val_accuracy: 0.8965\n",
            "Epoch 12/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1299 - accuracy: 0.9520 - val_loss: 0.3350 - val_accuracy: 0.9013\n",
            "Epoch 13/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1192 - accuracy: 0.9559 - val_loss: 0.3434 - val_accuracy: 0.9009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vAlrNWDgU-E"
      },
      "source": [
        "### data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3KwU_kDeWwg"
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True #좌우반전\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "_A8T6ckcg26z",
        "outputId": "e66cfceb-d92b-4786-ac15-42879537d298"
      },
      "source": [
        "print(train_gen[0][0].shape, train_gen[0][1].shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_gen[0][0][0].reshape(28, 28))\n",
        "#계속 눌러보면 조금씩 이동함"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 28, 28, 1) (256,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f79cb8bc650>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1evw1i0hL-T",
        "outputId": "c9471be3-3568-4ed0-ef7b-d3817a9d2b3b"
      },
      "source": [
        "model.fit(train_gen, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 23s 96ms/step - loss: 0.4804 - accuracy: 0.8253\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 23s 97ms/step - loss: 0.3826 - accuracy: 0.8590\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 23s 97ms/step - loss: 0.3494 - accuracy: 0.8706\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 23s 97ms/step - loss: 0.3345 - accuracy: 0.8775\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 23s 96ms/step - loss: 0.3181 - accuracy: 0.8813\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 23s 97ms/step - loss: 0.3077 - accuracy: 0.8861\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.2995 - accuracy: 0.8891\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 23s 96ms/step - loss: 0.2926 - accuracy: 0.8915\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 22s 95ms/step - loss: 0.2858 - accuracy: 0.8940\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 23s 97ms/step - loss: 0.2830 - accuracy: 0.8942\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79cbbcc110>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEvlkiK8h5KP",
        "outputId": "9b558acb-1518-45b9-a60c-6a5a04422337"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 5ms/step - loss: 0.2681 - accuracy: 0.9077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2681192457675934, 0.9077000021934509]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZxg0CQMj6PE",
        "outputId": "215ae392-fde4-41fe-ea27-daa4f50fe19b"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "x_train, x_val = x_train[:50000], x_train[50000:]\n",
        "y_train, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 28, 28, 1) (50000,)\n",
            "(10000, 28, 28, 1) (10000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFRyYjCFk-kT"
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "train_gen = datagen.flow(x_train, y_train, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5FYBvIDkNFG",
        "outputId": "dc354317-2a67-43be-ba38-ec1263e9e409"
      },
      "source": [
        "model.fit(train_gen, epochs=1000, validation_data=(x_val, y_val), callbacks=[early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "196/196 [==============================] - 20s 102ms/step - loss: 0.2743 - accuracy: 0.8990 - val_loss: 0.2631 - val_accuracy: 0.9038\n",
            "Epoch 2/1000\n",
            "196/196 [==============================] - 20s 103ms/step - loss: 0.2700 - accuracy: 0.8992 - val_loss: 0.2468 - val_accuracy: 0.9076\n",
            "Epoch 3/1000\n",
            "196/196 [==============================] - 20s 103ms/step - loss: 0.2678 - accuracy: 0.9014 - val_loss: 0.2441 - val_accuracy: 0.9072\n",
            "Epoch 4/1000\n",
            "196/196 [==============================] - 20s 103ms/step - loss: 0.2645 - accuracy: 0.9031 - val_loss: 0.2495 - val_accuracy: 0.9091\n",
            "Epoch 5/1000\n",
            "196/196 [==============================] - 20s 102ms/step - loss: 0.2621 - accuracy: 0.9026 - val_loss: 0.2572 - val_accuracy: 0.9052\n",
            "Epoch 6/1000\n",
            "196/196 [==============================] - 20s 102ms/step - loss: 0.2598 - accuracy: 0.9056 - val_loss: 0.2532 - val_accuracy: 0.9061\n",
            "Epoch 7/1000\n",
            "196/196 [==============================] - 20s 102ms/step - loss: 0.2553 - accuracy: 0.9056 - val_loss: 0.2230 - val_accuracy: 0.9185\n",
            "Epoch 8/1000\n",
            "196/196 [==============================] - 20s 100ms/step - loss: 0.2536 - accuracy: 0.9068 - val_loss: 0.2485 - val_accuracy: 0.9118\n",
            "Epoch 9/1000\n",
            "196/196 [==============================] - 20s 102ms/step - loss: 0.2530 - accuracy: 0.9072 - val_loss: 0.2419 - val_accuracy: 0.9112\n",
            "Epoch 10/1000\n",
            "196/196 [==============================] - 20s 102ms/step - loss: 0.2505 - accuracy: 0.9090 - val_loss: 0.2466 - val_accuracy: 0.9108\n",
            "Epoch 11/1000\n",
            "196/196 [==============================] - 20s 102ms/step - loss: 0.2487 - accuracy: 0.9086 - val_loss: 0.2361 - val_accuracy: 0.9117\n",
            "Epoch 12/1000\n",
            "196/196 [==============================] - 20s 102ms/step - loss: 0.2444 - accuracy: 0.9093 - val_loss: 0.2322 - val_accuracy: 0.9164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79cb6954d0>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbvw6mH2kdDj",
        "outputId": "8530f40c-422d-427a-bb2f-aa7faea991da"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2581 - accuracy: 0.9094\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.258137971162796, 0.9093999862670898]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLGENOaNojHs"
      },
      "source": [
        "### 필터와 특징맵 출력해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF8Pn2m_nZLM",
        "outputId": "5bc8a045-63f2-4aa5-db49-24f9882992e2"
      },
      "source": [
        "weights = model.get_weights()\n",
        "print(len(weights))\n",
        "print(weights[0].shape, weights[1].shape)\n",
        "print(weights[2].shape, weights[3].shape)\n",
        "print(weights[4].shape, weights[5].shape)\n",
        "print(weights[6].shape, weights[7].shape)\n",
        "print(weights[8].shape, weights[9].shape)\n",
        "print(weights[10].shape, weights[11].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "(3, 3, 1, 16) (16,)\n",
            "(3, 3, 16, 16) (16,)\n",
            "(3, 3, 16, 16) (16,)\n",
            "(3, 3, 16, 16) (16,)\n",
            "(784, 48) (48,)\n",
            "(48, 10) (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "lFk3lcNOnsBP",
        "outputId": "211f9015-d709-4faa-d6e6-1d31daba631b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(weights[0][:,:,:,-1].reshape(3,3), cmap='gray')\n",
        "print(weights[0][:,:,:,-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.0274251 ]\n",
            "  [-0.09708192]\n",
            "  [ 0.07142613]]\n",
            "\n",
            " [[ 0.17371975]\n",
            "  [-0.03837216]\n",
            "  [-0.06549069]]\n",
            "\n",
            " [[-0.19504882]\n",
            "  [-0.27827638]\n",
            "  [-0.16528916]]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh52rwWKoDdY",
        "outputId": "aa8d306e-81d5-4287-9202-d28cdec42b95"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1) #-1써주면 알아서 계산해서 줌\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8vU6qvhqTvs",
        "outputId": "d74bca5b-caab-47d1-8152-f827f42915cc"
      },
      "source": [
        "X=tf.keras.Input(shape=[28,28,1])\n",
        "\n",
        "H1=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(X)\n",
        "H2=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(H1)\n",
        "M1=tf.keras.layers.MaxPool2D()(H2)\n",
        "\n",
        "H3=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(M1)\n",
        "H4=tf.keras.layers.Conv2D(16, kernel_size=3, padding='same', activation='swish')(H3)\n",
        "M2=tf.keras.layers.MaxPool2D()(H4)\n",
        "\n",
        "H=tf.keras.layers.Flatten()(M2)\n",
        "H=tf.keras.layers.Dense(48, activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10,activation='softmax')(H)\n",
        "\n",
        "model=tf.keras.Model(X,Y)\n",
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 28, 28, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 14, 14, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 14, 14, 16)        2320      \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 14, 14, 16)        2320      \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 7, 7, 16)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 784)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 48)                37680     \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 10)                490       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,290\n",
            "Trainable params: 45,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SQbzHsJqt0K",
        "outputId": "6e277c54-2c28-4c88-a709-c9b911f69a75"
      },
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta = 0,\n",
        "    patience = 5,\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "result = model.fit(x_train, y_train, batch_size=256, epochs=1000, validation_split=0.2, callbacks=[early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "188/188 [==============================] - 6s 26ms/step - loss: 1.1377 - accuracy: 0.7448 - val_loss: 0.5980 - val_accuracy: 0.7808\n",
            "Epoch 2/1000\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.3810 - accuracy: 0.8614 - val_loss: 0.3740 - val_accuracy: 0.8621\n",
            "Epoch 3/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.3098 - accuracy: 0.8857 - val_loss: 0.3293 - val_accuracy: 0.8801\n",
            "Epoch 4/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.2694 - accuracy: 0.9013 - val_loss: 0.3110 - val_accuracy: 0.8896\n",
            "Epoch 5/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.2410 - accuracy: 0.9117 - val_loss: 0.3338 - val_accuracy: 0.8790\n",
            "Epoch 6/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.2219 - accuracy: 0.9177 - val_loss: 0.2789 - val_accuracy: 0.8988\n",
            "Epoch 7/1000\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.2028 - accuracy: 0.9244 - val_loss: 0.2674 - val_accuracy: 0.9029\n",
            "Epoch 8/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1878 - accuracy: 0.9301 - val_loss: 0.2626 - val_accuracy: 0.9092\n",
            "Epoch 9/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1748 - accuracy: 0.9358 - val_loss: 0.2860 - val_accuracy: 0.9001\n",
            "Epoch 10/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1604 - accuracy: 0.9412 - val_loss: 0.3086 - val_accuracy: 0.8963\n",
            "Epoch 11/1000\n",
            "188/188 [==============================] - 4s 24ms/step - loss: 0.1499 - accuracy: 0.9434 - val_loss: 0.2915 - val_accuracy: 0.9013\n",
            "Epoch 12/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1397 - accuracy: 0.9482 - val_loss: 0.3098 - val_accuracy: 0.9029\n",
            "Epoch 13/1000\n",
            "188/188 [==============================] - 5s 24ms/step - loss: 0.1296 - accuracy: 0.9524 - val_loss: 0.3489 - val_accuracy: 0.8935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "305Cc2smqzZ7"
      },
      "source": [
        "output1 = tf.keras.Model(X, [H1, H2, H3, H4])\n",
        "output2 = tf.keras.Model(X, [M1, M2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y13A_ATrU-A",
        "outputId": "88bddd36-c0ca-492a-902c-54e2ea588a3f"
      },
      "source": [
        "h1, h2, h3, h4 = output1.predict(x_test[:1])\n",
        "print(h1.shape, h2.shape, h3.shape, h4.shape)\n",
        "\n",
        "m1, m2 = output2.predict(x_test[:1])\n",
        "print(m1.shape, m2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 16) (1, 28, 28, 16) (1, 14, 14, 16) (1, 14, 14, 16)\n",
            "(1, 14, 14, 16) (1, 7, 7, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "TApt9meUrirq",
        "outputId": "e75d8c69-bb6c-464f-f0e8-e3154a8cf320"
      },
      "source": [
        "plt.imshow(h1[0, :, :, -1], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f79cb52a150>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "P2Kzz3kir3ee",
        "outputId": "65710e72-b52f-4c88-850e-a9f015cd9b2a"
      },
      "source": [
        "plt.imshow(h2[0, :, :, 3], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f79ca679d90>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Bmf2MEsMsJrx",
        "outputId": "9cde38cd-98c0-407e-d3c8-9896bcce4819"
      },
      "source": [
        "plt.imshow(h3[0, :, :, 2], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f79538323d0>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "l2emfFRwsO67",
        "outputId": "2de5bb28-6c1e-40d7-e963-4006bb815afb"
      },
      "source": [
        "plt.imshow(h4[0, :, :, -1], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f79cb4da090>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "ACoJLc3asQ7b",
        "outputId": "fcbc91e2-ae6f-491d-ce78-ae47ee021f83"
      },
      "source": [
        "plt.imshow(m1[0, :, :, 2], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f79536985d0>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Dr7dZ_sxslJP",
        "outputId": "dcaddbc7-723d-4339-d84c-a2d0f789b3bf"
      },
      "source": [
        "plt.imshow(m2[0, :, :, 5], cmap='gray')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f794d1ac510>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtaj1OGivSXE"
      },
      "source": [
        "## VGGNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH2nCm2pv-yW",
        "outputId": "12dad92d-3f7b-45b9-a53a-1ebf1573746f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeJ31QQGydrx"
      },
      "source": [
        "def vgg_block(numbers, x):\n",
        "  net = tf.keras.layers.Conv2D(numbers, kernel_size=3, padding='same')(x)\n",
        "  net = tf.keras.layers.BatchNormalization()(net)\n",
        "  net = tf.keras.layers.Activation('swish')(net)\n",
        "  net = tf.keras.layers.Conv2D(numbers, kernel_size=3, padding='same', activation='swish')(net)\n",
        "  net = tf.keras.layers.BatchNormalization()(net)\n",
        "  net = tf.keras.layers.Activation('swish')(net)\n",
        "  return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY-C7uIBtbdw",
        "outputId": "165836a9-6614-4bb1-ccb3-81740af91a6d"
      },
      "source": [
        "X=tf.keras.Input(shape=[32,32,3])\n",
        "\n",
        "H=vgg_block(64, X)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=vgg_block(128, H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=vgg_block(256, H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=vgg_block(512, H)\n",
        "H=tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H=tf.keras.layers.Flatten()(H)\n",
        "H=tf.keras.layers.Dense(4096, activation='swish')(H)\n",
        "H=tf.keras.layers.Dense(4096, activation='swish')(H)\n",
        "H=tf.keras.layers.Dense(1000, activation='swish')(H)\n",
        "Y=tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model=tf.keras.Model(X,Y)\n",
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, metrics='accuracy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_27 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_129 (Conv2D)         (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_130 (Conv2D)         (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_74 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_131 (Conv2D)         (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_132 (Conv2D)         (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_75 (MaxPoolin  (None, 8, 8, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_133 (Conv2D)         (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 8, 8, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_134 (Conv2D)         (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 8, 8, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_76 (MaxPoolin  (None, 4, 4, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_135 (Conv2D)         (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_136 (Conv2D)         (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 4, 4, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_77 (MaxPoolin  (None, 2, 2, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 4096)              8392704   \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 1000)              4097000   \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,974,082\n",
            "Trainable params: 33,970,242\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIEb3M9gxCT3",
        "outputId": "f59340f2-d70b-488b-cc96-ee28b81da443"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 46s 140ms/step - loss: 1.7983 - accuracy: 0.3878 - val_loss: 1.5222 - val_accuracy: 0.4634\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 43s 139ms/step - loss: 1.0848 - accuracy: 0.6146 - val_loss: 1.3003 - val_accuracy: 0.5959\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 46s 145ms/step - loss: 0.8256 - accuracy: 0.7156 - val_loss: 0.8537 - val_accuracy: 0.7074\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 43s 139ms/step - loss: 0.6490 - accuracy: 0.7796 - val_loss: 1.0623 - val_accuracy: 0.6822\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 43s 139ms/step - loss: 0.5336 - accuracy: 0.8214 - val_loss: 0.7700 - val_accuracy: 0.7598\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 43s 139ms/step - loss: 0.4202 - accuracy: 0.8592 - val_loss: 0.6788 - val_accuracy: 0.7817\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 43s 138ms/step - loss: 0.3466 - accuracy: 0.8862 - val_loss: 0.6522 - val_accuracy: 0.7861\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 43s 138ms/step - loss: 0.4610 - accuracy: 0.8549 - val_loss: 1.4620 - val_accuracy: 0.5731\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 43s 138ms/step - loss: 0.3701 - accuracy: 0.8796 - val_loss: 0.6539 - val_accuracy: 0.8066\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 43s 138ms/step - loss: 0.2126 - accuracy: 0.9297 - val_loss: 0.6160 - val_accuracy: 0.8242\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f794a070c10>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80xtUAPR5RV1"
      },
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMpBGl6qxSD4"
      },
      "source": [
        "def residual_block(f_in, f_out, x):\n",
        "    net = tf.keras.layers.Conv2D(f_out // 4, kernel_size=1, padding=\"same\")(x)\n",
        "    net = tf.keras.layers.BatchNormalization()(net)\n",
        "    net = tf.keras.layers.Activation('swish')(net)\n",
        "\n",
        "    net = tf.keras.layers.Conv2D(f_out // 4, kernel_size=3, padding=\"same\")(net)\n",
        "    net = tf.keras.layers.BatchNormalization()(net)\n",
        "    net = tf.keras.layers.Activation('swish')(net)\n",
        "\n",
        "    net = tf.keras.layers.Conv2D(f_out, kernel_size=1, padding=\"same\")(net)\n",
        "    net = tf.keras.layers.BatchNormalization()(net)\n",
        "    if f_in == f_out:\n",
        "        net = tf.keras.layers.Add()([x, net])\n",
        "    net = tf.keras.layers.Activation('swish')(net)\n",
        "\n",
        "    return net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar0U3mpZ6Rwf",
        "outputId": "db2fae3b-21e0-4b3e-daf6-5d5e29e57e77"
      },
      "source": [
        "X = tf.keras.Input(shape=[32, 32, 3])\n",
        "\n",
        "H = tf.keras.layers.Conv2D(64, kernel_size=7, padding='same')(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "H = tf.keras.layers.MaxPool2D(pool_size=3)(H)\n",
        "\n",
        "H = residual_block(64, 256, H)\n",
        "for i in range(2):\n",
        "  H = residual_block(256, 256, H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = residual_block(256, 512, H)\n",
        "for i in range(7):\n",
        "  H = residual_block(512, 512, H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = residual_block(512, 1024, H)\n",
        "for i in range(35):\n",
        "  H = residual_block(1024, 1024, H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = residual_block(1024, 2048, H)\n",
        "for i in range(2):\n",
        "  H = residual_block(2048, 2048, H)\n",
        "# H = tf.keras.layers.GlobalAveragePooling2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(1000)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, \n",
        "              metrics='accuracy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_26\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_32 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_153 (Conv2D)            (None, 32, 32, 64)   9472        ['input_32[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 32, 32, 64)  256         ['conv2d_153[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_82 (MaxPooling2D  (None, 10, 10, 64)  0           ['activation_52[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)            (None, 10, 10, 64)   4160        ['max_pooling2d_82[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 10, 10, 64)  256         ['conv2d_154[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)            (None, 10, 10, 64)   36928       ['activation_53[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 10, 10, 64)  256         ['conv2d_155[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)            (None, 10, 10, 256)  16640       ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 10, 10, 256)  1024       ['conv2d_156[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 10, 10, 256)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)            (None, 10, 10, 64)   16448       ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 10, 10, 64)  256         ['conv2d_157[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_158 (Conv2D)            (None, 10, 10, 64)   36928       ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 10, 10, 64)  256         ['conv2d_158[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)            (None, 10, 10, 256)  16640       ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 10, 10, 256)  1024       ['conv2d_159[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 10, 10, 256)  0           ['activation_55[0][0]',          \n",
            "                                                                  'batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 10, 10, 256)  0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)            (None, 10, 10, 64)   16448       ['activation_58[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 10, 10, 64)  256         ['conv2d_160[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)            (None, 10, 10, 64)   36928       ['activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 10, 10, 64)  256         ['conv2d_161[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 10, 10, 64)   0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)            (None, 10, 10, 256)  16640       ['activation_60[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 10, 10, 256)  1024       ['conv2d_162[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 10, 10, 256)  0           ['activation_58[0][0]',          \n",
            "                                                                  'batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 10, 10, 256)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_83 (MaxPooling2D  (None, 5, 5, 256)   0           ['activation_61[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_163 (Conv2D)            (None, 5, 5, 128)    32896       ['max_pooling2d_83[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 5, 5, 128)   512         ['conv2d_163[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)            (None, 5, 5, 128)    147584      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 5, 5, 128)   512         ['conv2d_164[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)            (None, 5, 5, 512)    66048       ['activation_63[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 5, 5, 512)   2048        ['conv2d_165[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 5, 5, 512)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)            (None, 5, 5, 128)    65664       ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 5, 5, 128)   512         ['conv2d_166[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)            (None, 5, 5, 128)    147584      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 5, 5, 128)   512         ['conv2d_167[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_168 (Conv2D)            (None, 5, 5, 512)    66048       ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 5, 5, 512)   2048        ['conv2d_168[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 5, 5, 512)    0           ['activation_64[0][0]',          \n",
            "                                                                  'batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 5, 5, 512)    0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)            (None, 5, 5, 128)    65664       ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 5, 5, 128)   512         ['conv2d_169[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)            (None, 5, 5, 128)    147584      ['activation_68[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 5, 5, 128)   512         ['conv2d_170[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)            (None, 5, 5, 512)    66048       ['activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 5, 5, 512)   2048        ['conv2d_171[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 5, 5, 512)    0           ['activation_67[0][0]',          \n",
            "                                                                  'batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 5, 5, 512)    0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)            (None, 5, 5, 128)    65664       ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 5, 5, 128)   512         ['conv2d_172[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_173 (Conv2D)            (None, 5, 5, 128)    147584      ['activation_71[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 128)   512         ['conv2d_173[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)            (None, 5, 5, 512)    66048       ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 512)   2048        ['conv2d_174[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 5, 5, 512)    0           ['activation_70[0][0]',          \n",
            "                                                                  'batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 5, 5, 512)    0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)            (None, 5, 5, 128)    65664       ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 128)   512         ['conv2d_175[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 5, 5, 128)    147584      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 128)   512         ['conv2d_176[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 5, 5, 512)    66048       ['activation_75[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 512)   2048        ['conv2d_177[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 5, 5, 512)    0           ['activation_73[0][0]',          \n",
            "                                                                  'batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 512)    0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_178 (Conv2D)            (None, 5, 5, 128)    65664       ['activation_76[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 128)   512         ['conv2d_178[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)            (None, 5, 5, 128)    147584      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 128)   512         ['conv2d_179[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 5, 5, 512)    66048       ['activation_78[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 512)   2048        ['conv2d_180[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 5, 5, 512)    0           ['activation_76[0][0]',          \n",
            "                                                                  'batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 512)    0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 5, 5, 128)    65664       ['activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 128)   512         ['conv2d_181[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_182 (Conv2D)            (None, 5, 5, 128)    147584      ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 128)   512         ['conv2d_182[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_183 (Conv2D)            (None, 5, 5, 512)    66048       ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 512)   2048        ['conv2d_183[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 5, 5, 512)    0           ['activation_79[0][0]',          \n",
            "                                                                  'batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 512)    0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 5, 5, 128)    65664       ['activation_82[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 128)   512         ['conv2d_184[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 5, 5, 128)    147584      ['activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 128)   512         ['conv2d_185[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 128)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 5, 5, 512)    66048       ['activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 512)   2048        ['conv2d_186[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 5, 5, 512)    0           ['activation_82[0][0]',          \n",
            "                                                                  'batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 512)    0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_84 (MaxPooling2D  (None, 2, 2, 512)   0           ['activation_85[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 2, 2, 256)    131328      ['max_pooling2d_84[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_187[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_188 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_188[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_189 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_87[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_189[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 2, 2, 1024)   0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_190 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_190[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_191 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_94 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_191[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_94[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_192 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_95 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_192[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 2, 2, 1024)   0           ['activation_88[0][0]',          \n",
            "                                                                  'batch_normalization_95[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 2, 2, 1024)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_193 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_91[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_96 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_193[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_96[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_194 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_97 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_194[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_97[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_195 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_98 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_195[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 2, 2, 1024)   0           ['activation_91[0][0]',          \n",
            "                                                                  'batch_normalization_98[0][0]'] \n",
            "                                                                                                  \n",
            " activation_94 (Activation)     (None, 2, 2, 1024)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_196 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_94[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_99 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_196[0][0]']             \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_95 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_99[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_197 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_95[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 2, 2, 256)   1024        ['conv2d_197[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_96 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_198 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_96[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_198[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 2, 2, 1024)   0           ['activation_94[0][0]',          \n",
            "                                                                  'batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " activation_97 (Activation)     (None, 2, 2, 1024)   0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_199 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_97[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 2, 2, 256)   1024        ['conv2d_199[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_98 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_200 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_98[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 2, 2, 256)   1024        ['conv2d_200[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_99 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_201 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_99[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_201[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 2, 2, 1024)   0           ['activation_97[0][0]',          \n",
            "                                                                  'batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 2, 2, 1024)   0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_202 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 2, 2, 256)   1024        ['conv2d_202[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_101[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 2, 2, 256)   1024        ['conv2d_203[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_102[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_204[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 2, 2, 1024)   0           ['activation_100[0][0]',         \n",
            "                                                                  'batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 2, 2, 1024)   0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 2, 2, 256)   1024        ['conv2d_205[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_104[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 2, 2, 256)   1024        ['conv2d_206[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_105[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_207[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_18 (Add)                   (None, 2, 2, 1024)   0           ['activation_103[0][0]',         \n",
            "                                                                  'batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 2, 2, 1024)   0           ['add_18[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_106[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 2, 2, 256)   1024        ['conv2d_208[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_209 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 2, 2, 256)   1024        ['conv2d_209[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_210 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_108[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_210[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_19 (Add)                   (None, 2, 2, 1024)   0           ['activation_106[0][0]',         \n",
            "                                                                  'batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 2, 2, 1024)   0           ['add_19[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_211 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_109[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 2, 2, 256)   1024        ['conv2d_211[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_212 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_110[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 2, 2, 256)   1024        ['conv2d_212[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_213 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_111[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_213[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_20 (Add)                   (None, 2, 2, 1024)   0           ['activation_109[0][0]',         \n",
            "                                                                  'batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 2, 2, 1024)   0           ['add_20[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_214 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_112[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_117 (Batch  (None, 2, 2, 256)   1024        ['conv2d_214[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_215 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_113[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_118 (Batch  (None, 2, 2, 256)   1024        ['conv2d_215[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_216 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_114[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_119 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_216[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_21 (Add)                   (None, 2, 2, 1024)   0           ['activation_112[0][0]',         \n",
            "                                                                  'batch_normalization_119[0][0]']\n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 2, 2, 1024)   0           ['add_21[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_217 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_115[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_120 (Batch  (None, 2, 2, 256)   1024        ['conv2d_217[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_218 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_116[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_121 (Batch  (None, 2, 2, 256)   1024        ['conv2d_218[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_117 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_219 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_117[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_122 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_219[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_22 (Add)                   (None, 2, 2, 1024)   0           ['activation_115[0][0]',         \n",
            "                                                                  'batch_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " activation_118 (Activation)    (None, 2, 2, 1024)   0           ['add_22[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_220 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_118[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_123 (Batch  (None, 2, 2, 256)   1024        ['conv2d_220[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_119 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_221 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_119[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_124 (Batch  (None, 2, 2, 256)   1024        ['conv2d_221[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_120 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_222 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_120[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_125 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_222[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_23 (Add)                   (None, 2, 2, 1024)   0           ['activation_118[0][0]',         \n",
            "                                                                  'batch_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " activation_121 (Activation)    (None, 2, 2, 1024)   0           ['add_23[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_223 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_121[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_126 (Batch  (None, 2, 2, 256)   1024        ['conv2d_223[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_122 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_126[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_224 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_122[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_127 (Batch  (None, 2, 2, 256)   1024        ['conv2d_224[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_123 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_127[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_225 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_123[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_128 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_225[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_24 (Add)                   (None, 2, 2, 1024)   0           ['activation_121[0][0]',         \n",
            "                                                                  'batch_normalization_128[0][0]']\n",
            "                                                                                                  \n",
            " activation_124 (Activation)    (None, 2, 2, 1024)   0           ['add_24[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_226 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_124[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_129 (Batch  (None, 2, 2, 256)   1024        ['conv2d_226[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_125 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_129[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_227 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_125[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_130 (Batch  (None, 2, 2, 256)   1024        ['conv2d_227[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_126 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_130[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_228 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_126[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_131 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_228[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_25 (Add)                   (None, 2, 2, 1024)   0           ['activation_124[0][0]',         \n",
            "                                                                  'batch_normalization_131[0][0]']\n",
            "                                                                                                  \n",
            " activation_127 (Activation)    (None, 2, 2, 1024)   0           ['add_25[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_229 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_127[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_132 (Batch  (None, 2, 2, 256)   1024        ['conv2d_229[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_128 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_132[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_230 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_128[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_133 (Batch  (None, 2, 2, 256)   1024        ['conv2d_230[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_129 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_133[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_231 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_129[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_134 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_231[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_26 (Add)                   (None, 2, 2, 1024)   0           ['activation_127[0][0]',         \n",
            "                                                                  'batch_normalization_134[0][0]']\n",
            "                                                                                                  \n",
            " activation_130 (Activation)    (None, 2, 2, 1024)   0           ['add_26[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_232 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_130[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_135 (Batch  (None, 2, 2, 256)   1024        ['conv2d_232[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_131 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_135[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_233 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_131[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_136 (Batch  (None, 2, 2, 256)   1024        ['conv2d_233[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_132 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_136[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_234 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_132[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_137 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_234[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_27 (Add)                   (None, 2, 2, 1024)   0           ['activation_130[0][0]',         \n",
            "                                                                  'batch_normalization_137[0][0]']\n",
            "                                                                                                  \n",
            " activation_133 (Activation)    (None, 2, 2, 1024)   0           ['add_27[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_235 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_133[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_138 (Batch  (None, 2, 2, 256)   1024        ['conv2d_235[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_134 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_138[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_236 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_134[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_139 (Batch  (None, 2, 2, 256)   1024        ['conv2d_236[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_135 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_139[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_237 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_135[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_140 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_237[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_28 (Add)                   (None, 2, 2, 1024)   0           ['activation_133[0][0]',         \n",
            "                                                                  'batch_normalization_140[0][0]']\n",
            "                                                                                                  \n",
            " activation_136 (Activation)    (None, 2, 2, 1024)   0           ['add_28[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_238 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_136[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_141 (Batch  (None, 2, 2, 256)   1024        ['conv2d_238[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_137 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_141[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_239 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_137[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_142 (Batch  (None, 2, 2, 256)   1024        ['conv2d_239[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_138 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_142[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_240 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_138[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_143 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_240[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_29 (Add)                   (None, 2, 2, 1024)   0           ['activation_136[0][0]',         \n",
            "                                                                  'batch_normalization_143[0][0]']\n",
            "                                                                                                  \n",
            " activation_139 (Activation)    (None, 2, 2, 1024)   0           ['add_29[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_241 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_139[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_144 (Batch  (None, 2, 2, 256)   1024        ['conv2d_241[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_140 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_144[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_242 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_140[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_145 (Batch  (None, 2, 2, 256)   1024        ['conv2d_242[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_141 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_145[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_243 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_141[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_146 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_243[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_30 (Add)                   (None, 2, 2, 1024)   0           ['activation_139[0][0]',         \n",
            "                                                                  'batch_normalization_146[0][0]']\n",
            "                                                                                                  \n",
            " activation_142 (Activation)    (None, 2, 2, 1024)   0           ['add_30[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_244 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_142[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_147 (Batch  (None, 2, 2, 256)   1024        ['conv2d_244[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_143 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_147[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_245 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_143[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_148 (Batch  (None, 2, 2, 256)   1024        ['conv2d_245[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_144 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_148[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_246 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_144[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_149 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_246[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_31 (Add)                   (None, 2, 2, 1024)   0           ['activation_142[0][0]',         \n",
            "                                                                  'batch_normalization_149[0][0]']\n",
            "                                                                                                  \n",
            " activation_145 (Activation)    (None, 2, 2, 1024)   0           ['add_31[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_247 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_145[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_150 (Batch  (None, 2, 2, 256)   1024        ['conv2d_247[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_146 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_150[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_248 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_146[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_151 (Batch  (None, 2, 2, 256)   1024        ['conv2d_248[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_147 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_151[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_249 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_147[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_152 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_249[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_32 (Add)                   (None, 2, 2, 1024)   0           ['activation_145[0][0]',         \n",
            "                                                                  'batch_normalization_152[0][0]']\n",
            "                                                                                                  \n",
            " activation_148 (Activation)    (None, 2, 2, 1024)   0           ['add_32[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_250 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_148[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_153 (Batch  (None, 2, 2, 256)   1024        ['conv2d_250[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_149 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_153[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_251 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_149[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_154 (Batch  (None, 2, 2, 256)   1024        ['conv2d_251[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_150 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_154[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_252 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_150[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_155 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_252[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_33 (Add)                   (None, 2, 2, 1024)   0           ['activation_148[0][0]',         \n",
            "                                                                  'batch_normalization_155[0][0]']\n",
            "                                                                                                  \n",
            " activation_151 (Activation)    (None, 2, 2, 1024)   0           ['add_33[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_253 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_151[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_156 (Batch  (None, 2, 2, 256)   1024        ['conv2d_253[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_152 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_156[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_254 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_152[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_157 (Batch  (None, 2, 2, 256)   1024        ['conv2d_254[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_153 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_157[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_255 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_153[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_158 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_255[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_34 (Add)                   (None, 2, 2, 1024)   0           ['activation_151[0][0]',         \n",
            "                                                                  'batch_normalization_158[0][0]']\n",
            "                                                                                                  \n",
            " activation_154 (Activation)    (None, 2, 2, 1024)   0           ['add_34[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_256 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_154[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_159 (Batch  (None, 2, 2, 256)   1024        ['conv2d_256[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_155 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_159[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_257 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_155[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 2, 2, 256)   1024        ['conv2d_257[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_156 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_160[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_258 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_156[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_258[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_35 (Add)                   (None, 2, 2, 1024)   0           ['activation_154[0][0]',         \n",
            "                                                                  'batch_normalization_161[0][0]']\n",
            "                                                                                                  \n",
            " activation_157 (Activation)    (None, 2, 2, 1024)   0           ['add_35[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_259 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_157[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (None, 2, 2, 256)   1024        ['conv2d_259[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_158 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_260 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_158[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (None, 2, 2, 256)   1024        ['conv2d_260[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_159 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_261 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_159[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_164 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_261[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_36 (Add)                   (None, 2, 2, 1024)   0           ['activation_157[0][0]',         \n",
            "                                                                  'batch_normalization_164[0][0]']\n",
            "                                                                                                  \n",
            " activation_160 (Activation)    (None, 2, 2, 1024)   0           ['add_36[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_262 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_160[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_165 (Batch  (None, 2, 2, 256)   1024        ['conv2d_262[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_161 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_165[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_263 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_161[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_166 (Batch  (None, 2, 2, 256)   1024        ['conv2d_263[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_162 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_166[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_264 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_162[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_167 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_264[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_37 (Add)                   (None, 2, 2, 1024)   0           ['activation_160[0][0]',         \n",
            "                                                                  'batch_normalization_167[0][0]']\n",
            "                                                                                                  \n",
            " activation_163 (Activation)    (None, 2, 2, 1024)   0           ['add_37[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_265 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_163[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_168 (Batch  (None, 2, 2, 256)   1024        ['conv2d_265[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_164 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_168[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_266 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_164[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_169 (Batch  (None, 2, 2, 256)   1024        ['conv2d_266[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_165 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_169[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_267 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_165[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_170 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_267[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_38 (Add)                   (None, 2, 2, 1024)   0           ['activation_163[0][0]',         \n",
            "                                                                  'batch_normalization_170[0][0]']\n",
            "                                                                                                  \n",
            " activation_166 (Activation)    (None, 2, 2, 1024)   0           ['add_38[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_268 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_166[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_171 (Batch  (None, 2, 2, 256)   1024        ['conv2d_268[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_167 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_171[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_269 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_167[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_172 (Batch  (None, 2, 2, 256)   1024        ['conv2d_269[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_168 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_172[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_270 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_168[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_173 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_270[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_39 (Add)                   (None, 2, 2, 1024)   0           ['activation_166[0][0]',         \n",
            "                                                                  'batch_normalization_173[0][0]']\n",
            "                                                                                                  \n",
            " activation_169 (Activation)    (None, 2, 2, 1024)   0           ['add_39[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_271 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_169[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_174 (Batch  (None, 2, 2, 256)   1024        ['conv2d_271[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_170 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_174[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_272 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_170[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_175 (Batch  (None, 2, 2, 256)   1024        ['conv2d_272[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_171 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_175[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_273 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_171[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_176 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_273[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_40 (Add)                   (None, 2, 2, 1024)   0           ['activation_169[0][0]',         \n",
            "                                                                  'batch_normalization_176[0][0]']\n",
            "                                                                                                  \n",
            " activation_172 (Activation)    (None, 2, 2, 1024)   0           ['add_40[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_274 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_172[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_177 (Batch  (None, 2, 2, 256)   1024        ['conv2d_274[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_173 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_177[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_275 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_173[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_178 (Batch  (None, 2, 2, 256)   1024        ['conv2d_275[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_178[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_276 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_174[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_179 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_276[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_41 (Add)                   (None, 2, 2, 1024)   0           ['activation_172[0][0]',         \n",
            "                                                                  'batch_normalization_179[0][0]']\n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 2, 2, 1024)   0           ['add_41[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_277 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_175[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_180 (Batch  (None, 2, 2, 256)   1024        ['conv2d_277[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_176 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_180[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_278 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_176[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_181 (Batch  (None, 2, 2, 256)   1024        ['conv2d_278[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_177 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_181[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_279 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_182 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_279[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_42 (Add)                   (None, 2, 2, 1024)   0           ['activation_175[0][0]',         \n",
            "                                                                  'batch_normalization_182[0][0]']\n",
            "                                                                                                  \n",
            " activation_178 (Activation)    (None, 2, 2, 1024)   0           ['add_42[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_280 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_183 (Batch  (None, 2, 2, 256)   1024        ['conv2d_280[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_179 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_183[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_281 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_179[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_184 (Batch  (None, 2, 2, 256)   1024        ['conv2d_281[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_180 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_184[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_282 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_180[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_185 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_282[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_43 (Add)                   (None, 2, 2, 1024)   0           ['activation_178[0][0]',         \n",
            "                                                                  'batch_normalization_185[0][0]']\n",
            "                                                                                                  \n",
            " activation_181 (Activation)    (None, 2, 2, 1024)   0           ['add_43[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_283 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_181[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_186 (Batch  (None, 2, 2, 256)   1024        ['conv2d_283[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_182 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_186[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_284 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_182[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_187 (Batch  (None, 2, 2, 256)   1024        ['conv2d_284[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_183 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_187[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_285 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_183[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_188 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_285[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_44 (Add)                   (None, 2, 2, 1024)   0           ['activation_181[0][0]',         \n",
            "                                                                  'batch_normalization_188[0][0]']\n",
            "                                                                                                  \n",
            " activation_184 (Activation)    (None, 2, 2, 1024)   0           ['add_44[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_286 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_189 (Batch  (None, 2, 2, 256)   1024        ['conv2d_286[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_185 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_189[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_287 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_185[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_190 (Batch  (None, 2, 2, 256)   1024        ['conv2d_287[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_186 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_190[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_288 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_186[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_191 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_288[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_45 (Add)                   (None, 2, 2, 1024)   0           ['activation_184[0][0]',         \n",
            "                                                                  'batch_normalization_191[0][0]']\n",
            "                                                                                                  \n",
            " activation_187 (Activation)    (None, 2, 2, 1024)   0           ['add_45[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_289 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_187[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_192 (Batch  (None, 2, 2, 256)   1024        ['conv2d_289[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_188 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_192[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_290 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_188[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_193 (Batch  (None, 2, 2, 256)   1024        ['conv2d_290[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_189 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_193[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_291 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_189[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_194 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_291[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_46 (Add)                   (None, 2, 2, 1024)   0           ['activation_187[0][0]',         \n",
            "                                                                  'batch_normalization_194[0][0]']\n",
            "                                                                                                  \n",
            " activation_190 (Activation)    (None, 2, 2, 1024)   0           ['add_46[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_292 (Conv2D)            (None, 2, 2, 256)    262400      ['activation_190[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_195 (Batch  (None, 2, 2, 256)   1024        ['conv2d_292[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_191 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_195[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_293 (Conv2D)            (None, 2, 2, 256)    590080      ['activation_191[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_196 (Batch  (None, 2, 2, 256)   1024        ['conv2d_293[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_192 (Activation)    (None, 2, 2, 256)    0           ['batch_normalization_196[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_294 (Conv2D)            (None, 2, 2, 1024)   263168      ['activation_192[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_197 (Batch  (None, 2, 2, 1024)  4096        ['conv2d_294[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_47 (Add)                   (None, 2, 2, 1024)   0           ['activation_190[0][0]',         \n",
            "                                                                  'batch_normalization_197[0][0]']\n",
            "                                                                                                  \n",
            " activation_193 (Activation)    (None, 2, 2, 1024)   0           ['add_47[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_85 (MaxPooling2D  (None, 1, 1, 1024)  0           ['activation_193[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_295 (Conv2D)            (None, 1, 1, 512)    524800      ['max_pooling2d_85[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_198 (Batch  (None, 1, 1, 512)   2048        ['conv2d_295[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_194 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_198[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_296 (Conv2D)            (None, 1, 1, 512)    2359808     ['activation_194[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_199 (Batch  (None, 1, 1, 512)   2048        ['conv2d_296[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_195 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_199[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_297 (Conv2D)            (None, 1, 1, 2048)   1050624     ['activation_195[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_200 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_297[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_196 (Activation)    (None, 1, 1, 2048)   0           ['batch_normalization_200[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_298 (Conv2D)            (None, 1, 1, 512)    1049088     ['activation_196[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_201 (Batch  (None, 1, 1, 512)   2048        ['conv2d_298[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_197 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_201[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_299 (Conv2D)            (None, 1, 1, 512)    2359808     ['activation_197[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_202 (Batch  (None, 1, 1, 512)   2048        ['conv2d_299[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_198 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_202[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_300 (Conv2D)            (None, 1, 1, 2048)   1050624     ['activation_198[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_203 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_300[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_48 (Add)                   (None, 1, 1, 2048)   0           ['activation_196[0][0]',         \n",
            "                                                                  'batch_normalization_203[0][0]']\n",
            "                                                                                                  \n",
            " activation_199 (Activation)    (None, 1, 1, 2048)   0           ['add_48[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_301 (Conv2D)            (None, 1, 1, 512)    1049088     ['activation_199[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_204 (Batch  (None, 1, 1, 512)   2048        ['conv2d_301[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_200 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_204[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_302 (Conv2D)            (None, 1, 1, 512)    2359808     ['activation_200[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_205 (Batch  (None, 1, 1, 512)   2048        ['conv2d_302[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_201 (Activation)    (None, 1, 1, 512)    0           ['batch_normalization_205[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_303 (Conv2D)            (None, 1, 1, 2048)   1050624     ['activation_201[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_206 (Batch  (None, 1, 1, 2048)  8192        ['conv2d_303[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_49 (Add)                   (None, 1, 1, 2048)   0           ['activation_199[0][0]',         \n",
            "                                                                  'batch_normalization_206[0][0]']\n",
            "                                                                                                  \n",
            " activation_202 (Activation)    (None, 1, 1, 2048)   0           ['add_49[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten_26 (Flatten)           (None, 2048)         0           ['activation_202[0][0]']         \n",
            "                                                                                                  \n",
            " dense_64 (Dense)               (None, 1000)         2049000     ['flatten_26[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_207 (Batch  (None, 1000)        4000        ['dense_64[0][0]']               \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_203 (Activation)    (None, 1000)         0           ['batch_normalization_207[0][0]']\n",
            "                                                                                                  \n",
            " dense_65 (Dense)               (None, 10)           10010       ['activation_203[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 57,645,858\n",
            "Trainable params: 57,500,114\n",
            "Non-trainable params: 145,744\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "s4UWWa25-Z8f",
        "outputId": "27e9d3c1-5cda-47b0-97e7-9a2f9a8092fc"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 227s 467ms/step - loss: 2.3456 - accuracy: 0.1036 - val_loss: 2.3053 - val_accuracy: 0.0980\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 149s 476ms/step - loss: 2.2958 - accuracy: 0.1188 - val_loss: 5.3087 - val_accuracy: 0.1028\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 149s 477ms/step - loss: 1.9956 - accuracy: 0.2269 - val_loss: 2.5600 - val_accuracy: 0.1703\n",
            "Epoch 4/10\n",
            "  5/313 [..............................] - ETA: 2:07 - loss: 1.8525 - accuracy: 0.2703"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-92b37657f5bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \"\"\"\n\u001b[1;32m   1148\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}