{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day16~20 딥러닝 #1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZYbTTCPYOth6loorSFyfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futurebly/Web-AI/blob/main/Day16~20_%EB%94%A5%EB%9F%AC%EB%8B%9D_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYeBJ9g2HNBO"
      },
      "source": [
        "## 판다스로 데이터 확인\n",
        "- 레모네이드 : https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/lemonade.csv\n",
        "- 보스턴 : https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\n",
        "- 아이리스 : https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "VOe63mWI-FtG",
        "outputId": "d3d04312-c2ab-489a-c97e-969697992e11"
      },
      "source": [
        "import pandas as pd\n",
        "path = 'https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/lemonade.csv'\n",
        "lemon = pd.read_csv(path)\n",
        "print(lemon.shape)\n",
        "lemon.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>온도</th>\n",
              "      <th>판매량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   온도  판매량\n",
              "0  20   40\n",
              "1  21   42\n",
              "2  22   44\n",
              "3  23   46\n",
              "4  24   48"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNYVlFkMIhsH",
        "outputId": "45faeba5-18c9-44dd-cc8c-c43aa7f10287"
      },
      "source": [
        "독립 = lemon[['온도']]\n",
        "종속 = lemon[['판매량']]\n",
        "print(독립.shape, 종속.shape)\n",
        "print(독립.head(2))\n",
        "print(종속.head(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 1) (6, 1)\n",
            "   온도\n",
            "0  20\n",
            "1  21\n",
            "   판매량\n",
            "0   40\n",
            "1   42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "NynkPep5HpPb",
        "outputId": "f7508ae3-c6e7-4009-f238-322b38fda5df"
      },
      "source": [
        "import pandas as pd\n",
        "path = 'https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv'\n",
        "boston = pd.read_csv(path)\n",
        "print(boston.shape)\n",
        "boston.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(506, 14)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      crim    zn  indus  chas    nox  ...  tax  ptratio       b  lstat  medv\n",
              "0  0.00632  18.0   2.31     0  0.538  ...  296     15.3  396.90   4.98  24.0\n",
              "1  0.02731   0.0   7.07     0  0.469  ...  242     17.8  396.90   9.14  21.6\n",
              "2  0.02729   0.0   7.07     0  0.469  ...  242     17.8  392.83   4.03  34.7\n",
              "3  0.03237   0.0   2.18     0  0.458  ...  222     18.7  394.63   2.94  33.4\n",
              "4  0.06905   0.0   2.18     0  0.458  ...  222     18.7  396.90   5.33  36.2\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQC9mlzgJYU4",
        "outputId": "da54df9b-a1a8-4b9e-f120-031c81765309"
      },
      "source": [
        "boston.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
              "       'ptratio', 'b', 'lstat', 'medv'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liAHrfPqJd1r",
        "outputId": "1b0148c2-8f05-4d85-a17d-61ae8e63ba39"
      },
      "source": [
        "독립 = boston[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']] # 독립 = boston.drop(['medv'], axis=1\n",
        "종속 = boston[['medv']]\n",
        "print(독립.shape, 종속.shape)\n",
        "print(독립.head(2))\n",
        "print(종속.head(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(506, 13) (506, 1)\n",
            "      crim    zn  indus  chas    nox  ...  rad  tax  ptratio      b  lstat\n",
            "0  0.00632  18.0   2.31     0  0.538  ...    1  296     15.3  396.9   4.98\n",
            "1  0.02731   0.0   7.07     0  0.469  ...    2  242     17.8  396.9   9.14\n",
            "\n",
            "[2 rows x 13 columns]\n",
            "   medv\n",
            "0  24.0\n",
            "1  21.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "3cdvj_XgH60H",
        "outputId": "2ae60a2b-ca8f-4f32-d105-b9df96c09ecd"
      },
      "source": [
        "import pandas as pd\n",
        "path = 'https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv'\n",
        "iris = pd.read_csv(path)\n",
        "print(iris.shape)\n",
        "iris.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "      <th>품종</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭      품종\n",
              "0   5.1  3.5    1.4   0.2  setosa\n",
              "1   4.9  3.0    1.4   0.2  setosa\n",
              "2   4.7  3.2    1.3   0.2  setosa\n",
              "3   4.6  3.1    1.5   0.2  setosa\n",
              "4   5.0  3.6    1.4   0.2  setosa"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njXeTEM4IIJ4",
        "outputId": "f0d96c00-e4a1-44eb-81ae-c683c1ed2308"
      },
      "source": [
        "iris.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm18Sfv0KEka",
        "outputId": "3b090149-beca-4222-c586-b862d9879bb5"
      },
      "source": [
        "독립 = iris[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
        "종속 = iris[['품종']]\n",
        "print(독립.shape, 종속.shape)\n",
        "print(독립.head(2))\n",
        "print(종속.head(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4) (150, 1)\n",
            "   꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭\n",
            "0   5.1  3.5    1.4   0.2\n",
            "1   4.9  3.0    1.4   0.2\n",
            "       품종\n",
            "0  setosa\n",
            "1  setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjD2broZRKPz"
      },
      "source": [
        "## 첫번째 딥러닝 - 레모네이드 판매 예측\n",
        "- https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/lemonade.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBqibDIjKaNb",
        "outputId": "b3d0642e-2938-41ae-da6c-25c6be988746"
      },
      "source": [
        "#데이터를 준비한다\n",
        "import tensorflow as tf\n",
        "import pandas as ad\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/lemonade.csv'\n",
        "lemon = pd.read_csv(path)\n",
        "\n",
        "x_lemon = lemon[['온도']]\n",
        "y_lemon = lemon[['판매량']]\n",
        "print(x_lemon.shape, y_lemon.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 1) (6, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuXCoEZDRZG7"
      },
      "source": [
        "#모델을 생성한다\n",
        "X = tf.keras.layers.Input(shape=1)\n",
        "Y = tf.keras.layers.Dense(1)(X)\n",
        "model = tf.keras.models.Model(X, Y)\n",
        "model.compile(loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEziYV52RVBb",
        "outputId": "7f3a27d9-76ac-4057-e513-f55406b29763"
      },
      "source": [
        "#모델을 학습한다\n",
        "model.fit(x_lemon, y_lemon, epochs=1000, verbose=0) #verbose수다쟁이, 조용히 학습해라\n",
        "model.fit(x_lemon, y_lemon, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7070e-04\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7061e-04\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7051e-04\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7046e-04\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7038e-04\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7031e-04\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7018e-04\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7006e-04\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6993e-04\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6970e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd976a8d950>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDgffPdDRW1j",
        "outputId": "03163365-ac17-413c-8784-34abf767c064"
      },
      "source": [
        "#모델을 이용한다\n",
        "model.predict(x_lemon)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40.00704 ],\n",
              "       [41.99986 ],\n",
              "       [43.992676],\n",
              "       [45.985497],\n",
              "       [47.978313],\n",
              "       [49.971134]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZBvbSOCUzzQ",
        "outputId": "0bf5b9d7-d13b-444d-fdb3-db12c7697abd"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[1.9928187]], dtype=float32), array([0.15066382], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLgd8gHnVPpp"
      },
      "source": [
        "#판매량 = 0.9290964 * 온도 + 1.1820884"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySTw3yZ2Vqu4"
      },
      "source": [
        "#판매량 = 1.9928187 * 온도 + 0.15066382 #수천번 학습 후"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01wRPfKle6Z8"
      },
      "source": [
        "## 두번째 딥러닝 - 보스턴 집값 예측\n",
        "- https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhV3OXusWp08",
        "outputId": "526c5cff-814f-4555-eb7c-139134d5e90b"
      },
      "source": [
        "#데이터를 준비\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv'\n",
        "boston = pd.read_csv(path)\n",
        "boston.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
              "       'ptratio', 'b', 'lstat', 'medv'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M44RTk_fda0",
        "outputId": "ae4d618f-64e9-4384-f298-18a785b3f532"
      },
      "source": [
        "x_boston = boston[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
        "       'ptratio', 'b', 'lstat']]\n",
        "y_boston = boston[['medv']]\n",
        "print(x_boston.shape, y_boston.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(506, 13) (506, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r8dHV6hfDaP",
        "outputId": "5e1311d2-fae8-42fa-9c8d-55ce4bd8e70b"
      },
      "source": [
        "#모델을 생성\n",
        "X = tf.keras.layers.Input(shape=[13])\n",
        "Y = tf.keras.layers.Dense(1)(X)\n",
        "model = tf.keras.models.Model(X, Y)\n",
        "model.compile(loss='mse')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 13)]              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 14        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "pF40pabTgWgW",
        "outputId": "15147391-e74b-413e-982a-61408a1d5ff6"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oktOW6cCfFV3",
        "outputId": "5989efd2-1798-49a1-e7fd-403f725e88a7"
      },
      "source": [
        "#모델을 학습\n",
        "model.fit(x_boston, y_boston, epochs=1000, verbose=0)\n",
        "model.fit(x_boston, y_boston, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 24.2354\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 24.0446\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 24.4826\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 24.1318\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 24.8598\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 24.2489\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 24.2984\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 23.9615\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 24.0248\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 24.1233\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd9a5ede490>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CFGc32RfGln",
        "outputId": "4beedbc0-7c66-47f2-f959-baa5f56fb20f"
      },
      "source": [
        "#모델을 이용\n",
        "model.predict(x_boston[:5]) #slicing을 하기때메 []대괄호 한번"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.363287],\n",
              "       [25.123318],\n",
              "       [31.704601],\n",
              "       [30.372547],\n",
              "       [30.017658]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMSK4l90fH0t",
        "outputId": "cb8dda84-4921-44d2-8011-196022d9afc9"
      },
      "source": [
        "model.predict([[1,2,3,4,5,6,7,8,9,10,11,12,13]]) #직접 숫자를 넣을때는 [[]]대괄호 두번"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[37.18771]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdJTKEDoiAFh",
        "outputId": "1c45a770-e546-43e6-e853-e55c6ea65a98"
      },
      "source": [
        "model.predict([[1,2,3,4,5,6,7,8,9,10,11,12,13],\n",
        "               [1,2,3,4,5,6,7,8,9,10,11,12,23],\n",
        "               [1,2,3,4,5,6,7,8,9,10,11,12,33]\n",
        "               ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[37.18771 ],\n",
              "       [32.270042],\n",
              "       [27.352379]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFwUU44KikGU",
        "outputId": "6457b68e-daff-4438-c0ed-8d49ffcbf597"
      },
      "source": [
        "model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.09400858],\n",
              "        [ 0.04892354],\n",
              "        [-0.02681748],\n",
              "        [ 2.657233  ],\n",
              "        [ 0.08154692],\n",
              "        [ 5.3763504 ],\n",
              "        [-0.01083029],\n",
              "        [-1.0144763 ],\n",
              "        [ 0.18967697],\n",
              "        [-0.00980105],\n",
              "        [-0.4688538 ],\n",
              "        [ 0.01444097],\n",
              "        [-0.4578764 ]], dtype=float32), array([5.440677], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyVVMQ-NjRB3",
        "outputId": "3f3368f0-b525-4155-ea4a-7607a0c9b8bf"
      },
      "source": [
        "boston.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
              "       'ptratio', 'b', 'lstat', 'medv'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkSQEp46o-zX"
      },
      "source": [
        "## 세번째 딥러닝 - 아이리스 품종 분류\n",
        "- https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN8wt9XMjUhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cb88530-0013-4596-cb8f-d3d4a56f0a89"
      },
      "source": [
        "# 데이터를 준비\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv'\n",
        "iris = pd.read_csv(path)\n",
        "iris = pd.get_dummies(iris)\n",
        "iris.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종_setosa', '품종_versicolor',\n",
              "       '품종_virginica'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKBFanPgOacF",
        "outputId": "43c55fbd-0858-4d87-b4d9-37108717a28b"
      },
      "source": [
        "x_iris = iris[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
        "y_iris = iris[['품종_setosa', '품종_versicolor', '품종_virginica']]\n",
        "\n",
        "print(x_iris.shape, y_iris.shape)\n",
        "print(x_iris.head(1))\n",
        "print(y_iris.head(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4) (150, 3)\n",
            "   꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭\n",
            "0   5.1  3.5    1.4   0.2\n",
            "   품종_setosa  품종_versicolor  품종_virginica\n",
            "0          1              0             0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr8eZTtNN860"
      },
      "source": [
        "# 모델을 준비\n",
        "X = tf.keras.layers.Input(shape=[4])\n",
        "Y = tf.keras.layers.Dense(3, activation=\"softmax\")(X)\n",
        "model = tf.keras.models.Model(X, Y)\n",
        "model.compile(loss='categorical_crossentropy', metrics='accuracy') #loss만으로는 정확도 예측이 어렵기때메 accuracy 추가"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNJBQSQBN-qy",
        "outputId": "bf7d3eea-d949-4619-9bad-4771c4a34196"
      },
      "source": [
        "# 모델에 데이터 학습시키기\n",
        "model.fit(x_iris, y_iris, epochs=100, verbose=0)\n",
        "model.fit(x_iris, y_iris, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9800\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9800\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1446 - accuracy: 0.9867\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9867\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9800\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9800\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9733\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9800\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9800\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1437 - accuracy: 0.9800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe017fe8810>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_URzZ4xJOEJW"
      },
      "source": [
        "# 모델 이용\n",
        "sample = x_iris.sample(5)\n",
        "pred = model.predict(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FjVnAkm-RO9E",
        "outputId": "f673dc87-ed85-4d99-d7ef-4908d591bed4"
      },
      "source": [
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>6.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.3</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>6.0</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭\n",
              "36    5.5  3.5    1.3   0.2\n",
              "46    5.1  3.8    1.6   0.2\n",
              "139   6.9  3.1    5.4   2.1\n",
              "111   6.4  2.7    5.3   1.9\n",
              "62    6.0  2.2    4.0   1.0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZEc0u4kRlhz",
        "outputId": "af79b78e-23ea-4b97-97c6-f6bab49d6077"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9953294e-01, 4.6709625e-04, 4.3732111e-09],\n",
              "       [9.9962819e-01, 3.7182332e-04, 1.0233803e-08],\n",
              "       [6.3408368e-07, 2.4456643e-01, 7.5543290e-01],\n",
              "       [4.0790712e-07, 1.7586607e-01, 8.2413352e-01],\n",
              "       [6.5575691e-04, 9.4370979e-01, 5.5634450e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPQbIb-RU5uq",
        "outputId": "33365c1a-2584-46d7-c144-9f004a62a0c4"
      },
      "source": [
        "sample.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([36, 46, 139, 111, 62], dtype='int64')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1fSw76hNRnP3",
        "outputId": "82abc23d-83fa-4769-9808-bf53363b2d97"
      },
      "source": [
        "y_iris.loc[sample.index, :]\n",
        "#y_iris.loc[[36,46,139,111,62], :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>품종_setosa</th>\n",
              "      <th>품종_versicolor</th>\n",
              "      <th>품종_virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     품종_setosa  품종_versicolor  품종_virginica\n",
              "36           1              0             0\n",
              "46           1              0             0\n",
              "139          0              0             1\n",
              "111          0              0             1\n",
              "62           0              1             0"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5CKFtiORtNs",
        "outputId": "52af3c38-f013-49da-81f3-ffd53a5934ab"
      },
      "source": [
        "#수식 확인\n",
        "model.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.5954092 ,  0.76737475, -0.9241416 ],\n",
              "        [ 3.119437  , -0.12402771, -1.0467147 ],\n",
              "        [-3.4345782 , -0.72253436,  1.5391753 ],\n",
              "        [-5.233304  , -1.0891954 ,  1.7700865 ]], dtype=float32),\n",
              " array([ 2.3551364 ,  0.73846596, -1.8196614 ], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Fd1Os0SjpX"
      },
      "source": [
        "#setosa = 0.5954092*x1 + 3.119437*x2 + -3.4345782*x3 + -5.233304*x4 + 2.3551364\n",
        "#versicolor = \n",
        "#virginica = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_8aTYlbYv5p"
      },
      "source": [
        "## 네번째 딥러닝 - 히든레이어\n",
        "- https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\n",
        "-  https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiYvuVDeYvH9",
        "outputId": "89aad023-1ae8-4bc3-f00e-9d3907d82b79"
      },
      "source": [
        "# 데이터 준비\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "boston = pd.read_csv('https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv')\n",
        "print(boston.columns)\n",
        "x_boston = boston[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
        "       'ptratio', 'b', 'lstat']]\n",
        "y_boston = boston[['medv']]\n",
        "print(x_boston.shape, y_boston.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
            "       'ptratio', 'b', 'lstat', 'medv'],\n",
            "      dtype='object')\n",
            "(506, 13) (506, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK7kunLTf7FD",
        "outputId": "4e118cb3-16a2-4db6-fd41-01c3429814be"
      },
      "source": [
        "# 모델 준비\n",
        "X = tf.keras.layers.Input(shape=[13])\n",
        "H = tf.keras.layers.Dense(5, activation='swish')(X)\n",
        "H = tf.keras.layers.Dense(5, activation='swish')(H)\n",
        "H = tf.keras.layers.Dense(5, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(1)(H)\n",
        "model = tf.keras.models.Model(X, Y)\n",
        "model.compile(loss='mse')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 13)]              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 70        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 30        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 136\n",
            "Trainable params: 136\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqOralPOf8Jn",
        "outputId": "790cc90e-5285-4c8c-820e-70d4b23e9b6b"
      },
      "source": [
        "# 모델을 데이터로 학습\n",
        "model.fit(x_boston, y_boston, epochs=1000, verbose=0)\n",
        "model.fit(x_boston, y_boston, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.8274\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.3116\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 10.6637\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.5991\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 12.0477\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.5037\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 12.4697\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 11.3102\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 11.2978\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 11.1222\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe019318250>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "voL6rVhhf-GT",
        "outputId": "6109abf4-9278-4999-8214-b9d50a9587a1"
      },
      "source": [
        "# 모델을 이용\n",
        "sample = x_boston.sample(5)\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.04011</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.52</td>\n",
              "      <td>0</td>\n",
              "      <td>0.404</td>\n",
              "      <td>7.287</td>\n",
              "      <td>34.1</td>\n",
              "      <td>7.3090</td>\n",
              "      <td>2</td>\n",
              "      <td>329</td>\n",
              "      <td>12.6</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>7.99248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.700</td>\n",
              "      <td>5.520</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.5331</td>\n",
              "      <td>24</td>\n",
              "      <td>666</td>\n",
              "      <td>20.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>24.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>0.07896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.83</td>\n",
              "      <td>0</td>\n",
              "      <td>0.437</td>\n",
              "      <td>6.273</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.2515</td>\n",
              "      <td>5</td>\n",
              "      <td>398</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.92</td>\n",
              "      <td>6.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>15.57570</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.580</td>\n",
              "      <td>5.926</td>\n",
              "      <td>71.0</td>\n",
              "      <td>2.9084</td>\n",
              "      <td>24</td>\n",
              "      <td>666</td>\n",
              "      <td>20.2</td>\n",
              "      <td>368.74</td>\n",
              "      <td>18.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>0.30347</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.38</td>\n",
              "      <td>0</td>\n",
              "      <td>0.493</td>\n",
              "      <td>6.312</td>\n",
              "      <td>28.9</td>\n",
              "      <td>5.4159</td>\n",
              "      <td>5</td>\n",
              "      <td>287</td>\n",
              "      <td>19.6</td>\n",
              "      <td>396.90</td>\n",
              "      <td>6.15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         crim    zn  indus  chas    nox  ...  rad  tax  ptratio       b  lstat\n",
              "196   0.04011  80.0   1.52     0  0.404  ...    2  329     12.6  396.90   4.08\n",
              "383   7.99248   0.0  18.10     0  0.700  ...   24  666     20.2  396.90  24.56\n",
              "74    0.07896   0.0  12.83     0  0.437  ...    5  398     18.7  394.92   6.78\n",
              "468  15.57570   0.0  18.10     0  0.580  ...   24  666     20.2  368.74  18.13\n",
              "326   0.30347   0.0   7.38     0  0.493  ...    5  287     19.6  396.90   6.15\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "8xDKZ1-7o8yH",
        "outputId": "2f8ac6bd-47cb-410e-cc1b-d9c414f4723c"
      },
      "source": [
        "pred = model.predict(x_boston[:5])\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-80b64405954c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_boston\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_4\" is incompatible with the layer: expected shape=(None, 4), found shape=(None, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwqGJryYmMgs"
      },
      "source": [
        "### 아이리스 인공신경망\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAt5fMYQmVXB",
        "outputId": "78e1e6f8-7a61-4a57-e986-239bdf1c0fb1"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#데이터 준비\n",
        "iris = pd.read_csv('https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv')\n",
        "iris = pd.get_dummies(iris)\n",
        "print(iris.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종_setosa', '품종_versicolor',\n",
            "       '품종_virginica'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwcB9AAjmmxV",
        "outputId": "b171d430-8316-4855-f234-f368a8e8840d"
      },
      "source": [
        "x_iris = iris[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
        "y_iris = iris[['품종_setosa', '품종_versicolor', '품종_virginica']]\n",
        "print(x_iris.shape, y_iris.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 4) (150, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2eo3ugXmwQL",
        "outputId": "e43c51c7-be9b-45bf-b808-08201bf945d9"
      },
      "source": [
        "#모델 생성\n",
        "X = tf.keras.layers.Input(shape=[4])\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(X)\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(H)\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(3, activation='softmax')(H)\n",
        "model = tf.keras.models.Model(X, Y)\n",
        "model.compile(loss='categorical_crossentropy', metrics='accuracy')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 211\n",
            "Trainable params: 211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEIpicADnAaD",
        "outputId": "ec123c5a-5955-4831-ff87-fe35fcbc6596"
      },
      "source": [
        "#모델 학습\n",
        "model.fit(x_iris, y_iris, epochs=100, verbose=0)\n",
        "model.fit(x_iris, y_iris, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9733\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9533\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9733\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9600\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9667\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9733\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0907 - accuracy: 0.9600\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9667\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.9733\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe01918edd0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXofmRG1nz4N"
      },
      "source": [
        "#모델 이용\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiYppmER4aP8"
      },
      "source": [
        "## 딥러닝 예제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN52pAMk4Z5l"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_train = [[0,0],\n",
        "           [0,1],\n",
        "           [1,0],\n",
        "           [1,1]]\n",
        "y_train = [[0],\n",
        "           [0],\n",
        "           [0],\n",
        "           [1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJfBJPz9p4cv"
      },
      "source": [
        "X = tf.keras.layers.Input(shape=[2])\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(X)\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(H)\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(1, activation='sigmoid')(H)\n",
        "model = tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='binary_crossentropy', metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOpQKZ715DRf",
        "outputId": "433ec5b0-01fb-43a4-c3ae-d4589d458554"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=1000, verbose=0)\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4829 - accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4815 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4814 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe0151c5790>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uly3uuLfB8N"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x_train = [[0, 0], #AND\n",
        "           [0, 1],\n",
        "           [1, 0],\n",
        "           [1, 1]]\n",
        "y_train = [[0, 0],\n",
        "           [0, 1],\n",
        "           [0, 1],\n",
        "           [1, 1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFTbWYu8fJDH"
      },
      "source": [
        "X = tf.keras.layers.Input(shape=[2])\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(X)\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(H)\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(2, activation='sigmoid')(H)\n",
        "model = tf.keras.models.Model(X,Y)\n",
        "model.compile(loss='binary_crossentropy', metrics='binary_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmTioYBUfSfy",
        "outputId": "dc3efe4c-3ace-41ae-91bc-b0de8d548594"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=1000, verbose=0)\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0068 - binary_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0067 - binary_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0067 - binary_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0067 - binary_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0067 - binary_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0067 - binary_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1253aad990>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUWVNbRN66Kg"
      },
      "source": [
        "### 덧셈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5q4jrWE6Gfn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6b4111-f839-43cb-bb86-b229356096ef"
      },
      "source": [
        "# 데이터 준비하기\n",
        "x_input = [\n",
        "    [1, 2],\n",
        "    [1, 5],\n",
        "    [2, 2],\n",
        "    [2, 9],\n",
        "    [3, 1],\n",
        "    [3, 7],\n",
        "    [4, 3],\n",
        "    [4, 8],\n",
        "    [5, 8],\n",
        "    [5, 3],\n",
        "    [6, 5],\n",
        "    [6, 9],\n",
        "    [7, 3],\n",
        "    [7, 1],\n",
        "    [8, 5],\n",
        "    [8, 8],\n",
        "    [9, 4],\n",
        "    [9, 3],\n",
        "]\n",
        "y_label = [[sum(e)] for e in x_input]\n",
        "y_label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3],\n",
              " [6],\n",
              " [4],\n",
              " [11],\n",
              " [4],\n",
              " [10],\n",
              " [7],\n",
              " [12],\n",
              " [13],\n",
              " [8],\n",
              " [11],\n",
              " [15],\n",
              " [10],\n",
              " [8],\n",
              " [13],\n",
              " [16],\n",
              " [13],\n",
              " [12]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zZVJCTDiMLo"
      },
      "source": [
        "X = tf.keras.layers.Input(shape=[2])\n",
        "H = tf.keras.layers.Dense(8, activation=\"swish\")(X)\n",
        "H = tf.keras.layers.Dense(8, activation=\"swish\")(H)\n",
        "H = tf.keras.layers.Dense(8, activation=\"swish\")(H)\n",
        "Y = tf.keras.layers.Dense(1)(H)\n",
        "model = tf.keras.models.Model(X, Y)\n",
        "model.compile(loss=\"mse\", metrics=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY8ePi6SiOf_",
        "outputId": "516cc02d-9327-4f8d-a1d4-233bfdb31b67"
      },
      "source": [
        "model.fit(x_input, y_label, epochs=1000, verbose=0)\n",
        "model.fit(x_input, y_label, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f124e013a90>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N6rbwZmiTXP",
        "outputId": "0077c387-a756-4bdf-dab5-e37e6f8ffe66"
      },
      "source": [
        "model.predict([[12, 11]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.570374]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKcmNgmOj9c6"
      },
      "source": [
        "# 함수형의 의미\n",
        "- 절차형 프로그래밍 (C언어)\n",
        "- 객체지향형 프로그래밍 (C++, 자바) : 많은 사람이 협업이 가능하고 남의 코드 따다 오기 쉽게 됨\n",
        "- 함수형 프로그래밍 (C++, 자바도 발전했고 새로운 언어들 대부분 다 가능) : 다량의 데이터를 한꺼번에 다루기 시작하면서 탄생. 데이터를 그대로 두고 함수만 보낼 수 있게 됨. 병렬 구조가 가능. 연쇄 함수가 도입된 측면도 있음. => 데이터에 함수를 적용한다는 개념\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1a1llbbj8Hj",
        "outputId": "12b47ca0-b489-4b8f-bc91-900e1f0a4a1f"
      },
      "source": [
        "def add(a, b):\n",
        "  return a + b\n",
        "print(add(1,3))\n",
        "print(type(add))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "<class 'function'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sra_JSYNkhGN",
        "outputId": "516d13fd-a2da-4123-d448-393765b4356b"
      },
      "source": [
        "number = 1\n",
        "print(number)\n",
        "print(type(number))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "<class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipw389KekkUY",
        "outputId": "1e02af9b-a4c0-4000-a6db-6e56e588f125"
      },
      "source": [
        "def add(a, b):\n",
        "  return a + b\n",
        "\n",
        "def minus(a, b):\n",
        "  return a - b\n",
        "\n",
        "def func(f, a, b):\n",
        "  return f(a, b)\n",
        "\n",
        "print(func(add, 3, 2))\n",
        "print(func(minus, 3, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0CbcEXPqvDk"
      },
      "source": [
        "# lambda 함수\n",
        "- 이름 없이 간단한 함수를 만든다. 익명 함수."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo9sxl2mlQqS",
        "outputId": "46ade947-cd6a-4771-82d4-af324297e592"
      },
      "source": [
        "# lambda 1\n",
        "\n",
        "add = lambda a, b: a + b\n",
        "minus = lambda a, b: a - b\n",
        "def func(f, a, b):\n",
        "  return f(a, b)\n",
        "\n",
        "print(func(add, 3, 2))\n",
        "print(func(minus, 3, 2))\n",
        "\n",
        "print(func(lambda a, b: a* b, 3, 2))\n",
        "print(func(lambda a, b: a / b, 3, 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "1\n",
            "6\n",
            "1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnNeL8tIl7p6",
        "outputId": "e8cd2b2f-002f-42cc-ff19-23e75917c159"
      },
      "source": [
        "# lambda 2\n",
        "\n",
        "def get_func(what='add'):\n",
        "  if what == 'minus':\n",
        "    return lambda a, b: a - b\n",
        " \n",
        "  return lambda a, b : a + b\n",
        "\n",
        "print(get_func('add')(1,3))\n",
        "print(get_func('minus')(1,3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7VCP2h0nSEr",
        "outputId": "2d7b79dd-7055-4c59-8fab-eb67f2e1848f"
      },
      "source": [
        "print(get_func('mult')(1,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJDwxXxOnnRO",
        "outputId": "5d7b8b86-7fe5-400e-f530-f28f42df57ea"
      },
      "source": [
        "a = 'abac'\n",
        "print(dir(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__add__', '__class__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mod__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmod__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'capitalize', 'casefold', 'center', 'count', 'encode', 'endswith', 'expandtabs', 'find', 'format', 'format_map', 'index', 'isalnum', 'isalpha', 'isascii', 'isdecimal', 'isdigit', 'isidentifier', 'islower', 'isnumeric', 'isprintable', 'isspace', 'istitle', 'isupper', 'join', 'ljust', 'lower', 'lstrip', 'maketrans', 'partition', 'replace', 'rfind', 'rindex', 'rjust', 'rpartition', 'rsplit', 'rstrip', 'split', 'splitlines', 'startswith', 'strip', 'swapcase', 'title', 'translate', 'upper', 'zfill']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMM8z-sOrfjQ",
        "outputId": "854f26c5-9544-4039-b976-cb7c3fce1e39"
      },
      "source": [
        "b = [1,2,3]\n",
        "print(dir(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__add__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf12tV0iuWBa",
        "outputId": "abec3191-13a1-405e-dc60-4151d8793702"
      },
      "source": [
        "print(a.count('a'))\n",
        "print(b.count(1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jjA27CcrnTh",
        "outputId": "aa85afd7-a42c-4507-c306-513471c6c7b4"
      },
      "source": [
        "users = [\n",
        "    ['이숙번', 70, 80, 90],\n",
        "    ['이고잉', 82, 85, 83],\n",
        "    ['강두루', 56, 91, 90],\n",
        "]\n",
        "\n",
        "sorted(users, key=lambda x: sum(x[1:]), reverse=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['이고잉', 82, 85, 83], ['이숙번', 70, 80, 90], ['강두루', 56, 91, 90]]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTsMCN1uvKC1"
      },
      "source": [
        "# 딥러닝 # 02"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWGYJU8vvHtQ"
      },
      "source": [
        "# 보스턴 집값 예측 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuNN9eJTuTaf",
        "outputId": "77a51ab7-9442-43e4-bb84-620eb4a3e214"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "boston = pd.read_csv('https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv')\n",
        "print(boston.columns)\n",
        "x_boston = boston.drop(['medv'], axis=1)\n",
        "y_boston = boston[['medv']]\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
            "       'ptratio', 'b', 'lstat', 'medv'],\n",
            "      dtype='object')\n",
            "(400, 13) (400, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH8cM4xOwzFh"
      },
      "source": [
        "X = tf.keras.Input(shape=[13])\n",
        "H = tf.keras.layers.Dense(8, activation='swish')(X)\n",
        "Y = tf.keras.layers.Dense(1)(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='mse')\n",
        "\n",
        "\n",
        "# X = tf.keras.layers.Input(shape=[13])\n",
        "# H = tf.keras.layers.Dense(8, activation=tf.keras.activations.)(X)\n",
        "# Y = tf.keras.layers.Dense(1)(H)\n",
        "\n",
        "# model = tf.keras.models.Model(X, Y)\n",
        "# model.compile(loss=tf.keras.losses.mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR4jDowa0-5X",
        "outputId": "712b66ac-ac35-4019-be0b-850b208490bf"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 2ms/step - loss: 4282.4980\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1361.2657\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 804.6667\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 496.1468\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 295.2938\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 195.9659\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 165.5000\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 146.2592\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 135.5525\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 125.1962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12461a74d0>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw2SVPRa1qy_",
        "outputId": "c5ffb4fe-5368-4d56-b1a5-378a3a3d0589"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.MSE)\n",
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 376.7414\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 225.5289\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 179.2685\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 161.4532\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 145.9648\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 132.4031\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 127.7988\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 112.9351\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 108.2488\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 96.8570\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12533098d0>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg7tIiU72yR2",
        "outputId": "f932c4ad-2091-4e7b-cca0-41d4fcf4e5c3"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 92.0813\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 85.2191\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 80.1986\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 75.8351\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 72.0781\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 67.9802\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 67.8822\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 63.4464\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 60.9698\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 59.3958\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f124f0bb110>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1FdAmfW4e4x"
      },
      "source": [
        "### Train / Validation / Test\n",
        "- train : 학습용\n",
        "- validation : 모의고사용\n",
        "- test : 최종면접\n",
        "\n",
        "보통 7:1:2 정도로 나눔"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-iOGT-w4qta",
        "outputId": "f080d857-080b-42c6-a386-b8aaf6cad43c"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_qSj2Zt45Vy",
        "outputId": "abedaca7-9cbe-4011-bd14-1eedaefa8d6a"
      },
      "source": [
        "x_train, x_test = x_boston[:400], x_boston[400:]\n",
        "y_train, y_test = y_boston[:400], y_boston[400:]\n",
        "print(x_train.shape, x_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 13) (106, 13)\n",
            "(400, 1) (106, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OefbuTMr5Gao",
        "outputId": "acf45468-228a-46a2-fe0d-0a2a34547ad5"
      },
      "source": [
        "result = model.fit(x_train, y_train, epochs=500, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "10/10 [==============================] - 0s 22ms/step - loss: 105.7942 - val_loss: 238.1550\n",
            "Epoch 2/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 91.3651 - val_loss: 292.8460\n",
            "Epoch 3/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 79.9425 - val_loss: 473.5901\n",
            "Epoch 4/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 79.5462 - val_loss: 448.3982\n",
            "Epoch 5/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 72.9154 - val_loss: 734.8892\n",
            "Epoch 6/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 65.4494 - val_loss: 789.5706\n",
            "Epoch 7/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 61.6778 - val_loss: 619.4666\n",
            "Epoch 8/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 62.0622 - val_loss: 695.7260\n",
            "Epoch 9/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 58.8689 - val_loss: 1018.8662\n",
            "Epoch 10/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 54.0085 - val_loss: 1002.0705\n",
            "Epoch 11/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 55.3001 - val_loss: 839.1996\n",
            "Epoch 12/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 50.7640 - val_loss: 863.1906\n",
            "Epoch 13/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 52.5165 - val_loss: 1149.1592\n",
            "Epoch 14/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 46.3490 - val_loss: 936.5316\n",
            "Epoch 15/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 46.9430 - val_loss: 1117.2819\n",
            "Epoch 16/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 46.9425 - val_loss: 1214.5668\n",
            "Epoch 17/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 42.6672 - val_loss: 1218.0267\n",
            "Epoch 18/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 47.8426 - val_loss: 1080.8562\n",
            "Epoch 19/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 42.6909 - val_loss: 1123.0801\n",
            "Epoch 20/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 42.8533 - val_loss: 1152.7858\n",
            "Epoch 21/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 43.6294 - val_loss: 1278.5699\n",
            "Epoch 22/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 37.0654 - val_loss: 1670.6152\n",
            "Epoch 23/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 44.5905 - val_loss: 1164.0781\n",
            "Epoch 24/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 38.0319 - val_loss: 962.3224\n",
            "Epoch 25/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 41.0364 - val_loss: 1206.8552\n",
            "Epoch 26/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 38.2951 - val_loss: 1424.1709\n",
            "Epoch 27/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 39.8249 - val_loss: 970.2073\n",
            "Epoch 28/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 39.2576 - val_loss: 1258.5016\n",
            "Epoch 29/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 37.4849 - val_loss: 1192.5154\n",
            "Epoch 30/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 39.3679 - val_loss: 1090.2999\n",
            "Epoch 31/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 39.9310 - val_loss: 1174.2780\n",
            "Epoch 32/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 34.0509 - val_loss: 1312.4525\n",
            "Epoch 33/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 39.3000 - val_loss: 1489.6798\n",
            "Epoch 34/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 34.9191 - val_loss: 1274.9447\n",
            "Epoch 35/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 35.6626 - val_loss: 1274.0330\n",
            "Epoch 36/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 40.0088 - val_loss: 1255.4904\n",
            "Epoch 37/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 36.0597 - val_loss: 1145.3610\n",
            "Epoch 38/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 34.7071 - val_loss: 1390.6721\n",
            "Epoch 39/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 38.5186 - val_loss: 1320.2445\n",
            "Epoch 40/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 34.9672 - val_loss: 1162.7738\n",
            "Epoch 41/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 33.2222 - val_loss: 1304.9583\n",
            "Epoch 42/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 37.0208 - val_loss: 1430.7620\n",
            "Epoch 43/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 35.0385 - val_loss: 1218.7340\n",
            "Epoch 44/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 36.5721 - val_loss: 1466.7015\n",
            "Epoch 45/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.5358 - val_loss: 1531.5686\n",
            "Epoch 46/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 34.6861 - val_loss: 1347.9440\n",
            "Epoch 47/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 38.6535 - val_loss: 1438.5549\n",
            "Epoch 48/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 33.0691 - val_loss: 1426.0072\n",
            "Epoch 49/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 33.5877 - val_loss: 1715.3855\n",
            "Epoch 50/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 36.1269 - val_loss: 1382.6667\n",
            "Epoch 51/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 37.1955 - val_loss: 1267.3510\n",
            "Epoch 52/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 33.5394 - val_loss: 1257.7869\n",
            "Epoch 53/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 34.2140 - val_loss: 1207.2054\n",
            "Epoch 54/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 35.5495 - val_loss: 1119.8040\n",
            "Epoch 55/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 37.2452 - val_loss: 1392.7727\n",
            "Epoch 56/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 33.4489 - val_loss: 1294.1580\n",
            "Epoch 57/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.2734 - val_loss: 1604.7952\n",
            "Epoch 58/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 38.4837 - val_loss: 1462.0671\n",
            "Epoch 59/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 32.4359 - val_loss: 1544.2689\n",
            "Epoch 60/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 35.5125 - val_loss: 1483.9896\n",
            "Epoch 61/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.7299 - val_loss: 1480.0515\n",
            "Epoch 62/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.8592 - val_loss: 1554.4497\n",
            "Epoch 63/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 31.9891 - val_loss: 1595.2177\n",
            "Epoch 64/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 34.2114 - val_loss: 1504.3835\n",
            "Epoch 65/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 38.3534 - val_loss: 1497.0957\n",
            "Epoch 66/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.3837 - val_loss: 1482.3561\n",
            "Epoch 67/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 31.8533 - val_loss: 1438.5203\n",
            "Epoch 68/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 31.5995 - val_loss: 1491.2830\n",
            "Epoch 69/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.9925 - val_loss: 1422.0554\n",
            "Epoch 70/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.7628 - val_loss: 1467.2673\n",
            "Epoch 71/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 31.7517 - val_loss: 1552.2244\n",
            "Epoch 72/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 33.8372 - val_loss: 1457.1398\n",
            "Epoch 73/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.3618 - val_loss: 1379.7253\n",
            "Epoch 74/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.5407 - val_loss: 1378.9878\n",
            "Epoch 75/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.7262 - val_loss: 1669.7336\n",
            "Epoch 76/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.8720 - val_loss: 1679.9622\n",
            "Epoch 77/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.6531 - val_loss: 1285.1002\n",
            "Epoch 78/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 31.2124 - val_loss: 1522.5836\n",
            "Epoch 79/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.4007 - val_loss: 1881.6746\n",
            "Epoch 80/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.7769 - val_loss: 1573.0458\n",
            "Epoch 81/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 33.6583 - val_loss: 1890.0338\n",
            "Epoch 82/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 33.6926 - val_loss: 1703.7262\n",
            "Epoch 83/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.1625 - val_loss: 1624.8058\n",
            "Epoch 84/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 32.6228 - val_loss: 1646.9469\n",
            "Epoch 85/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 35.6957 - val_loss: 1721.5330\n",
            "Epoch 86/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.9819 - val_loss: 1552.4773\n",
            "Epoch 87/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.8171 - val_loss: 1539.4948\n",
            "Epoch 88/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 33.0029 - val_loss: 1616.1063\n",
            "Epoch 89/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 32.6728 - val_loss: 1651.2408\n",
            "Epoch 90/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.0346 - val_loss: 1596.9373\n",
            "Epoch 91/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 33.0092 - val_loss: 1580.8328\n",
            "Epoch 92/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.6552 - val_loss: 1625.4629\n",
            "Epoch 93/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.5338 - val_loss: 1604.3776\n",
            "Epoch 94/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.4119 - val_loss: 1473.4651\n",
            "Epoch 95/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.6594 - val_loss: 1398.1689\n",
            "Epoch 96/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.7286 - val_loss: 1743.8289\n",
            "Epoch 97/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 33.1478 - val_loss: 1824.3381\n",
            "Epoch 98/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 33.4970 - val_loss: 1758.2565\n",
            "Epoch 99/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.5594 - val_loss: 1600.3452\n",
            "Epoch 100/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 31.8590 - val_loss: 1535.8324\n",
            "Epoch 101/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.1766 - val_loss: 1626.3987\n",
            "Epoch 102/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 34.3135 - val_loss: 1506.9287\n",
            "Epoch 103/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.0082 - val_loss: 1602.5385\n",
            "Epoch 104/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 29.8376 - val_loss: 1717.4469\n",
            "Epoch 105/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 34.8561 - val_loss: 1633.5663\n",
            "Epoch 106/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.2965 - val_loss: 1842.0645\n",
            "Epoch 107/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 28.6861 - val_loss: 1753.5856\n",
            "Epoch 108/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 28.6984 - val_loss: 1974.1410\n",
            "Epoch 109/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 32.7314 - val_loss: 1841.8119\n",
            "Epoch 110/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 35.0499 - val_loss: 1721.6931\n",
            "Epoch 111/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.7073 - val_loss: 1662.8604\n",
            "Epoch 112/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 32.6929 - val_loss: 1913.9938\n",
            "Epoch 113/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.0289 - val_loss: 1588.1428\n",
            "Epoch 114/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 28.6006 - val_loss: 1587.8044\n",
            "Epoch 115/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 34.9152 - val_loss: 1850.8918\n",
            "Epoch 116/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.9948 - val_loss: 1901.2102\n",
            "Epoch 117/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.9085 - val_loss: 2016.5403\n",
            "Epoch 118/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.9331 - val_loss: 1738.8861\n",
            "Epoch 119/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.0857 - val_loss: 1597.6395\n",
            "Epoch 120/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 32.8425 - val_loss: 1712.1859\n",
            "Epoch 121/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.9419 - val_loss: 1894.0328\n",
            "Epoch 122/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 30.2498 - val_loss: 1821.0804\n",
            "Epoch 123/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.1796 - val_loss: 1684.5029\n",
            "Epoch 124/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 31.1493 - val_loss: 1935.0664\n",
            "Epoch 125/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.8288 - val_loss: 1613.9207\n",
            "Epoch 126/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 36.3984 - val_loss: 1645.5452\n",
            "Epoch 127/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.3306 - val_loss: 1621.7773\n",
            "Epoch 128/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.2437 - val_loss: 1813.9609\n",
            "Epoch 129/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.0097 - val_loss: 1850.7676\n",
            "Epoch 130/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.3760 - val_loss: 1504.4592\n",
            "Epoch 131/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.5761 - val_loss: 1573.3170\n",
            "Epoch 132/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 32.8886 - val_loss: 1678.7102\n",
            "Epoch 133/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.9520 - val_loss: 1705.4938\n",
            "Epoch 134/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.2186 - val_loss: 2063.3015\n",
            "Epoch 135/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.9978 - val_loss: 1771.3402\n",
            "Epoch 136/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.5051 - val_loss: 1851.4531\n",
            "Epoch 137/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 31.7644 - val_loss: 1776.3428\n",
            "Epoch 138/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.6224 - val_loss: 1981.5287\n",
            "Epoch 139/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.6367 - val_loss: 1781.2820\n",
            "Epoch 140/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.1476 - val_loss: 1881.0746\n",
            "Epoch 141/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.9536 - val_loss: 1899.6277\n",
            "Epoch 142/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.5260 - val_loss: 1953.6143\n",
            "Epoch 143/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.1034 - val_loss: 1639.5865\n",
            "Epoch 144/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.6610 - val_loss: 1727.4410\n",
            "Epoch 145/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.1608 - val_loss: 1808.3328\n",
            "Epoch 146/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.4019 - val_loss: 1846.6975\n",
            "Epoch 147/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.9741 - val_loss: 1765.6149\n",
            "Epoch 148/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.4978 - val_loss: 2035.7605\n",
            "Epoch 149/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 32.9426 - val_loss: 1917.9551\n",
            "Epoch 150/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.1623 - val_loss: 1860.1211\n",
            "Epoch 151/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 31.4582 - val_loss: 1813.5078\n",
            "Epoch 152/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.0590 - val_loss: 1832.9248\n",
            "Epoch 153/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.4576 - val_loss: 1743.7230\n",
            "Epoch 154/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 30.4557 - val_loss: 1799.3519\n",
            "Epoch 155/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.5677 - val_loss: 1770.5270\n",
            "Epoch 156/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 33.4850 - val_loss: 1909.3076\n",
            "Epoch 157/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.3829 - val_loss: 1970.0336\n",
            "Epoch 158/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.0453 - val_loss: 1706.8811\n",
            "Epoch 159/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.0923 - val_loss: 1969.8871\n",
            "Epoch 160/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.5105 - val_loss: 1949.5000\n",
            "Epoch 161/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 31.9254 - val_loss: 1948.8691\n",
            "Epoch 162/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.1557 - val_loss: 1855.4270\n",
            "Epoch 163/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 26.1268 - val_loss: 2056.3772\n",
            "Epoch 164/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 30.7576 - val_loss: 2092.7747\n",
            "Epoch 165/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27.3894 - val_loss: 1807.1208\n",
            "Epoch 166/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.4156 - val_loss: 2127.1633\n",
            "Epoch 167/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 28.4629 - val_loss: 1804.1064\n",
            "Epoch 168/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.2992 - val_loss: 1736.3770\n",
            "Epoch 169/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.3906 - val_loss: 2156.8149\n",
            "Epoch 170/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.3104 - val_loss: 1869.5491\n",
            "Epoch 171/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.2445 - val_loss: 1831.3910\n",
            "Epoch 172/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.2530 - val_loss: 1630.0139\n",
            "Epoch 173/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.6016 - val_loss: 1831.9301\n",
            "Epoch 174/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 29.9160 - val_loss: 1918.2297\n",
            "Epoch 175/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.8029 - val_loss: 2078.9746\n",
            "Epoch 176/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 30.8411 - val_loss: 1692.0355\n",
            "Epoch 177/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 31.1218 - val_loss: 1690.2141\n",
            "Epoch 178/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.2515 - val_loss: 1947.1849\n",
            "Epoch 179/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.5969 - val_loss: 1987.4519\n",
            "Epoch 180/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.0503 - val_loss: 2014.1256\n",
            "Epoch 181/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.1987 - val_loss: 1904.9248\n",
            "Epoch 182/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.7085 - val_loss: 1943.4668\n",
            "Epoch 183/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.0902 - val_loss: 2327.2827\n",
            "Epoch 184/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 33.0457 - val_loss: 1923.1820\n",
            "Epoch 185/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.4547 - val_loss: 2091.6362\n",
            "Epoch 186/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.7994 - val_loss: 2148.8774\n",
            "Epoch 187/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.5947 - val_loss: 2083.7310\n",
            "Epoch 188/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.2814 - val_loss: 1810.9065\n",
            "Epoch 189/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.3800 - val_loss: 1767.8112\n",
            "Epoch 190/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 36.2159 - val_loss: 1892.9387\n",
            "Epoch 191/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.1466 - val_loss: 2085.7964\n",
            "Epoch 192/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.7665 - val_loss: 1840.3577\n",
            "Epoch 193/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.3208 - val_loss: 1889.5791\n",
            "Epoch 194/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.7030 - val_loss: 1860.1998\n",
            "Epoch 195/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.0176 - val_loss: 1832.0778\n",
            "Epoch 196/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.1231 - val_loss: 2056.7136\n",
            "Epoch 197/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.4656 - val_loss: 2107.3777\n",
            "Epoch 198/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 29.0256 - val_loss: 1772.4456\n",
            "Epoch 199/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.0275 - val_loss: 2194.7817\n",
            "Epoch 200/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.0644 - val_loss: 2050.0278\n",
            "Epoch 201/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.0698 - val_loss: 1824.9880\n",
            "Epoch 202/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.6847 - val_loss: 1898.7566\n",
            "Epoch 203/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 30.1128 - val_loss: 2154.2026\n",
            "Epoch 204/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.0550 - val_loss: 2150.5137\n",
            "Epoch 205/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.1830 - val_loss: 1864.8313\n",
            "Epoch 206/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.6089 - val_loss: 1703.9430\n",
            "Epoch 207/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 30.6103 - val_loss: 1920.0618\n",
            "Epoch 208/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 31.2514 - val_loss: 1892.5569\n",
            "Epoch 209/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.1890 - val_loss: 2164.7505\n",
            "Epoch 210/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 28.3588 - val_loss: 1936.2992\n",
            "Epoch 211/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.9025 - val_loss: 2352.7449\n",
            "Epoch 212/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.6411 - val_loss: 1889.6602\n",
            "Epoch 213/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.6495 - val_loss: 2057.3188\n",
            "Epoch 214/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.8391 - val_loss: 1848.6012\n",
            "Epoch 215/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 29.2311 - val_loss: 1984.7640\n",
            "Epoch 216/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 25.9603 - val_loss: 2114.7837\n",
            "Epoch 217/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.5141 - val_loss: 1799.7969\n",
            "Epoch 218/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.2942 - val_loss: 1687.6246\n",
            "Epoch 219/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.0925 - val_loss: 1994.7112\n",
            "Epoch 220/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.2066 - val_loss: 2051.2319\n",
            "Epoch 221/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.4988 - val_loss: 2158.9263\n",
            "Epoch 222/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.2732 - val_loss: 2047.8672\n",
            "Epoch 223/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.4936 - val_loss: 2112.8704\n",
            "Epoch 224/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.8722 - val_loss: 1899.8090\n",
            "Epoch 225/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.0038 - val_loss: 1816.2496\n",
            "Epoch 226/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.4704 - val_loss: 2110.3328\n",
            "Epoch 227/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 28.9848 - val_loss: 2099.2852\n",
            "Epoch 228/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 25.7735 - val_loss: 2294.5112\n",
            "Epoch 229/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 30.2322 - val_loss: 1959.6097\n",
            "Epoch 230/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.8289 - val_loss: 1765.5476\n",
            "Epoch 231/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.7073 - val_loss: 2083.5581\n",
            "Epoch 232/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.5521 - val_loss: 1778.1179\n",
            "Epoch 233/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.7655 - val_loss: 2249.5664\n",
            "Epoch 234/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.6548 - val_loss: 1999.1605\n",
            "Epoch 235/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.3563 - val_loss: 2232.4629\n",
            "Epoch 236/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27.7307 - val_loss: 2158.6140\n",
            "Epoch 237/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.4724 - val_loss: 2041.8000\n",
            "Epoch 238/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 29.3032 - val_loss: 2022.6326\n",
            "Epoch 239/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.2350 - val_loss: 2206.9851\n",
            "Epoch 240/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.1756 - val_loss: 2091.4146\n",
            "Epoch 241/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.9095 - val_loss: 2078.9922\n",
            "Epoch 242/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 29.0974 - val_loss: 2189.8516\n",
            "Epoch 243/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.5587 - val_loss: 1903.1842\n",
            "Epoch 244/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.1005 - val_loss: 1823.4789\n",
            "Epoch 245/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 31.2846 - val_loss: 2208.1743\n",
            "Epoch 246/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.1237 - val_loss: 2185.3196\n",
            "Epoch 247/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.0055 - val_loss: 1825.8381\n",
            "Epoch 248/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.5480 - val_loss: 1759.2133\n",
            "Epoch 249/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.9899 - val_loss: 1937.6267\n",
            "Epoch 250/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.6521 - val_loss: 2184.5884\n",
            "Epoch 251/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 30.0551 - val_loss: 1830.4397\n",
            "Epoch 252/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.8303 - val_loss: 2023.7031\n",
            "Epoch 253/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.6223 - val_loss: 1997.8588\n",
            "Epoch 254/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.4074 - val_loss: 1765.9150\n",
            "Epoch 255/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.8140 - val_loss: 1914.8147\n",
            "Epoch 256/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.1822 - val_loss: 1883.7844\n",
            "Epoch 257/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.2457 - val_loss: 2182.0833\n",
            "Epoch 258/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 32.3871 - val_loss: 1913.8727\n",
            "Epoch 259/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.8226 - val_loss: 2242.7214\n",
            "Epoch 260/500\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 22.7435 - val_loss: 1849.6199\n",
            "Epoch 261/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.5109 - val_loss: 1952.5710\n",
            "Epoch 262/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.3039 - val_loss: 2044.1989\n",
            "Epoch 263/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.6637 - val_loss: 1844.4084\n",
            "Epoch 264/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.8912 - val_loss: 2280.4983\n",
            "Epoch 265/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.2974 - val_loss: 1867.9623\n",
            "Epoch 266/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.7056 - val_loss: 1782.7507\n",
            "Epoch 267/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.2543 - val_loss: 2256.4819\n",
            "Epoch 268/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.0190 - val_loss: 2201.7581\n",
            "Epoch 269/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 28.9211 - val_loss: 1984.8073\n",
            "Epoch 270/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27.5901 - val_loss: 1889.1273\n",
            "Epoch 271/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27.1331 - val_loss: 2139.0984\n",
            "Epoch 272/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.3321 - val_loss: 1712.2180\n",
            "Epoch 273/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.1688 - val_loss: 1837.7275\n",
            "Epoch 274/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.2583 - val_loss: 1976.6448\n",
            "Epoch 275/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 22.9493 - val_loss: 2130.5742\n",
            "Epoch 276/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.6689 - val_loss: 1856.0726\n",
            "Epoch 277/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.2360 - val_loss: 1800.2963\n",
            "Epoch 278/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.6570 - val_loss: 1955.0129\n",
            "Epoch 279/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.8891 - val_loss: 1965.9836\n",
            "Epoch 280/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 22.0083 - val_loss: 1831.3414\n",
            "Epoch 281/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.2389 - val_loss: 1916.9281\n",
            "Epoch 282/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.2519 - val_loss: 2239.3931\n",
            "Epoch 283/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.8191 - val_loss: 1952.9229\n",
            "Epoch 284/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.0416 - val_loss: 1898.8860\n",
            "Epoch 285/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.6795 - val_loss: 1851.5969\n",
            "Epoch 286/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.6106 - val_loss: 1865.2380\n",
            "Epoch 287/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 28.8328 - val_loss: 1918.8254\n",
            "Epoch 288/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.0093 - val_loss: 2072.4622\n",
            "Epoch 289/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.1381 - val_loss: 2153.5696\n",
            "Epoch 290/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.0234 - val_loss: 2148.2905\n",
            "Epoch 291/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.1889 - val_loss: 2051.9624\n",
            "Epoch 292/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.9788 - val_loss: 1786.1648\n",
            "Epoch 293/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 31.0263 - val_loss: 1969.8250\n",
            "Epoch 294/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.5587 - val_loss: 1865.7441\n",
            "Epoch 295/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.3194 - val_loss: 1943.3610\n",
            "Epoch 296/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.4923 - val_loss: 1828.2164\n",
            "Epoch 297/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.9275 - val_loss: 1810.2434\n",
            "Epoch 298/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.0941 - val_loss: 1869.2415\n",
            "Epoch 299/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27.8791 - val_loss: 1847.7595\n",
            "Epoch 300/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.5037 - val_loss: 1880.9993\n",
            "Epoch 301/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 25.5062 - val_loss: 1944.8250\n",
            "Epoch 302/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.9666 - val_loss: 2212.2129\n",
            "Epoch 303/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.7901 - val_loss: 2016.1589\n",
            "Epoch 304/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.7392 - val_loss: 1742.1584\n",
            "Epoch 305/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.0741 - val_loss: 1861.3191\n",
            "Epoch 306/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 30.7436 - val_loss: 1866.9382\n",
            "Epoch 307/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.7914 - val_loss: 1967.1127\n",
            "Epoch 308/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.3480 - val_loss: 1924.9020\n",
            "Epoch 309/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.0985 - val_loss: 2011.6907\n",
            "Epoch 310/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.2461 - val_loss: 1931.1194\n",
            "Epoch 311/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.0652 - val_loss: 1922.6771\n",
            "Epoch 312/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 28.1828 - val_loss: 1868.4089\n",
            "Epoch 313/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.5002 - val_loss: 2126.5391\n",
            "Epoch 314/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.2531 - val_loss: 2134.4253\n",
            "Epoch 315/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.9782 - val_loss: 1771.7939\n",
            "Epoch 316/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.4272 - val_loss: 1859.5996\n",
            "Epoch 317/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.0688 - val_loss: 2206.1753\n",
            "Epoch 318/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.9633 - val_loss: 1943.8235\n",
            "Epoch 319/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.4066 - val_loss: 1864.1345\n",
            "Epoch 320/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.1582 - val_loss: 2145.5493\n",
            "Epoch 321/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.7534 - val_loss: 2037.8864\n",
            "Epoch 322/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.6701 - val_loss: 1719.0603\n",
            "Epoch 323/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.9219 - val_loss: 2105.5967\n",
            "Epoch 324/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.9338 - val_loss: 2029.5811\n",
            "Epoch 325/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.3774 - val_loss: 1846.7178\n",
            "Epoch 326/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.9209 - val_loss: 1854.0071\n",
            "Epoch 327/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.0125 - val_loss: 1744.8914\n",
            "Epoch 328/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.6659 - val_loss: 1804.8969\n",
            "Epoch 329/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.3703 - val_loss: 1718.8027\n",
            "Epoch 330/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.6379 - val_loss: 1866.4512\n",
            "Epoch 331/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.0549 - val_loss: 1900.0596\n",
            "Epoch 332/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.6961 - val_loss: 1646.9924\n",
            "Epoch 333/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.0651 - val_loss: 1783.2172\n",
            "Epoch 334/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.5614 - val_loss: 1798.2008\n",
            "Epoch 335/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.3781 - val_loss: 1853.5332\n",
            "Epoch 336/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.8029 - val_loss: 1846.9984\n",
            "Epoch 337/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.9232 - val_loss: 2096.8679\n",
            "Epoch 338/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.8533 - val_loss: 1780.3939\n",
            "Epoch 339/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.5143 - val_loss: 2146.2429\n",
            "Epoch 340/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.1766 - val_loss: 2187.3247\n",
            "Epoch 341/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.9509 - val_loss: 1974.7864\n",
            "Epoch 342/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 31.1048 - val_loss: 2062.3867\n",
            "Epoch 343/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.5404 - val_loss: 1948.7533\n",
            "Epoch 344/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.3257 - val_loss: 2005.7529\n",
            "Epoch 345/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.2350 - val_loss: 1836.0479\n",
            "Epoch 346/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.2504 - val_loss: 1803.3640\n",
            "Epoch 347/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.0760 - val_loss: 1747.9661\n",
            "Epoch 348/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.3884 - val_loss: 2116.0640\n",
            "Epoch 349/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.3341 - val_loss: 2009.9313\n",
            "Epoch 350/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.7726 - val_loss: 1658.3324\n",
            "Epoch 351/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.6462 - val_loss: 1784.1846\n",
            "Epoch 352/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.4364 - val_loss: 2070.9453\n",
            "Epoch 353/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.5425 - val_loss: 1947.6357\n",
            "Epoch 354/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.4703 - val_loss: 2064.6628\n",
            "Epoch 355/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.1813 - val_loss: 2044.8762\n",
            "Epoch 356/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.1545 - val_loss: 1874.2061\n",
            "Epoch 357/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.8650 - val_loss: 2102.5464\n",
            "Epoch 358/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.2602 - val_loss: 1895.2819\n",
            "Epoch 359/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.9424 - val_loss: 2005.5817\n",
            "Epoch 360/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.1567 - val_loss: 1826.9583\n",
            "Epoch 361/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 24.5266 - val_loss: 2132.2766\n",
            "Epoch 362/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.2720 - val_loss: 1778.2269\n",
            "Epoch 363/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.1767 - val_loss: 2035.0300\n",
            "Epoch 364/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.8972 - val_loss: 2104.0842\n",
            "Epoch 365/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.0067 - val_loss: 2178.3950\n",
            "Epoch 366/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.3764 - val_loss: 2038.9348\n",
            "Epoch 367/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 26.7419 - val_loss: 2331.3027\n",
            "Epoch 368/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.7503 - val_loss: 1856.5697\n",
            "Epoch 369/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.2336 - val_loss: 1670.2346\n",
            "Epoch 370/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.3680 - val_loss: 1745.5153\n",
            "Epoch 371/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.1527 - val_loss: 1801.8633\n",
            "Epoch 372/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 25.6999 - val_loss: 1991.6176\n",
            "Epoch 373/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.2455 - val_loss: 1683.6418\n",
            "Epoch 374/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 28.1063 - val_loss: 1787.0944\n",
            "Epoch 375/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.9521 - val_loss: 2161.6509\n",
            "Epoch 376/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.8728 - val_loss: 1769.8447\n",
            "Epoch 377/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 22.2834 - val_loss: 1764.9512\n",
            "Epoch 378/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.5320 - val_loss: 2167.2446\n",
            "Epoch 379/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.4860 - val_loss: 1792.0637\n",
            "Epoch 380/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 22.9608 - val_loss: 2134.3901\n",
            "Epoch 381/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.2324 - val_loss: 1874.5088\n",
            "Epoch 382/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27.1186 - val_loss: 1878.8835\n",
            "Epoch 383/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.0232 - val_loss: 1912.7855\n",
            "Epoch 384/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.2234 - val_loss: 2050.8560\n",
            "Epoch 385/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.9027 - val_loss: 2039.0613\n",
            "Epoch 386/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.8832 - val_loss: 2124.6882\n",
            "Epoch 387/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.4146 - val_loss: 1804.4840\n",
            "Epoch 388/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.2340 - val_loss: 1770.1508\n",
            "Epoch 389/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.6691 - val_loss: 1884.7009\n",
            "Epoch 390/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 32.0870 - val_loss: 2070.1558\n",
            "Epoch 391/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.1928 - val_loss: 2052.9939\n",
            "Epoch 392/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 22.7727 - val_loss: 2017.4929\n",
            "Epoch 393/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.9653 - val_loss: 2217.7820\n",
            "Epoch 394/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 27.8139 - val_loss: 1980.4436\n",
            "Epoch 395/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.0538 - val_loss: 2016.6510\n",
            "Epoch 396/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.4053 - val_loss: 1899.3484\n",
            "Epoch 397/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.0515 - val_loss: 1836.2683\n",
            "Epoch 398/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.5267 - val_loss: 1813.6531\n",
            "Epoch 399/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.7076 - val_loss: 1786.6920\n",
            "Epoch 400/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.8018 - val_loss: 1773.8981\n",
            "Epoch 401/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 28.8888 - val_loss: 1889.9441\n",
            "Epoch 402/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.8335 - val_loss: 2020.7673\n",
            "Epoch 403/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.3623 - val_loss: 2025.2188\n",
            "Epoch 404/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.7982 - val_loss: 1998.5706\n",
            "Epoch 405/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 26.1012 - val_loss: 1674.5281\n",
            "Epoch 406/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 25.2908 - val_loss: 1673.4951\n",
            "Epoch 407/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.4276 - val_loss: 1747.1902\n",
            "Epoch 408/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.0930 - val_loss: 1851.8386\n",
            "Epoch 409/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.4768 - val_loss: 1979.3051\n",
            "Epoch 410/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.1145 - val_loss: 1878.6934\n",
            "Epoch 411/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.5510 - val_loss: 1771.1982\n",
            "Epoch 412/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.7955 - val_loss: 1941.3295\n",
            "Epoch 413/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.0888 - val_loss: 1847.7043\n",
            "Epoch 414/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.6779 - val_loss: 1762.1365\n",
            "Epoch 415/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 21.8941 - val_loss: 1801.8945\n",
            "Epoch 416/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.1840 - val_loss: 2039.5094\n",
            "Epoch 417/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.5430 - val_loss: 2018.0605\n",
            "Epoch 418/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.1142 - val_loss: 1782.9684\n",
            "Epoch 419/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 25.8794 - val_loss: 1574.7490\n",
            "Epoch 420/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.8811 - val_loss: 1842.2070\n",
            "Epoch 421/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.3505 - val_loss: 1829.3928\n",
            "Epoch 422/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.3526 - val_loss: 2059.8345\n",
            "Epoch 423/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.3201 - val_loss: 1787.5461\n",
            "Epoch 424/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.3339 - val_loss: 1657.1394\n",
            "Epoch 425/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.0372 - val_loss: 1736.1390\n",
            "Epoch 426/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 22.8212 - val_loss: 1951.8616\n",
            "Epoch 427/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.9867 - val_loss: 1711.5016\n",
            "Epoch 428/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.4358 - val_loss: 1625.1101\n",
            "Epoch 429/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.7897 - val_loss: 1968.8412\n",
            "Epoch 430/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 19.5147 - val_loss: 1780.5211\n",
            "Epoch 431/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 28.8083 - val_loss: 1957.4807\n",
            "Epoch 432/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 21.8249 - val_loss: 1728.1270\n",
            "Epoch 433/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 24.3431 - val_loss: 1911.8730\n",
            "Epoch 434/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.5373 - val_loss: 1830.3562\n",
            "Epoch 435/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 19.9894 - val_loss: 1714.4783\n",
            "Epoch 436/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 28.4065 - val_loss: 1630.0813\n",
            "Epoch 437/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.8852 - val_loss: 1787.7703\n",
            "Epoch 438/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.4839 - val_loss: 1697.0774\n",
            "Epoch 439/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 30.3514 - val_loss: 1749.3396\n",
            "Epoch 440/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.4990 - val_loss: 1655.2930\n",
            "Epoch 441/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.2639 - val_loss: 1556.5192\n",
            "Epoch 442/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.4190 - val_loss: 1524.6862\n",
            "Epoch 443/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.6118 - val_loss: 1698.3676\n",
            "Epoch 444/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.7016 - val_loss: 1875.6741\n",
            "Epoch 445/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.3938 - val_loss: 1709.3464\n",
            "Epoch 446/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.1923 - val_loss: 1681.0156\n",
            "Epoch 447/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 28.4100 - val_loss: 1728.1299\n",
            "Epoch 448/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 22.7798 - val_loss: 1861.7955\n",
            "Epoch 449/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.9371 - val_loss: 1639.2220\n",
            "Epoch 450/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.3638 - val_loss: 1698.6683\n",
            "Epoch 451/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.9979 - val_loss: 1782.7703\n",
            "Epoch 452/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 28.5217 - val_loss: 1663.6722\n",
            "Epoch 453/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 20.3768 - val_loss: 1652.9695\n",
            "Epoch 454/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.0693 - val_loss: 2100.5964\n",
            "Epoch 455/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.3023 - val_loss: 1599.3157\n",
            "Epoch 456/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 24.2691 - val_loss: 1493.0466\n",
            "Epoch 457/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 23.6639 - val_loss: 1773.4460\n",
            "Epoch 458/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.2974 - val_loss: 1673.8289\n",
            "Epoch 459/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.5388 - val_loss: 1805.7395\n",
            "Epoch 460/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.5595 - val_loss: 1624.0809\n",
            "Epoch 461/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.8691 - val_loss: 1887.7523\n",
            "Epoch 462/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 19.5499 - val_loss: 1503.3362\n",
            "Epoch 463/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 27.0227 - val_loss: 1770.2332\n",
            "Epoch 464/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.6301 - val_loss: 1847.1931\n",
            "Epoch 465/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.1151 - val_loss: 1729.1676\n",
            "Epoch 466/500\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 25.1575 - val_loss: 1807.9498\n",
            "Epoch 467/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 19.3288 - val_loss: 1574.3376\n",
            "Epoch 468/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.5798 - val_loss: 1837.2758\n",
            "Epoch 469/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 20.2985 - val_loss: 1950.8785\n",
            "Epoch 470/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.3298 - val_loss: 1693.6191\n",
            "Epoch 471/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.9539 - val_loss: 1639.7468\n",
            "Epoch 472/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.9339 - val_loss: 2029.2184\n",
            "Epoch 473/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.7372 - val_loss: 1630.4293\n",
            "Epoch 474/500\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 25.6903 - val_loss: 1872.9514\n",
            "Epoch 475/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.6925 - val_loss: 1774.9395\n",
            "Epoch 476/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.5249 - val_loss: 1582.3074\n",
            "Epoch 477/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 26.8725 - val_loss: 1775.0247\n",
            "Epoch 478/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 19.3623 - val_loss: 1748.2301\n",
            "Epoch 479/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 25.7695 - val_loss: 1670.2996\n",
            "Epoch 480/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.7524 - val_loss: 1583.8121\n",
            "Epoch 481/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.1831 - val_loss: 1565.5376\n",
            "Epoch 482/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.3344 - val_loss: 1742.5105\n",
            "Epoch 483/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.8589 - val_loss: 1650.6549\n",
            "Epoch 484/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 23.6376 - val_loss: 1539.7932\n",
            "Epoch 485/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.6733 - val_loss: 1726.2252\n",
            "Epoch 486/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 28.2080 - val_loss: 1648.7773\n",
            "Epoch 487/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 19.9258 - val_loss: 1811.8844\n",
            "Epoch 488/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.0839 - val_loss: 1659.4700\n",
            "Epoch 489/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 20.6972 - val_loss: 1580.7992\n",
            "Epoch 490/500\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 22.3627 - val_loss: 1624.2052\n",
            "Epoch 491/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.2088 - val_loss: 1744.5785\n",
            "Epoch 492/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 20.0839 - val_loss: 1837.3347\n",
            "Epoch 493/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.4338 - val_loss: 1589.7833\n",
            "Epoch 494/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.4137 - val_loss: 1852.9075\n",
            "Epoch 495/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 19.5727 - val_loss: 1643.7451\n",
            "Epoch 496/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.1755 - val_loss: 1757.8567\n",
            "Epoch 497/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.3384 - val_loss: 1662.1262\n",
            "Epoch 498/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 23.8083 - val_loss: 1799.4141\n",
            "Epoch 499/500\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.0615 - val_loss: 1807.5670\n",
            "Epoch 500/500\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.4390 - val_loss: 1881.3688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5hchAQY6Cfo",
        "outputId": "f1cd6702-aaa0-452e-d510-e994a9c6a5b3"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 2731.3428\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2731.3427734375"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF3cOefl6chp"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=160, epochs=100, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5oNnRjYA4Qu",
        "outputId": "602d575c-5965-4fc6-8351-945dc8dc5240"
      },
      "source": [
        "x_train, x_test = x_boston[:400], x_boston[400:]\n",
        "y_train, y_test = y_boston[:400], y_boston[400:]\n",
        "print(x_train.shape, x_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(400, 13) (106, 13)\n",
            "(400, 1) (106, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dME1mmfzA6jJ",
        "outputId": "23f5ade7-f4a3-462f-c65b-df5dfd60adfb"
      },
      "source": [
        "result = model.fit(x_train, y_train, batch_size=128, epochs=500, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 23.5382 - val_loss: 1717.1067\n",
            "Epoch 2/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.8220 - val_loss: 1717.9274\n",
            "Epoch 3/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.0385 - val_loss: 1805.2793\n",
            "Epoch 4/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 21.5257 - val_loss: 1617.1965\n",
            "Epoch 5/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 20.8315 - val_loss: 1939.1160\n",
            "Epoch 6/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 29.2304 - val_loss: 1595.9535\n",
            "Epoch 7/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 26.2927 - val_loss: 1961.0642\n",
            "Epoch 8/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 26.6840 - val_loss: 1648.1125\n",
            "Epoch 9/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 18.8673 - val_loss: 1713.6033\n",
            "Epoch 10/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 18.4847 - val_loss: 1515.3376\n",
            "Epoch 11/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 28.6320 - val_loss: 1795.0891\n",
            "Epoch 12/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 19.0583 - val_loss: 1684.4124\n",
            "Epoch 13/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 18.5635 - val_loss: 1764.8464\n",
            "Epoch 14/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 21.2914 - val_loss: 1554.9597\n",
            "Epoch 15/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 27.7734 - val_loss: 1951.3457\n",
            "Epoch 16/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 27.0990 - val_loss: 1640.3177\n",
            "Epoch 17/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.7055 - val_loss: 1594.5842\n",
            "Epoch 18/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 20.7669 - val_loss: 1916.7812\n",
            "Epoch 19/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 28.5080 - val_loss: 1597.0299\n",
            "Epoch 20/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.5615 - val_loss: 1618.2213\n",
            "Epoch 21/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 21.7684 - val_loss: 1912.1018\n",
            "Epoch 22/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 27.6725 - val_loss: 1523.4631\n",
            "Epoch 23/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 27.1154 - val_loss: 1832.2067\n",
            "Epoch 24/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 23.4783 - val_loss: 1595.1887\n",
            "Epoch 25/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.8880 - val_loss: 1692.4069\n",
            "Epoch 26/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.3633 - val_loss: 1799.6472\n",
            "Epoch 27/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 19.7817 - val_loss: 1712.2522\n",
            "Epoch 28/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 18.6843 - val_loss: 1798.5247\n",
            "Epoch 29/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 27.5499 - val_loss: 1491.8486\n",
            "Epoch 30/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 28.7397 - val_loss: 1908.1887\n",
            "Epoch 31/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 26.7536 - val_loss: 1583.5818\n",
            "Epoch 32/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 22.3476 - val_loss: 1750.5267\n",
            "Epoch 33/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.6624 - val_loss: 1784.3191\n",
            "Epoch 34/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 22.6116 - val_loss: 1566.2559\n",
            "Epoch 35/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 23.7911 - val_loss: 1858.9489\n",
            "Epoch 36/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 21.2829 - val_loss: 1500.0964\n",
            "Epoch 37/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 26.0143 - val_loss: 1765.2375\n",
            "Epoch 38/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.6131 - val_loss: 1569.9739\n",
            "Epoch 39/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 26.6293 - val_loss: 1970.9675\n",
            "Epoch 40/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 27.8776 - val_loss: 1573.9587\n",
            "Epoch 41/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.5987 - val_loss: 1662.9037\n",
            "Epoch 42/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 20.6288 - val_loss: 2007.8074\n",
            "Epoch 43/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 33.3310 - val_loss: 1631.5908\n",
            "Epoch 44/500\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 19.2267 - val_loss: 1637.0505\n",
            "Epoch 45/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19.7632 - val_loss: 1786.9211\n",
            "Epoch 46/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 21.5529 - val_loss: 1515.7322\n",
            "Epoch 47/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 31.1695 - val_loss: 1906.8611\n",
            "Epoch 48/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 25.4237 - val_loss: 1632.2585\n",
            "Epoch 49/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.5682 - val_loss: 1858.6898\n",
            "Epoch 50/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 22.5173 - val_loss: 1501.7610\n",
            "Epoch 51/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 26.4511 - val_loss: 1753.0963\n",
            "Epoch 52/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19.5259 - val_loss: 1786.1672\n",
            "Epoch 53/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 24.8255 - val_loss: 1476.4933\n",
            "Epoch 54/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 25.2255 - val_loss: 1761.6184\n",
            "Epoch 55/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 20.1034 - val_loss: 1564.5642\n",
            "Epoch 56/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 22.8386 - val_loss: 1840.4996\n",
            "Epoch 57/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 23.5176 - val_loss: 1490.7396\n",
            "Epoch 58/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 25.2756 - val_loss: 1816.3733\n",
            "Epoch 59/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 22.0275 - val_loss: 1539.2238\n",
            "Epoch 60/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 22.8320 - val_loss: 1695.1693\n",
            "Epoch 61/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19.0293 - val_loss: 1609.9412\n",
            "Epoch 62/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19.0540 - val_loss: 1767.2068\n",
            "Epoch 63/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 21.7194 - val_loss: 1503.1628\n",
            "Epoch 64/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 27.4636 - val_loss: 1820.0957\n",
            "Epoch 65/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 23.2711 - val_loss: 1638.3048\n",
            "Epoch 66/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.1843 - val_loss: 1742.9727\n",
            "Epoch 67/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 20.9300 - val_loss: 1709.4590\n",
            "Epoch 68/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 19.2287 - val_loss: 1496.8113\n",
            "Epoch 69/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 36.1680 - val_loss: 1844.1683\n",
            "Epoch 70/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 23.2439 - val_loss: 1733.9938\n",
            "Epoch 71/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.0816 - val_loss: 1880.7891\n",
            "Epoch 72/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 22.0341 - val_loss: 1640.0491\n",
            "Epoch 73/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 22.5287 - val_loss: 1825.2510\n",
            "Epoch 74/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 21.4104 - val_loss: 1606.1873\n",
            "Epoch 75/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 20.7492 - val_loss: 1842.9469\n",
            "Epoch 76/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 29.1431 - val_loss: 1582.8285\n",
            "Epoch 77/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19.2932 - val_loss: 1663.5310\n",
            "Epoch 78/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.5146 - val_loss: 1784.8121\n",
            "Epoch 79/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 26.4449 - val_loss: 1464.5752\n",
            "Epoch 80/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 24.9771 - val_loss: 1706.7181\n",
            "Epoch 81/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.8819 - val_loss: 1840.6084\n",
            "Epoch 82/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.6091 - val_loss: 1681.8109\n",
            "Epoch 83/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19.4742 - val_loss: 1566.4918\n",
            "Epoch 84/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 21.5975 - val_loss: 1977.6211\n",
            "Epoch 85/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 39.4809 - val_loss: 1601.0195\n",
            "Epoch 86/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.3377 - val_loss: 1703.9395\n",
            "Epoch 87/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.3191 - val_loss: 1724.5989\n",
            "Epoch 88/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.5583 - val_loss: 1595.6282\n",
            "Epoch 89/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.2490 - val_loss: 1912.8105\n",
            "Epoch 90/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 26.9601 - val_loss: 1601.1086\n",
            "Epoch 91/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 21.8095 - val_loss: 1782.7533\n",
            "Epoch 92/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 20.0002 - val_loss: 1632.6079\n",
            "Epoch 93/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.0323 - val_loss: 1748.2246\n",
            "Epoch 94/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.9187 - val_loss: 1579.2502\n",
            "Epoch 95/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 23.6625 - val_loss: 1785.9512\n",
            "Epoch 96/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 20.9905 - val_loss: 1510.9047\n",
            "Epoch 97/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 22.7428 - val_loss: 1715.9769\n",
            "Epoch 98/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 22.2469 - val_loss: 1472.5629\n",
            "Epoch 99/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 32.5743 - val_loss: 1835.3538\n",
            "Epoch 100/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.2871 - val_loss: 1588.0116\n",
            "Epoch 101/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 22.9194 - val_loss: 1903.3365\n",
            "Epoch 102/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 25.6313 - val_loss: 1656.6609\n",
            "Epoch 103/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 18.7314 - val_loss: 1705.0465\n",
            "Epoch 104/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.2696 - val_loss: 1670.4414\n",
            "Epoch 105/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 21.8610 - val_loss: 1803.6826\n",
            "Epoch 106/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 25.2097 - val_loss: 1577.2365\n",
            "Epoch 107/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 24.1566 - val_loss: 1863.9027\n",
            "Epoch 108/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 23.9370 - val_loss: 1634.9442\n",
            "Epoch 109/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 19.5598 - val_loss: 1709.3715\n",
            "Epoch 110/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.9437 - val_loss: 1795.6709\n",
            "Epoch 111/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 24.8183 - val_loss: 1540.5896\n",
            "Epoch 112/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 22.1845 - val_loss: 1818.4033\n",
            "Epoch 113/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 23.9856 - val_loss: 1566.1016\n",
            "Epoch 114/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 21.1330 - val_loss: 1782.0422\n",
            "Epoch 115/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 22.1023 - val_loss: 1572.0780\n",
            "Epoch 116/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 21.4127 - val_loss: 1740.7465\n",
            "Epoch 117/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.3486 - val_loss: 1681.3157\n",
            "Epoch 118/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.2716 - val_loss: 1585.8395\n",
            "Epoch 119/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 21.6363 - val_loss: 1945.9617\n",
            "Epoch 120/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 33.0752 - val_loss: 1527.7562\n",
            "Epoch 121/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 20.1532 - val_loss: 1595.7267\n",
            "Epoch 122/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.1869 - val_loss: 1700.9719\n",
            "Epoch 123/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.7163 - val_loss: 1526.7737\n",
            "Epoch 124/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 29.4899 - val_loss: 1871.6697\n",
            "Epoch 125/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 24.9781 - val_loss: 1614.9589\n",
            "Epoch 126/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.1432 - val_loss: 1717.1790\n",
            "Epoch 127/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 21.3132 - val_loss: 1500.3972\n",
            "Epoch 128/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 21.0890 - val_loss: 1829.3539\n",
            "Epoch 129/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.2251 - val_loss: 1490.9456\n",
            "Epoch 130/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 26.1625 - val_loss: 1806.5378\n",
            "Epoch 131/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 21.6753 - val_loss: 1562.6418\n",
            "Epoch 132/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 21.6315 - val_loss: 1724.0551\n",
            "Epoch 133/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 20.1901 - val_loss: 1506.2371\n",
            "Epoch 134/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 20.7480 - val_loss: 1666.0261\n",
            "Epoch 135/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.9374 - val_loss: 1462.9542\n",
            "Epoch 136/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 31.5136 - val_loss: 1842.8375\n",
            "Epoch 137/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 24.2211 - val_loss: 1526.9824\n",
            "Epoch 138/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 19.8635 - val_loss: 1648.6832\n",
            "Epoch 139/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 18.1866 - val_loss: 1595.3896\n",
            "Epoch 140/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.7249 - val_loss: 1854.9719\n",
            "Epoch 141/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 24.5342 - val_loss: 1433.4811\n",
            "Epoch 142/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 32.5417 - val_loss: 1695.1149\n",
            "Epoch 143/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.7023 - val_loss: 1602.4065\n",
            "Epoch 144/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.7248 - val_loss: 1646.3518\n",
            "Epoch 145/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.9787 - val_loss: 1635.7841\n",
            "Epoch 146/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 20.8696 - val_loss: 1869.0247\n",
            "Epoch 147/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 35.9619 - val_loss: 1527.5837\n",
            "Epoch 148/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.4756 - val_loss: 1685.2922\n",
            "Epoch 149/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.0096 - val_loss: 1610.2488\n",
            "Epoch 150/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.6447 - val_loss: 1722.3285\n",
            "Epoch 151/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 20.5367 - val_loss: 1482.4929\n",
            "Epoch 152/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 27.6946 - val_loss: 1922.8551\n",
            "Epoch 153/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 28.9824 - val_loss: 1594.4574\n",
            "Epoch 154/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.8104 - val_loss: 1732.1312\n",
            "Epoch 155/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.6512 - val_loss: 1584.5616\n",
            "Epoch 156/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.7194 - val_loss: 1759.8235\n",
            "Epoch 157/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 19.6404 - val_loss: 1474.7642\n",
            "Epoch 158/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 25.9685 - val_loss: 1827.8474\n",
            "Epoch 159/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 22.5933 - val_loss: 1581.1049\n",
            "Epoch 160/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.5306 - val_loss: 1974.3881\n",
            "Epoch 161/500\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 32.6304 - val_loss: 1510.9781\n",
            "Epoch 162/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 22.6278 - val_loss: 1706.7844\n",
            "Epoch 163/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19.4993 - val_loss: 1574.4561\n",
            "Epoch 164/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 21.6318 - val_loss: 1833.3909\n",
            "Epoch 165/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 23.6668 - val_loss: 1522.2849\n",
            "Epoch 166/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 20.3180 - val_loss: 1615.3363\n",
            "Epoch 167/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 19.6482 - val_loss: 1803.8264\n",
            "Epoch 168/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 23.5713 - val_loss: 1485.9835\n",
            "Epoch 169/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 23.3411 - val_loss: 1791.4841\n",
            "Epoch 170/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 22.1180 - val_loss: 1604.8448\n",
            "Epoch 171/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.0359 - val_loss: 1755.7461\n",
            "Epoch 172/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.8626 - val_loss: 1442.6296\n",
            "Epoch 173/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 25.7063 - val_loss: 1732.4805\n",
            "Epoch 174/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 21.2827 - val_loss: 1517.3407\n",
            "Epoch 175/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.8803 - val_loss: 1662.1989\n",
            "Epoch 176/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.8469 - val_loss: 1613.0547\n",
            "Epoch 177/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 20.0912 - val_loss: 1887.9612\n",
            "Epoch 178/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 33.7291 - val_loss: 1549.6111\n",
            "Epoch 179/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.9141 - val_loss: 1651.2454\n",
            "Epoch 180/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.8993 - val_loss: 1694.5078\n",
            "Epoch 181/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.3261 - val_loss: 1518.7372\n",
            "Epoch 182/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 23.0528 - val_loss: 1960.2148\n",
            "Epoch 183/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 32.8350 - val_loss: 1536.3127\n",
            "Epoch 184/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 21.3366 - val_loss: 1771.9473\n",
            "Epoch 185/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 20.4942 - val_loss: 1659.7604\n",
            "Epoch 186/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.8518 - val_loss: 1624.8650\n",
            "Epoch 187/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.3900 - val_loss: 1849.0593\n",
            "Epoch 188/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 35.1625 - val_loss: 1476.9939\n",
            "Epoch 189/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.7547 - val_loss: 1588.0298\n",
            "Epoch 190/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 18.0647 - val_loss: 1724.4008\n",
            "Epoch 191/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 20.0634 - val_loss: 1623.2350\n",
            "Epoch 192/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.6566 - val_loss: 1925.6985\n",
            "Epoch 193/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 35.4942 - val_loss: 1543.1248\n",
            "Epoch 194/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 22.4810 - val_loss: 1717.5765\n",
            "Epoch 195/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.1743 - val_loss: 1773.4092\n",
            "Epoch 196/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 20.1978 - val_loss: 1597.7756\n",
            "Epoch 197/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 23.8227 - val_loss: 1868.8199\n",
            "Epoch 198/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 20.9710 - val_loss: 1586.1643\n",
            "Epoch 199/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 18.9200 - val_loss: 1712.0017\n",
            "Epoch 200/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 19.1184 - val_loss: 1543.4167\n",
            "Epoch 201/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 24.1495 - val_loss: 1925.1334\n",
            "Epoch 202/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.1336 - val_loss: 1510.6028\n",
            "Epoch 203/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.9642 - val_loss: 1664.6296\n",
            "Epoch 204/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.3599 - val_loss: 1776.2571\n",
            "Epoch 205/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 23.6339 - val_loss: 1446.6250\n",
            "Epoch 206/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 30.2895 - val_loss: 1705.6943\n",
            "Epoch 207/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.4254 - val_loss: 1602.7594\n",
            "Epoch 208/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.9694 - val_loss: 1805.7269\n",
            "Epoch 209/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 21.8832 - val_loss: 1492.7709\n",
            "Epoch 210/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 24.4804 - val_loss: 1871.6140\n",
            "Epoch 211/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 30.4442 - val_loss: 1481.4497\n",
            "Epoch 212/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 21.7654 - val_loss: 1554.5492\n",
            "Epoch 213/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.3636 - val_loss: 1699.0891\n",
            "Epoch 214/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 20.5200 - val_loss: 1629.6371\n",
            "Epoch 215/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.7211 - val_loss: 1559.8616\n",
            "Epoch 216/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.2163 - val_loss: 1815.8929\n",
            "Epoch 217/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 30.4867 - val_loss: 1440.9086\n",
            "Epoch 218/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 24.6366 - val_loss: 1762.8549\n",
            "Epoch 219/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 22.9893 - val_loss: 1524.2297\n",
            "Epoch 220/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 18.9419 - val_loss: 1683.9343\n",
            "Epoch 221/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.8364 - val_loss: 1704.7523\n",
            "Epoch 222/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 20.6606 - val_loss: 1477.2888\n",
            "Epoch 223/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 31.0949 - val_loss: 1836.5729\n",
            "Epoch 224/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 28.0781 - val_loss: 1543.3657\n",
            "Epoch 225/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.3863 - val_loss: 1666.4709\n",
            "Epoch 226/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 18.0835 - val_loss: 1660.6565\n",
            "Epoch 227/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 23.9666 - val_loss: 1430.4836\n",
            "Epoch 228/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 22.7066 - val_loss: 1711.9851\n",
            "Epoch 229/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.5741 - val_loss: 1589.3307\n",
            "Epoch 230/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.7195 - val_loss: 1651.2747\n",
            "Epoch 231/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 19.1848 - val_loss: 1448.5549\n",
            "Epoch 232/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 28.3747 - val_loss: 1775.2883\n",
            "Epoch 233/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 22.7832 - val_loss: 1481.2875\n",
            "Epoch 234/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 19.3659 - val_loss: 1558.2594\n",
            "Epoch 235/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 22.1225 - val_loss: 1851.6703\n",
            "Epoch 236/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 22.2276 - val_loss: 1519.0835\n",
            "Epoch 237/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 26.8239 - val_loss: 1759.0735\n",
            "Epoch 238/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.3679 - val_loss: 1560.5481\n",
            "Epoch 239/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 20.3119 - val_loss: 1751.7115\n",
            "Epoch 240/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 24.5757 - val_loss: 1466.2141\n",
            "Epoch 241/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.0243 - val_loss: 1839.4661\n",
            "Epoch 242/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 26.2487 - val_loss: 1429.4333\n",
            "Epoch 243/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 23.5628 - val_loss: 1692.7527\n",
            "Epoch 244/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.3338 - val_loss: 1464.6940\n",
            "Epoch 245/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 27.4892 - val_loss: 1740.0242\n",
            "Epoch 246/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.6650 - val_loss: 1514.7295\n",
            "Epoch 247/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.0133 - val_loss: 1566.5035\n",
            "Epoch 248/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.0733 - val_loss: 1721.3884\n",
            "Epoch 249/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.0697 - val_loss: 1387.8114\n",
            "Epoch 250/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 27.3797 - val_loss: 1680.6667\n",
            "Epoch 251/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 17.6356 - val_loss: 1607.6560\n",
            "Epoch 252/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.6848 - val_loss: 1543.2253\n",
            "Epoch 253/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 23.7774 - val_loss: 1863.4636\n",
            "Epoch 254/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 24.4568 - val_loss: 1496.8806\n",
            "Epoch 255/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 18.4043 - val_loss: 1563.0209\n",
            "Epoch 256/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 22.9537 - val_loss: 1900.7200\n",
            "Epoch 257/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 29.9161 - val_loss: 1518.8469\n",
            "Epoch 258/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.8842 - val_loss: 1564.4753\n",
            "Epoch 259/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.6627 - val_loss: 1560.8008\n",
            "Epoch 260/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 18.1387 - val_loss: 1594.1406\n",
            "Epoch 261/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 23.4406 - val_loss: 1360.0306\n",
            "Epoch 262/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 34.4532 - val_loss: 1755.6801\n",
            "Epoch 263/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 22.2032 - val_loss: 1546.1559\n",
            "Epoch 264/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.4422 - val_loss: 1670.9183\n",
            "Epoch 265/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.0198 - val_loss: 1477.6658\n",
            "Epoch 266/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 24.1909 - val_loss: 1782.6813\n",
            "Epoch 267/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 23.2696 - val_loss: 1479.3625\n",
            "Epoch 268/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 26.4618 - val_loss: 1719.4332\n",
            "Epoch 269/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 18.1894 - val_loss: 1597.0573\n",
            "Epoch 270/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 17.4682 - val_loss: 1730.8699\n",
            "Epoch 271/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 23.9441 - val_loss: 1440.8290\n",
            "Epoch 272/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 26.4880 - val_loss: 1694.8307\n",
            "Epoch 273/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 22.7819 - val_loss: 1534.5835\n",
            "Epoch 274/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 18.3264 - val_loss: 1679.4949\n",
            "Epoch 275/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.8223 - val_loss: 1447.2791\n",
            "Epoch 276/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 24.9564 - val_loss: 1724.9860\n",
            "Epoch 277/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 19.4302 - val_loss: 1514.3503\n",
            "Epoch 278/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 18.5947 - val_loss: 1670.6830\n",
            "Epoch 279/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 18.5785 - val_loss: 1497.1969\n",
            "Epoch 280/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 23.0924 - val_loss: 1794.6957\n",
            "Epoch 281/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 23.1618 - val_loss: 1446.0762\n",
            "Epoch 282/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.6599 - val_loss: 1680.6471\n",
            "Epoch 283/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.9299 - val_loss: 1578.9291\n",
            "Epoch 284/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.0636 - val_loss: 1685.1726\n",
            "Epoch 285/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 25.2396 - val_loss: 1407.4070\n",
            "Epoch 286/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 26.8359 - val_loss: 1720.4603\n",
            "Epoch 287/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.8593 - val_loss: 1738.7828\n",
            "Epoch 288/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 20.0321 - val_loss: 1582.4125\n",
            "Epoch 289/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.5500 - val_loss: 1692.0393\n",
            "Epoch 290/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 24.4688 - val_loss: 1388.8483\n",
            "Epoch 291/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 22.6536 - val_loss: 1506.7648\n",
            "Epoch 292/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.9436 - val_loss: 1790.4840\n",
            "Epoch 293/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 28.5361 - val_loss: 1428.5403\n",
            "Epoch 294/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 23.5110 - val_loss: 1725.0928\n",
            "Epoch 295/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 21.4183 - val_loss: 1670.0612\n",
            "Epoch 296/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 18.5479 - val_loss: 1613.5027\n",
            "Epoch 297/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.4318 - val_loss: 1612.5424\n",
            "Epoch 298/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 17.7125 - val_loss: 1752.7527\n",
            "Epoch 299/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.7350 - val_loss: 1442.8839\n",
            "Epoch 300/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 18.7268 - val_loss: 1589.3762\n",
            "Epoch 301/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.9661 - val_loss: 1369.7556\n",
            "Epoch 302/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 35.6909 - val_loss: 1699.6586\n",
            "Epoch 303/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 22.5384 - val_loss: 1476.5286\n",
            "Epoch 304/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.0318 - val_loss: 1553.9833\n",
            "Epoch 305/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.8830 - val_loss: 1645.4047\n",
            "Epoch 306/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 18.3529 - val_loss: 1468.2528\n",
            "Epoch 307/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 27.8374 - val_loss: 1837.3516\n",
            "Epoch 308/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 24.8741 - val_loss: 1452.7610\n",
            "Epoch 309/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 22.1726 - val_loss: 1751.0485\n",
            "Epoch 310/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 22.7089 - val_loss: 1495.3694\n",
            "Epoch 311/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 21.5881 - val_loss: 1691.0964\n",
            "Epoch 312/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.7865 - val_loss: 1659.3981\n",
            "Epoch 313/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.8748 - val_loss: 1422.3470\n",
            "Epoch 314/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 28.9709 - val_loss: 1801.0566\n",
            "Epoch 315/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 24.8128 - val_loss: 1548.5345\n",
            "Epoch 316/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 17.5010 - val_loss: 1592.6232\n",
            "Epoch 317/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.3807 - val_loss: 1558.8635\n",
            "Epoch 318/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 17.4759 - val_loss: 1601.9832\n",
            "Epoch 319/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 18.1595 - val_loss: 1747.7402\n",
            "Epoch 320/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 26.4245 - val_loss: 1373.2582\n",
            "Epoch 321/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 34.4678 - val_loss: 1723.9255\n",
            "Epoch 322/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 18.2837 - val_loss: 1560.7703\n",
            "Epoch 323/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.5649 - val_loss: 1501.1389\n",
            "Epoch 324/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 19.9008 - val_loss: 1755.8812\n",
            "Epoch 325/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 22.0470 - val_loss: 1352.3035\n",
            "Epoch 326/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 35.1113 - val_loss: 1723.9885\n",
            "Epoch 327/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.7131 - val_loss: 1560.9944\n",
            "Epoch 328/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 18.5487 - val_loss: 1580.8962\n",
            "Epoch 329/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.4458 - val_loss: 1572.1361\n",
            "Epoch 330/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.2768 - val_loss: 1390.9364\n",
            "Epoch 331/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 32.9704 - val_loss: 1722.8773\n",
            "Epoch 332/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.6648 - val_loss: 1463.3054\n",
            "Epoch 333/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 19.4486 - val_loss: 1624.9861\n",
            "Epoch 334/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 17.1217 - val_loss: 1511.7822\n",
            "Epoch 335/500\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 19.0782 - val_loss: 1656.3893\n",
            "Epoch 336/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.1726 - val_loss: 1355.0833\n",
            "Epoch 337/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 28.4879 - val_loss: 1707.8857\n",
            "Epoch 338/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 26.8318 - val_loss: 1416.2416\n",
            "Epoch 339/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.5593 - val_loss: 1698.5406\n",
            "Epoch 340/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.8431 - val_loss: 1554.2343\n",
            "Epoch 341/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.4210 - val_loss: 1570.6002\n",
            "Epoch 342/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 17.2591 - val_loss: 1627.0173\n",
            "Epoch 343/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 21.3795 - val_loss: 1331.5740\n",
            "Epoch 344/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 35.2335 - val_loss: 1677.2947\n",
            "Epoch 345/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 21.2675 - val_loss: 1491.4019\n",
            "Epoch 346/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.3696 - val_loss: 1703.7770\n",
            "Epoch 347/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 20.6765 - val_loss: 1571.9163\n",
            "Epoch 348/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 17.5868 - val_loss: 1664.9283\n",
            "Epoch 349/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 17.6102 - val_loss: 1493.6595\n",
            "Epoch 350/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 20.8240 - val_loss: 1840.3066\n",
            "Epoch 351/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 35.4767 - val_loss: 1482.3289\n",
            "Epoch 352/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 18.7560 - val_loss: 1617.2405\n",
            "Epoch 353/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 21.7050 - val_loss: 1409.5819\n",
            "Epoch 354/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 20.4520 - val_loss: 1600.4377\n",
            "Epoch 355/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.3518 - val_loss: 1641.9160\n",
            "Epoch 356/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 19.7998 - val_loss: 1405.6472\n",
            "Epoch 357/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 30.5327 - val_loss: 1732.3727\n",
            "Epoch 358/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 21.6361 - val_loss: 1494.9558\n",
            "Epoch 359/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.8983 - val_loss: 1726.7441\n",
            "Epoch 360/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 23.2061 - val_loss: 1462.3319\n",
            "Epoch 361/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.6513 - val_loss: 1695.2386\n",
            "Epoch 362/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.7908 - val_loss: 1437.5211\n",
            "Epoch 363/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 26.5010 - val_loss: 1718.7844\n",
            "Epoch 364/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 20.9339 - val_loss: 1485.1530\n",
            "Epoch 365/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 22.7175 - val_loss: 1710.6442\n",
            "Epoch 366/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 32.0588 - val_loss: 1431.0144\n",
            "Epoch 367/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 20.6278 - val_loss: 1699.0883\n",
            "Epoch 368/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.4638 - val_loss: 1610.9476\n",
            "Epoch 369/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 19.2558 - val_loss: 1409.8872\n",
            "Epoch 370/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 27.9007 - val_loss: 1662.7791\n",
            "Epoch 371/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.5867 - val_loss: 1496.2354\n",
            "Epoch 372/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.7925 - val_loss: 1500.1825\n",
            "Epoch 373/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 18.4970 - val_loss: 1669.5820\n",
            "Epoch 374/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 22.8036 - val_loss: 1371.6803\n",
            "Epoch 375/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 25.0597 - val_loss: 1613.6442\n",
            "Epoch 376/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.9429 - val_loss: 1424.8252\n",
            "Epoch 377/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 23.8176 - val_loss: 1633.7625\n",
            "Epoch 378/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.6781 - val_loss: 1541.2349\n",
            "Epoch 379/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.9853 - val_loss: 1905.4033\n",
            "Epoch 380/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 33.4941 - val_loss: 1448.2437\n",
            "Epoch 381/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.8933 - val_loss: 1580.1503\n",
            "Epoch 382/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 17.1733 - val_loss: 1561.8545\n",
            "Epoch 383/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.1886 - val_loss: 1535.2483\n",
            "Epoch 384/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.7231 - val_loss: 1802.3977\n",
            "Epoch 385/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 31.9698 - val_loss: 1403.5483\n",
            "Epoch 386/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 21.4778 - val_loss: 1611.8134\n",
            "Epoch 387/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.2649 - val_loss: 1560.2118\n",
            "Epoch 388/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.1475 - val_loss: 1548.2415\n",
            "Epoch 389/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 19.0342 - val_loss: 1782.5205\n",
            "Epoch 390/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 34.0734 - val_loss: 1459.7842\n",
            "Epoch 391/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.8116 - val_loss: 1541.1942\n",
            "Epoch 392/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.7317 - val_loss: 1542.1802\n",
            "Epoch 393/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.5011 - val_loss: 1725.3929\n",
            "Epoch 394/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.6082 - val_loss: 1365.5881\n",
            "Epoch 395/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 29.4105 - val_loss: 1679.1110\n",
            "Epoch 396/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 20.9176 - val_loss: 1461.8219\n",
            "Epoch 397/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 18.6181 - val_loss: 1552.3719\n",
            "Epoch 398/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.6665 - val_loss: 1458.9734\n",
            "Epoch 399/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 22.0779 - val_loss: 1791.4551\n",
            "Epoch 400/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 27.1263 - val_loss: 1481.9271\n",
            "Epoch 401/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 20.7717 - val_loss: 1641.2571\n",
            "Epoch 402/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.3630 - val_loss: 1464.5850\n",
            "Epoch 403/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 19.9773 - val_loss: 1715.5957\n",
            "Epoch 404/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 24.5252 - val_loss: 1481.9407\n",
            "Epoch 405/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.3526 - val_loss: 1515.5222\n",
            "Epoch 406/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 26.3489 - val_loss: 1799.1930\n",
            "Epoch 407/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 25.8417 - val_loss: 1585.3062\n",
            "Epoch 408/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.1659 - val_loss: 1640.3967\n",
            "Epoch 409/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.6356 - val_loss: 1594.6292\n",
            "Epoch 410/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.5520 - val_loss: 1417.2415\n",
            "Epoch 411/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 21.3574 - val_loss: 1673.6152\n",
            "Epoch 412/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 19.8367 - val_loss: 1501.1234\n",
            "Epoch 413/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.4727 - val_loss: 1635.1790\n",
            "Epoch 414/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 22.2185 - val_loss: 1307.3145\n",
            "Epoch 415/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 32.7456 - val_loss: 1742.8711\n",
            "Epoch 416/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 23.0211 - val_loss: 1598.7268\n",
            "Epoch 417/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.3557 - val_loss: 1397.1587\n",
            "Epoch 418/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 21.5612 - val_loss: 1777.4180\n",
            "Epoch 419/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 25.2680 - val_loss: 1535.4886\n",
            "Epoch 420/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 17.1791 - val_loss: 1499.3625\n",
            "Epoch 421/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 20.1302 - val_loss: 1753.6488\n",
            "Epoch 422/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 28.6387 - val_loss: 1415.9775\n",
            "Epoch 423/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 23.8131 - val_loss: 1571.6387\n",
            "Epoch 424/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.0686 - val_loss: 1585.0344\n",
            "Epoch 425/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 20.0304 - val_loss: 1381.6282\n",
            "Epoch 426/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 29.3086 - val_loss: 1785.8619\n",
            "Epoch 427/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 26.1663 - val_loss: 1506.4518\n",
            "Epoch 428/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.4258 - val_loss: 1492.4281\n",
            "Epoch 429/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 20.4421 - val_loss: 1626.4434\n",
            "Epoch 430/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 22.6819 - val_loss: 1452.5453\n",
            "Epoch 431/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 18.4798 - val_loss: 1551.2225\n",
            "Epoch 432/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.2983 - val_loss: 1769.1748\n",
            "Epoch 433/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 31.3347 - val_loss: 1442.9521\n",
            "Epoch 434/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 20.3333 - val_loss: 1585.9319\n",
            "Epoch 435/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.0201 - val_loss: 1582.2014\n",
            "Epoch 436/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 16.9914 - val_loss: 1589.7375\n",
            "Epoch 437/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.6176 - val_loss: 1412.5144\n",
            "Epoch 438/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 25.3003 - val_loss: 1730.0388\n",
            "Epoch 439/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 22.7481 - val_loss: 1521.4286\n",
            "Epoch 440/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.1971 - val_loss: 1457.5151\n",
            "Epoch 441/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 27.3996 - val_loss: 1687.2439\n",
            "Epoch 442/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 20.0063 - val_loss: 1543.6371\n",
            "Epoch 443/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 18.1945 - val_loss: 1671.6381\n",
            "Epoch 444/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.3467 - val_loss: 1386.5793\n",
            "Epoch 445/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 20.8338 - val_loss: 1632.8446\n",
            "Epoch 446/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 21.4360 - val_loss: 1352.5247\n",
            "Epoch 447/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 28.8014 - val_loss: 1604.9788\n",
            "Epoch 448/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 17.0800 - val_loss: 1505.8982\n",
            "Epoch 449/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 18.2611 - val_loss: 1744.1379\n",
            "Epoch 450/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 21.4848 - val_loss: 1378.3689\n",
            "Epoch 451/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 30.6941 - val_loss: 1798.5129\n",
            "Epoch 452/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 23.3501 - val_loss: 1479.4490\n",
            "Epoch 453/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 17.6981 - val_loss: 1439.8740\n",
            "Epoch 454/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 21.3782 - val_loss: 1714.1497\n",
            "Epoch 455/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.2993 - val_loss: 1463.7852\n",
            "Epoch 456/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 20.9535 - val_loss: 1767.5684\n",
            "Epoch 457/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 26.9298 - val_loss: 1514.7223\n",
            "Epoch 458/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 17.4284 - val_loss: 1609.8538\n",
            "Epoch 459/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 19.6644 - val_loss: 1458.8212\n",
            "Epoch 460/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 22.3376 - val_loss: 1759.0889\n",
            "Epoch 461/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 22.1356 - val_loss: 1546.1000\n",
            "Epoch 462/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 16.9585 - val_loss: 1581.2441\n",
            "Epoch 463/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 17.2426 - val_loss: 1448.3286\n",
            "Epoch 464/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 22.7564 - val_loss: 1798.5697\n",
            "Epoch 465/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 32.9840 - val_loss: 1347.1257\n",
            "Epoch 466/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 23.7832 - val_loss: 1608.2119\n",
            "Epoch 467/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 17.6620 - val_loss: 1513.2332\n",
            "Epoch 468/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 18.2385 - val_loss: 1565.6084\n",
            "Epoch 469/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 18.5014 - val_loss: 1426.6345\n",
            "Epoch 470/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 24.2838 - val_loss: 1813.7734\n",
            "Epoch 471/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 31.0912 - val_loss: 1491.8691\n",
            "Epoch 472/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 17.4727 - val_loss: 1579.1309\n",
            "Epoch 473/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.0487 - val_loss: 1584.2515\n",
            "Epoch 474/500\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 22.8110 - val_loss: 1357.8336\n",
            "Epoch 475/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 23.9925 - val_loss: 1555.2068\n",
            "Epoch 476/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.0623 - val_loss: 1612.8403\n",
            "Epoch 477/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 19.6032 - val_loss: 1389.2708\n",
            "Epoch 478/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 23.2751 - val_loss: 1706.4817\n",
            "Epoch 479/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 28.4587 - val_loss: 1448.5746\n",
            "Epoch 480/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 18.8461 - val_loss: 1541.8328\n",
            "Epoch 481/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.2550 - val_loss: 1460.1534\n",
            "Epoch 482/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 21.9430 - val_loss: 1783.6223\n",
            "Epoch 483/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 27.9686 - val_loss: 1368.1859\n",
            "Epoch 484/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 28.1136 - val_loss: 1689.1403\n",
            "Epoch 485/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 18.6491 - val_loss: 1646.4877\n",
            "Epoch 486/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.3620 - val_loss: 1487.6578\n",
            "Epoch 487/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 19.6482 - val_loss: 1750.1838\n",
            "Epoch 488/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 24.2419 - val_loss: 1400.6489\n",
            "Epoch 489/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 24.0194 - val_loss: 1604.3226\n",
            "Epoch 490/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 17.7754 - val_loss: 1416.1471\n",
            "Epoch 491/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 24.7757 - val_loss: 1638.7693\n",
            "Epoch 492/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 20.5794 - val_loss: 1452.1865\n",
            "Epoch 493/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 22.3606 - val_loss: 1569.5945\n",
            "Epoch 494/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 16.8558 - val_loss: 1551.0068\n",
            "Epoch 495/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 16.8189 - val_loss: 1487.0988\n",
            "Epoch 496/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 17.7724 - val_loss: 1713.8025\n",
            "Epoch 497/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 32.2276 - val_loss: 1322.4697\n",
            "Epoch 498/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 26.4822 - val_loss: 1519.9000\n",
            "Epoch 499/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 16.8646 - val_loss: 1620.5271\n",
            "Epoch 500/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 17.5465 - val_loss: 1479.7839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ZXmJ5XWX8wkF",
        "outputId": "5f85120b-d6d8-46d9-ef0d-b2cc56716d38"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(result.history['loss'])\n",
        "plt.plot(result.history['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciyylvzA_ifG"
      },
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4c1Vh_Ntb_5"
      },
      "source": [
        "## Batchnormalization, Activation 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES4T7g8rLZT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfd633e-3a39-4ca3-cfa7-d28dec03312b"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "boston = pd.read_csv(\"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\")\n",
        "print(boston.columns)\n",
        "x_boston = boston.drop(['medv'], axis=1)\n",
        "y_boston = boston[['medv']]\n",
        "print(x_boston.shape, y_boston.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
            "       'ptratio', 'b', 'lstat', 'medv'],\n",
            "      dtype='object')\n",
            "(506, 13) (506, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG0wQvectbWp"
      },
      "source": [
        "X = tf.keras.Input(shape=[13])\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(8)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(1)(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1R9M27Y406cc",
        "outputId": "ae30469e-7bc7-49a8-a15f-0896938695f2"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=1000, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 4.0007 - val_loss: 94.6856\n",
            "Epoch 2/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4242 - val_loss: 95.5211\n",
            "Epoch 3/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.1664 - val_loss: 94.8498\n",
            "Epoch 4/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4057 - val_loss: 93.1639\n",
            "Epoch 5/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.8173 - val_loss: 90.8044\n",
            "Epoch 6/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.2101 - val_loss: 89.7682\n",
            "Epoch 7/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.6329 - val_loss: 87.3575\n",
            "Epoch 8/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.2325 - val_loss: 86.1275\n",
            "Epoch 9/1000\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 3.6340 - val_loss: 85.0561\n",
            "Epoch 10/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.8530 - val_loss: 86.1311\n",
            "Epoch 11/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.2039 - val_loss: 88.0518\n",
            "Epoch 12/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3471 - val_loss: 91.7738\n",
            "Epoch 13/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.1831 - val_loss: 94.7573\n",
            "Epoch 14/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.9821 - val_loss: 94.5490\n",
            "Epoch 15/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8677 - val_loss: 93.7944\n",
            "Epoch 16/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7898 - val_loss: 95.0402\n",
            "Epoch 17/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.4690 - val_loss: 95.7476\n",
            "Epoch 18/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 4.3398 - val_loss: 94.6863\n",
            "Epoch 19/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.3603 - val_loss: 96.3960\n",
            "Epoch 20/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.6392 - val_loss: 96.7497\n",
            "Epoch 21/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3498 - val_loss: 95.7256\n",
            "Epoch 22/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.8621 - val_loss: 91.7643\n",
            "Epoch 23/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0678 - val_loss: 87.4946\n",
            "Epoch 24/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.8869 - val_loss: 86.4954\n",
            "Epoch 25/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3846 - val_loss: 86.9189\n",
            "Epoch 26/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.2211 - val_loss: 88.4397\n",
            "Epoch 27/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.0308 - val_loss: 90.0202\n",
            "Epoch 28/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.5463 - val_loss: 86.9335\n",
            "Epoch 29/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2673 - val_loss: 84.3356\n",
            "Epoch 30/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.5014 - val_loss: 83.5886\n",
            "Epoch 31/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.9728 - val_loss: 84.1627\n",
            "Epoch 32/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5324 - val_loss: 85.7689\n",
            "Epoch 33/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.8385 - val_loss: 87.8362\n",
            "Epoch 34/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9958 - val_loss: 87.6781\n",
            "Epoch 35/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.9640 - val_loss: 87.5791\n",
            "Epoch 36/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6510 - val_loss: 86.9138\n",
            "Epoch 37/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.9167 - val_loss: 86.9002\n",
            "Epoch 38/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9602 - val_loss: 86.8680\n",
            "Epoch 39/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6922 - val_loss: 88.2548\n",
            "Epoch 40/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.1407 - val_loss: 91.0421\n",
            "Epoch 41/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.6079 - val_loss: 92.6328\n",
            "Epoch 42/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9362 - val_loss: 93.1553\n",
            "Epoch 43/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7753 - val_loss: 91.5382\n",
            "Epoch 44/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.4000 - val_loss: 89.7611\n",
            "Epoch 45/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9205 - val_loss: 87.5550\n",
            "Epoch 46/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8093 - val_loss: 86.4463\n",
            "Epoch 47/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8385 - val_loss: 86.4273\n",
            "Epoch 48/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.5811 - val_loss: 86.9390\n",
            "Epoch 49/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.7459 - val_loss: 87.6553\n",
            "Epoch 50/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.5277 - val_loss: 87.6269\n",
            "Epoch 51/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.0319 - val_loss: 89.3918\n",
            "Epoch 52/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2859 - val_loss: 91.7454\n",
            "Epoch 53/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9736 - val_loss: 90.7384\n",
            "Epoch 54/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2915 - val_loss: 88.9266\n",
            "Epoch 55/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.0953 - val_loss: 86.8131\n",
            "Epoch 56/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8802 - val_loss: 85.7603\n",
            "Epoch 57/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.5073 - val_loss: 86.0275\n",
            "Epoch 58/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9181 - val_loss: 87.2243\n",
            "Epoch 59/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.7239 - val_loss: 88.4087\n",
            "Epoch 60/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3597 - val_loss: 88.9974\n",
            "Epoch 61/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3114 - val_loss: 87.9810\n",
            "Epoch 62/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.6919 - val_loss: 87.5371\n",
            "Epoch 63/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9508 - val_loss: 87.2741\n",
            "Epoch 64/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3078 - val_loss: 87.6446\n",
            "Epoch 65/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8535 - val_loss: 87.1038\n",
            "Epoch 66/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.9891 - val_loss: 86.4345\n",
            "Epoch 67/1000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 5.3498 - val_loss: 86.2792\n",
            "Epoch 68/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.9629 - val_loss: 85.7755\n",
            "Epoch 69/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.0337 - val_loss: 86.1690\n",
            "Epoch 70/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4277 - val_loss: 87.2716\n",
            "Epoch 71/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.9863 - val_loss: 89.5079\n",
            "Epoch 72/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3801 - val_loss: 92.6946\n",
            "Epoch 73/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7628 - val_loss: 92.8377\n",
            "Epoch 74/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 5.2898 - val_loss: 91.0405\n",
            "Epoch 75/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2080 - val_loss: 88.9567\n",
            "Epoch 76/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8020 - val_loss: 89.0987\n",
            "Epoch 77/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.1872 - val_loss: 87.2934\n",
            "Epoch 78/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.5314 - val_loss: 86.3444\n",
            "Epoch 79/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.4777 - val_loss: 86.6802\n",
            "Epoch 80/1000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.8502 - val_loss: 88.1932\n",
            "Epoch 81/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3193 - val_loss: 89.2216\n",
            "Epoch 82/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8028 - val_loss: 89.5660\n",
            "Epoch 83/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.1997 - val_loss: 89.5590\n",
            "Epoch 84/1000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.6716 - val_loss: 88.8109\n",
            "Epoch 85/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3151 - val_loss: 88.2867\n",
            "Epoch 86/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.7860 - val_loss: 87.7370\n",
            "Epoch 87/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.2277 - val_loss: 87.1280\n",
            "Epoch 88/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 2.7546 - val_loss: 86.8601\n",
            "Epoch 89/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.8529 - val_loss: 86.4224\n",
            "Epoch 90/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.0518 - val_loss: 84.6607\n",
            "Epoch 91/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.0094 - val_loss: 84.2054\n",
            "Epoch 92/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.5261 - val_loss: 84.1348\n",
            "Epoch 93/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.2961 - val_loss: 83.4651\n",
            "Epoch 94/1000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.3372 - val_loss: 83.7844\n",
            "Epoch 95/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 5.2692 - val_loss: 84.3594\n",
            "Epoch 96/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.8982 - val_loss: 82.6387\n",
            "Epoch 97/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.9479 - val_loss: 83.0556\n",
            "Epoch 98/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7922 - val_loss: 84.8178\n",
            "Epoch 99/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.1852 - val_loss: 85.6658\n",
            "Epoch 100/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2873 - val_loss: 85.0816\n",
            "Epoch 101/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.6575 - val_loss: 84.7870\n",
            "Epoch 102/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3516 - val_loss: 86.1308\n",
            "Epoch 103/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5731 - val_loss: 86.4405\n",
            "Epoch 104/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.8166 - val_loss: 86.3273\n",
            "Epoch 105/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9055 - val_loss: 86.5572\n",
            "Epoch 106/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.5444 - val_loss: 85.9411\n",
            "Epoch 107/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2689 - val_loss: 85.8742\n",
            "Epoch 108/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2794 - val_loss: 85.9932\n",
            "Epoch 109/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.6438 - val_loss: 85.7682\n",
            "Epoch 110/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3638 - val_loss: 85.7356\n",
            "Epoch 111/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9728 - val_loss: 85.8088\n",
            "Epoch 112/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.1116 - val_loss: 85.6530\n",
            "Epoch 113/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.9809 - val_loss: 85.8034\n",
            "Epoch 114/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.7211 - val_loss: 85.0174\n",
            "Epoch 115/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.0748 - val_loss: 84.0163\n",
            "Epoch 116/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1383 - val_loss: 84.3961\n",
            "Epoch 117/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2069 - val_loss: 85.5382\n",
            "Epoch 118/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.5847 - val_loss: 86.1597\n",
            "Epoch 119/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.7402 - val_loss: 86.0483\n",
            "Epoch 120/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.0046 - val_loss: 85.8055\n",
            "Epoch 121/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.8453 - val_loss: 85.3039\n",
            "Epoch 122/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.2543 - val_loss: 85.4712\n",
            "Epoch 123/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.2160 - val_loss: 85.3775\n",
            "Epoch 124/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9836 - val_loss: 86.6674\n",
            "Epoch 125/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8088 - val_loss: 87.1930\n",
            "Epoch 126/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.6912 - val_loss: 87.5397\n",
            "Epoch 127/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.2110 - val_loss: 86.7738\n",
            "Epoch 128/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.9970 - val_loss: 85.1726\n",
            "Epoch 129/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.9583 - val_loss: 84.5266\n",
            "Epoch 130/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1992 - val_loss: 83.8999\n",
            "Epoch 131/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 6.2174 - val_loss: 83.5318\n",
            "Epoch 132/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6412 - val_loss: 82.3638\n",
            "Epoch 133/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8154 - val_loss: 82.0657\n",
            "Epoch 134/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1567 - val_loss: 81.6167\n",
            "Epoch 135/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9951 - val_loss: 82.5185\n",
            "Epoch 136/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 2.7936 - val_loss: 84.9559\n",
            "Epoch 137/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.9774 - val_loss: 86.6933\n",
            "Epoch 138/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.1584 - val_loss: 87.4789\n",
            "Epoch 139/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.0623 - val_loss: 86.8603\n",
            "Epoch 140/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8245 - val_loss: 84.6904\n",
            "Epoch 141/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1175 - val_loss: 84.2320\n",
            "Epoch 142/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.4340 - val_loss: 83.6142\n",
            "Epoch 143/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9764 - val_loss: 81.9346\n",
            "Epoch 144/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.3193 - val_loss: 80.9441\n",
            "Epoch 145/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.5421 - val_loss: 81.2308\n",
            "Epoch 146/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.8887 - val_loss: 82.6387\n",
            "Epoch 147/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.3125 - val_loss: 83.9066\n",
            "Epoch 148/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.8352 - val_loss: 84.2593\n",
            "Epoch 149/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4356 - val_loss: 85.2650\n",
            "Epoch 150/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.0593 - val_loss: 85.1250\n",
            "Epoch 151/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.8321 - val_loss: 86.3000\n",
            "Epoch 152/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.4786 - val_loss: 88.1241\n",
            "Epoch 153/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 6.1184 - val_loss: 90.8040\n",
            "Epoch 154/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.2401 - val_loss: 89.4869\n",
            "Epoch 155/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.6455 - val_loss: 86.3582\n",
            "Epoch 156/1000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 2.9855 - val_loss: 84.2310\n",
            "Epoch 157/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.6398 - val_loss: 82.8391\n",
            "Epoch 158/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8576 - val_loss: 82.6500\n",
            "Epoch 159/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6167 - val_loss: 83.5109\n",
            "Epoch 160/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1369 - val_loss: 83.6681\n",
            "Epoch 161/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.5395 - val_loss: 84.8790\n",
            "Epoch 162/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.8548 - val_loss: 86.0132\n",
            "Epoch 163/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.8829 - val_loss: 87.2006\n",
            "Epoch 164/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.2453 - val_loss: 88.2252\n",
            "Epoch 165/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.8330 - val_loss: 89.1308\n",
            "Epoch 166/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1871 - val_loss: 87.9755\n",
            "Epoch 167/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3744 - val_loss: 87.2605\n",
            "Epoch 168/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.8082 - val_loss: 88.4616\n",
            "Epoch 169/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2509 - val_loss: 88.8385\n",
            "Epoch 170/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.8979 - val_loss: 87.2694\n",
            "Epoch 171/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2531 - val_loss: 85.0006\n",
            "Epoch 172/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.0181 - val_loss: 83.7069\n",
            "Epoch 173/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.6098 - val_loss: 82.8898\n",
            "Epoch 174/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.8863 - val_loss: 82.0907\n",
            "Epoch 175/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.6358 - val_loss: 83.6264\n",
            "Epoch 176/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9379 - val_loss: 85.4773\n",
            "Epoch 177/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1277 - val_loss: 86.2551\n",
            "Epoch 178/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.5036 - val_loss: 84.9563\n",
            "Epoch 179/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1379 - val_loss: 83.6181\n",
            "Epoch 180/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.9350 - val_loss: 83.6411\n",
            "Epoch 181/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.4962 - val_loss: 83.9518\n",
            "Epoch 182/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9109 - val_loss: 84.4606\n",
            "Epoch 183/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9393 - val_loss: 85.4670\n",
            "Epoch 184/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.1897 - val_loss: 86.1995\n",
            "Epoch 185/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7171 - val_loss: 86.4885\n",
            "Epoch 186/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.4282 - val_loss: 86.7643\n",
            "Epoch 187/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.8600 - val_loss: 86.3368\n",
            "Epoch 188/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2646 - val_loss: 86.0366\n",
            "Epoch 189/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.7828 - val_loss: 86.3763\n",
            "Epoch 190/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8358 - val_loss: 85.0130\n",
            "Epoch 191/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.1067 - val_loss: 83.3439\n",
            "Epoch 192/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.2819 - val_loss: 83.4486\n",
            "Epoch 193/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.7357 - val_loss: 84.4344\n",
            "Epoch 194/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.7775 - val_loss: 86.3635\n",
            "Epoch 195/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.9056 - val_loss: 87.3847\n",
            "Epoch 196/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.8241 - val_loss: 88.6577\n",
            "Epoch 197/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.4741 - val_loss: 89.7127\n",
            "Epoch 198/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2570 - val_loss: 88.6932\n",
            "Epoch 199/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1987 - val_loss: 86.8932\n",
            "Epoch 200/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.7397 - val_loss: 85.7092\n",
            "Epoch 201/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.9807 - val_loss: 85.3245\n",
            "Epoch 202/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.0779 - val_loss: 84.6157\n",
            "Epoch 203/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.2812 - val_loss: 83.1724\n",
            "Epoch 204/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0620 - val_loss: 83.3703\n",
            "Epoch 205/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.7633 - val_loss: 84.2309\n",
            "Epoch 206/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.0898 - val_loss: 84.6591\n",
            "Epoch 207/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.0045 - val_loss: 86.3038\n",
            "Epoch 208/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.6440 - val_loss: 89.0607\n",
            "Epoch 209/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8176 - val_loss: 91.7408\n",
            "Epoch 210/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2399 - val_loss: 90.0581\n",
            "Epoch 211/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7290 - val_loss: 86.4901\n",
            "Epoch 212/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.0083 - val_loss: 85.6152\n",
            "Epoch 213/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8565 - val_loss: 85.3442\n",
            "Epoch 214/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1130 - val_loss: 86.4146\n",
            "Epoch 215/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.0327 - val_loss: 87.7704\n",
            "Epoch 216/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9142 - val_loss: 86.6573\n",
            "Epoch 217/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0033 - val_loss: 85.4024\n",
            "Epoch 218/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.4098 - val_loss: 84.0860\n",
            "Epoch 219/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2532 - val_loss: 83.1578\n",
            "Epoch 220/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7311 - val_loss: 83.2088\n",
            "Epoch 221/1000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 3.7013 - val_loss: 82.4086\n",
            "Epoch 222/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1886 - val_loss: 81.8498\n",
            "Epoch 223/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3864 - val_loss: 82.9199\n",
            "Epoch 224/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.7552 - val_loss: 83.9995\n",
            "Epoch 225/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3925 - val_loss: 85.1972\n",
            "Epoch 226/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5939 - val_loss: 86.9028\n",
            "Epoch 227/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4009 - val_loss: 86.9651\n",
            "Epoch 228/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.0761 - val_loss: 86.1436\n",
            "Epoch 229/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1661 - val_loss: 84.3937\n",
            "Epoch 230/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3902 - val_loss: 83.5717\n",
            "Epoch 231/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3038 - val_loss: 82.9337\n",
            "Epoch 232/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.2520 - val_loss: 82.6016\n",
            "Epoch 233/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.4004 - val_loss: 82.2708\n",
            "Epoch 234/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.9211 - val_loss: 82.6739\n",
            "Epoch 235/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3405 - val_loss: 82.8014\n",
            "Epoch 236/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.8853 - val_loss: 83.2883\n",
            "Epoch 237/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.6093 - val_loss: 84.2116\n",
            "Epoch 238/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9567 - val_loss: 85.0935\n",
            "Epoch 239/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7413 - val_loss: 85.4402\n",
            "Epoch 240/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.5542 - val_loss: 86.2500\n",
            "Epoch 241/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.1208 - val_loss: 86.6171\n",
            "Epoch 242/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8948 - val_loss: 84.9642\n",
            "Epoch 243/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0770 - val_loss: 83.8247\n",
            "Epoch 244/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.6936 - val_loss: 82.2592\n",
            "Epoch 245/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.4236 - val_loss: 80.9914\n",
            "Epoch 246/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.6834 - val_loss: 80.3818\n",
            "Epoch 247/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6993 - val_loss: 80.5765\n",
            "Epoch 248/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.6069 - val_loss: 80.7858\n",
            "Epoch 249/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.3037 - val_loss: 81.1029\n",
            "Epoch 250/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 7.9612 - val_loss: 82.1657\n",
            "Epoch 251/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.3261 - val_loss: 83.2966\n",
            "Epoch 252/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.8452 - val_loss: 83.7244\n",
            "Epoch 253/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.0076 - val_loss: 84.0069\n",
            "Epoch 254/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0102 - val_loss: 84.8610\n",
            "Epoch 255/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.4324 - val_loss: 86.5072\n",
            "Epoch 256/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2520 - val_loss: 85.8958\n",
            "Epoch 257/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.9409 - val_loss: 85.5046\n",
            "Epoch 258/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9619 - val_loss: 84.3705\n",
            "Epoch 259/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.0542 - val_loss: 84.4066\n",
            "Epoch 260/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9727 - val_loss: 85.0679\n",
            "Epoch 261/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 5.0081 - val_loss: 83.9792\n",
            "Epoch 262/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.8175 - val_loss: 83.3764\n",
            "Epoch 263/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.5565 - val_loss: 82.3776\n",
            "Epoch 264/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.2849 - val_loss: 81.7401\n",
            "Epoch 265/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.8873 - val_loss: 81.7540\n",
            "Epoch 266/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.3077 - val_loss: 81.8673\n",
            "Epoch 267/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.9375 - val_loss: 82.0462\n",
            "Epoch 268/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.5570 - val_loss: 82.0985\n",
            "Epoch 269/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.5994 - val_loss: 82.8880\n",
            "Epoch 270/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.7428 - val_loss: 83.4523\n",
            "Epoch 271/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.6950 - val_loss: 84.5325\n",
            "Epoch 272/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.8464 - val_loss: 85.8138\n",
            "Epoch 273/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.4825 - val_loss: 86.3330\n",
            "Epoch 274/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9390 - val_loss: 86.1469\n",
            "Epoch 275/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.0111 - val_loss: 86.7427\n",
            "Epoch 276/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1810 - val_loss: 88.1393\n",
            "Epoch 277/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5801 - val_loss: 90.2676\n",
            "Epoch 278/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.9094 - val_loss: 91.6660\n",
            "Epoch 279/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.6661 - val_loss: 90.8559\n",
            "Epoch 280/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2456 - val_loss: 89.2117\n",
            "Epoch 281/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6741 - val_loss: 86.5458\n",
            "Epoch 282/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.0726 - val_loss: 84.9441\n",
            "Epoch 283/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2346 - val_loss: 84.0595\n",
            "Epoch 284/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.8325 - val_loss: 84.1345\n",
            "Epoch 285/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2610 - val_loss: 84.2304\n",
            "Epoch 286/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.3435 - val_loss: 84.5981\n",
            "Epoch 287/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.8941 - val_loss: 85.1980\n",
            "Epoch 288/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.6597 - val_loss: 85.2683\n",
            "Epoch 289/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.0326 - val_loss: 84.8091\n",
            "Epoch 290/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.8834 - val_loss: 85.1442\n",
            "Epoch 291/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.8096 - val_loss: 84.7658\n",
            "Epoch 292/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.3615 - val_loss: 84.4776\n",
            "Epoch 293/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.8813 - val_loss: 83.9011\n",
            "Epoch 294/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1232 - val_loss: 83.9158\n",
            "Epoch 295/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3556 - val_loss: 84.0725\n",
            "Epoch 296/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.7389 - val_loss: 84.6735\n",
            "Epoch 297/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4737 - val_loss: 84.2651\n",
            "Epoch 298/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3954 - val_loss: 84.6029\n",
            "Epoch 299/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9039 - val_loss: 84.4162\n",
            "Epoch 300/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3828 - val_loss: 84.2950\n",
            "Epoch 301/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.5178 - val_loss: 83.6584\n",
            "Epoch 302/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9144 - val_loss: 82.9808\n",
            "Epoch 303/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.7881 - val_loss: 83.4754\n",
            "Epoch 304/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.2479 - val_loss: 84.3101\n",
            "Epoch 305/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.0193 - val_loss: 85.3123\n",
            "Epoch 306/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.2883 - val_loss: 86.6141\n",
            "Epoch 307/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2431 - val_loss: 89.0246\n",
            "Epoch 308/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.1246 - val_loss: 91.7999\n",
            "Epoch 309/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3573 - val_loss: 92.7074\n",
            "Epoch 310/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.6163 - val_loss: 89.7452\n",
            "Epoch 311/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3057 - val_loss: 85.6777\n",
            "Epoch 312/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.8866 - val_loss: 83.4619\n",
            "Epoch 313/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.9202 - val_loss: 82.3639\n",
            "Epoch 314/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2536 - val_loss: 81.7296\n",
            "Epoch 315/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.5287 - val_loss: 83.3237\n",
            "Epoch 316/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.9492 - val_loss: 84.6997\n",
            "Epoch 317/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3555 - val_loss: 86.8287\n",
            "Epoch 318/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2760 - val_loss: 87.0651\n",
            "Epoch 319/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5556 - val_loss: 87.9310\n",
            "Epoch 320/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1569 - val_loss: 88.9978\n",
            "Epoch 321/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2093 - val_loss: 87.8416\n",
            "Epoch 322/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.8498 - val_loss: 87.0974\n",
            "Epoch 323/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.8762 - val_loss: 87.7328\n",
            "Epoch 324/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.4597 - val_loss: 88.6497\n",
            "Epoch 325/1000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 4.3244 - val_loss: 89.6096\n",
            "Epoch 326/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.3074 - val_loss: 86.9345\n",
            "Epoch 327/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.4192 - val_loss: 85.0736\n",
            "Epoch 328/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.3846 - val_loss: 85.6901\n",
            "Epoch 329/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.3395 - val_loss: 87.2980\n",
            "Epoch 330/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.1616 - val_loss: 88.3724\n",
            "Epoch 331/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.0573 - val_loss: 88.6843\n",
            "Epoch 332/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.1571 - val_loss: 88.3708\n",
            "Epoch 333/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 4.8363 - val_loss: 88.6372\n",
            "Epoch 334/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.0604 - val_loss: 87.4906\n",
            "Epoch 335/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.2349 - val_loss: 84.8577\n",
            "Epoch 336/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1349 - val_loss: 82.4620\n",
            "Epoch 337/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7456 - val_loss: 81.7284\n",
            "Epoch 338/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.4461 - val_loss: 81.9653\n",
            "Epoch 339/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 6.5420 - val_loss: 84.7003\n",
            "Epoch 340/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7502 - val_loss: 87.0714\n",
            "Epoch 341/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 2.7441 - val_loss: 84.1558\n",
            "Epoch 342/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.0660 - val_loss: 81.8484\n",
            "Epoch 343/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.8165 - val_loss: 80.1848\n",
            "Epoch 344/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9518 - val_loss: 80.6515\n",
            "Epoch 345/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.7260 - val_loss: 80.9857\n",
            "Epoch 346/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.0558 - val_loss: 81.6062\n",
            "Epoch 347/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 3.3412 - val_loss: 82.4792\n",
            "Epoch 348/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2726 - val_loss: 83.1104\n",
            "Epoch 349/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.5846 - val_loss: 83.1415\n",
            "Epoch 350/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.0572 - val_loss: 83.7831\n",
            "Epoch 351/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6893 - val_loss: 82.9267\n",
            "Epoch 352/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0360 - val_loss: 81.1321\n",
            "Epoch 353/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.7615 - val_loss: 80.4621\n",
            "Epoch 354/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7649 - val_loss: 82.8017\n",
            "Epoch 355/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0949 - val_loss: 82.5938\n",
            "Epoch 356/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.4701 - val_loss: 80.5328\n",
            "Epoch 357/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1300 - val_loss: 79.6624\n",
            "Epoch 358/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.8932 - val_loss: 80.7234\n",
            "Epoch 359/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8946 - val_loss: 81.4175\n",
            "Epoch 360/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2940 - val_loss: 82.5229\n",
            "Epoch 361/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8171 - val_loss: 84.8565\n",
            "Epoch 362/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.5023 - val_loss: 86.3072\n",
            "Epoch 363/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.0650 - val_loss: 86.6539\n",
            "Epoch 364/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.1666 - val_loss: 85.7024\n",
            "Epoch 365/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6454 - val_loss: 85.5822\n",
            "Epoch 366/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7794 - val_loss: 86.6861\n",
            "Epoch 367/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3920 - val_loss: 86.7938\n",
            "Epoch 368/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0805 - val_loss: 84.6630\n",
            "Epoch 369/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2066 - val_loss: 83.2080\n",
            "Epoch 370/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.7033 - val_loss: 82.2458\n",
            "Epoch 371/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.3667 - val_loss: 80.6060\n",
            "Epoch 372/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.3843 - val_loss: 79.2249\n",
            "Epoch 373/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.4497 - val_loss: 79.4684\n",
            "Epoch 374/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2689 - val_loss: 79.7918\n",
            "Epoch 375/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.6150 - val_loss: 80.7499\n",
            "Epoch 376/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.2537 - val_loss: 81.0305\n",
            "Epoch 377/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1694 - val_loss: 81.6214\n",
            "Epoch 378/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.9483 - val_loss: 82.8820\n",
            "Epoch 379/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.6404 - val_loss: 84.5326\n",
            "Epoch 380/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 5.4532 - val_loss: 85.5491\n",
            "Epoch 381/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.5390 - val_loss: 85.6845\n",
            "Epoch 382/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3031 - val_loss: 85.5863\n",
            "Epoch 383/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9609 - val_loss: 86.6545\n",
            "Epoch 384/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.3154 - val_loss: 86.0423\n",
            "Epoch 385/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.1610 - val_loss: 82.8564\n",
            "Epoch 386/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8550 - val_loss: 81.2450\n",
            "Epoch 387/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.6843 - val_loss: 81.6237\n",
            "Epoch 388/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.2949 - val_loss: 81.4104\n",
            "Epoch 389/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7117 - val_loss: 83.1492\n",
            "Epoch 390/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.3387 - val_loss: 85.1695\n",
            "Epoch 391/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8071 - val_loss: 84.7001\n",
            "Epoch 392/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.8269 - val_loss: 82.4275\n",
            "Epoch 393/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7139 - val_loss: 80.8266\n",
            "Epoch 394/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.4787 - val_loss: 81.8971\n",
            "Epoch 395/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2333 - val_loss: 83.7760\n",
            "Epoch 396/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6719 - val_loss: 85.7775\n",
            "Epoch 397/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.1034 - val_loss: 84.7740\n",
            "Epoch 398/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.1621 - val_loss: 84.8716\n",
            "Epoch 399/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3064 - val_loss: 83.8506\n",
            "Epoch 400/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2124 - val_loss: 83.3281\n",
            "Epoch 401/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8611 - val_loss: 83.5154\n",
            "Epoch 402/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6141 - val_loss: 83.6255\n",
            "Epoch 403/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7668 - val_loss: 81.9027\n",
            "Epoch 404/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.9824 - val_loss: 80.7232\n",
            "Epoch 405/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.2644 - val_loss: 80.2742\n",
            "Epoch 406/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9490 - val_loss: 78.3941\n",
            "Epoch 407/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1633 - val_loss: 77.6676\n",
            "Epoch 408/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7869 - val_loss: 78.2151\n",
            "Epoch 409/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.5335 - val_loss: 78.9133\n",
            "Epoch 410/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.0110 - val_loss: 80.3193\n",
            "Epoch 411/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.4299 - val_loss: 82.2251\n",
            "Epoch 412/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 6.8028 - val_loss: 83.2457\n",
            "Epoch 413/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.1328 - val_loss: 82.2893\n",
            "Epoch 414/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.9297 - val_loss: 80.7455\n",
            "Epoch 415/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4034 - val_loss: 81.6004\n",
            "Epoch 416/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.4987 - val_loss: 82.6396\n",
            "Epoch 417/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.5558 - val_loss: 84.1683\n",
            "Epoch 418/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7754 - val_loss: 84.1678\n",
            "Epoch 419/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0901 - val_loss: 82.6707\n",
            "Epoch 420/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.7301 - val_loss: 81.1040\n",
            "Epoch 421/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.8617 - val_loss: 80.6366\n",
            "Epoch 422/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.5297 - val_loss: 80.1333\n",
            "Epoch 423/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6363 - val_loss: 80.2187\n",
            "Epoch 424/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.8630 - val_loss: 81.8437\n",
            "Epoch 425/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.0330 - val_loss: 83.4920\n",
            "Epoch 426/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.7701 - val_loss: 84.3582\n",
            "Epoch 427/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1865 - val_loss: 84.3444\n",
            "Epoch 428/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.7854 - val_loss: 83.8527\n",
            "Epoch 429/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.8405 - val_loss: 83.6742\n",
            "Epoch 430/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4684 - val_loss: 83.3957\n",
            "Epoch 431/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.6485 - val_loss: 82.4814\n",
            "Epoch 432/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.9212 - val_loss: 81.7223\n",
            "Epoch 433/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.6970 - val_loss: 81.4512\n",
            "Epoch 434/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1195 - val_loss: 81.9361\n",
            "Epoch 435/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.8925 - val_loss: 81.7035\n",
            "Epoch 436/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.5581 - val_loss: 81.3807\n",
            "Epoch 437/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.9020 - val_loss: 81.4848\n",
            "Epoch 438/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.0159 - val_loss: 81.4780\n",
            "Epoch 439/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7375 - val_loss: 81.7441\n",
            "Epoch 440/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.5341 - val_loss: 81.1761\n",
            "Epoch 441/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.4433 - val_loss: 80.7121\n",
            "Epoch 442/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0201 - val_loss: 82.2520\n",
            "Epoch 443/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8241 - val_loss: 83.7012\n",
            "Epoch 444/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1139 - val_loss: 84.1587\n",
            "Epoch 445/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 5.0852 - val_loss: 83.6096\n",
            "Epoch 446/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 6.3265 - val_loss: 83.5074\n",
            "Epoch 447/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.3041 - val_loss: 82.6626\n",
            "Epoch 448/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.2697 - val_loss: 82.1512\n",
            "Epoch 449/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.7176 - val_loss: 80.3849\n",
            "Epoch 450/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.1724 - val_loss: 78.7269\n",
            "Epoch 451/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2716 - val_loss: 78.2161\n",
            "Epoch 452/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.0782 - val_loss: 79.0524\n",
            "Epoch 453/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.7770 - val_loss: 80.6081\n",
            "Epoch 454/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.1095 - val_loss: 84.8697\n",
            "Epoch 455/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.0511 - val_loss: 88.1779\n",
            "Epoch 456/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.1609 - val_loss: 90.7652\n",
            "Epoch 457/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.5043 - val_loss: 89.2504\n",
            "Epoch 458/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.0559 - val_loss: 87.2198\n",
            "Epoch 459/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9203 - val_loss: 84.0276\n",
            "Epoch 460/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7616 - val_loss: 83.0399\n",
            "Epoch 461/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3432 - val_loss: 82.4253\n",
            "Epoch 462/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8422 - val_loss: 82.5021\n",
            "Epoch 463/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.2987 - val_loss: 82.1368\n",
            "Epoch 464/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.8037 - val_loss: 81.8989\n",
            "Epoch 465/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 5.6856 - val_loss: 80.2446\n",
            "Epoch 466/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.5675 - val_loss: 79.7098\n",
            "Epoch 467/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.7527 - val_loss: 79.3771\n",
            "Epoch 468/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.5141 - val_loss: 78.9487\n",
            "Epoch 469/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 4.1473 - val_loss: 79.1894\n",
            "Epoch 470/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.8436 - val_loss: 78.9925\n",
            "Epoch 471/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.1474 - val_loss: 78.8407\n",
            "Epoch 472/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1428 - val_loss: 78.7992\n",
            "Epoch 473/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.4179 - val_loss: 78.6148\n",
            "Epoch 474/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.8173 - val_loss: 79.2769\n",
            "Epoch 475/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1769 - val_loss: 79.3078\n",
            "Epoch 476/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.7412 - val_loss: 79.0471\n",
            "Epoch 477/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4756 - val_loss: 78.8057\n",
            "Epoch 478/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.8714 - val_loss: 78.4301\n",
            "Epoch 479/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5699 - val_loss: 78.3526\n",
            "Epoch 480/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.2530 - val_loss: 78.8507\n",
            "Epoch 481/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.4385 - val_loss: 81.4871\n",
            "Epoch 482/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9974 - val_loss: 85.5066\n",
            "Epoch 483/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7730 - val_loss: 84.5405\n",
            "Epoch 484/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2420 - val_loss: 82.3443\n",
            "Epoch 485/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3615 - val_loss: 81.4229\n",
            "Epoch 486/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2033 - val_loss: 82.0709\n",
            "Epoch 487/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6870 - val_loss: 82.8192\n",
            "Epoch 488/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6955 - val_loss: 83.4426\n",
            "Epoch 489/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.7162 - val_loss: 81.4460\n",
            "Epoch 490/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1427 - val_loss: 79.9924\n",
            "Epoch 491/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.5456 - val_loss: 79.6141\n",
            "Epoch 492/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.5661 - val_loss: 80.0219\n",
            "Epoch 493/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7137 - val_loss: 80.3350\n",
            "Epoch 494/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.6407 - val_loss: 80.9546\n",
            "Epoch 495/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3275 - val_loss: 80.4532\n",
            "Epoch 496/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.6335 - val_loss: 80.2203\n",
            "Epoch 497/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.1198 - val_loss: 79.5340\n",
            "Epoch 498/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.2046 - val_loss: 79.9748\n",
            "Epoch 499/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 6.6080 - val_loss: 81.3718\n",
            "Epoch 500/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8849 - val_loss: 83.3321\n",
            "Epoch 501/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.7722 - val_loss: 83.1029\n",
            "Epoch 502/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9489 - val_loss: 82.7447\n",
            "Epoch 503/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.0672 - val_loss: 82.5831\n",
            "Epoch 504/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0243 - val_loss: 82.8033\n",
            "Epoch 505/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.8133 - val_loss: 82.3465\n",
            "Epoch 506/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.8437 - val_loss: 82.4146\n",
            "Epoch 507/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7179 - val_loss: 81.8349\n",
            "Epoch 508/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.4537 - val_loss: 81.9517\n",
            "Epoch 509/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 2.8479 - val_loss: 81.8966\n",
            "Epoch 510/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 4.1633 - val_loss: 82.6634\n",
            "Epoch 511/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.2616 - val_loss: 83.4274\n",
            "Epoch 512/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.1386 - val_loss: 82.6860\n",
            "Epoch 513/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8820 - val_loss: 82.4779\n",
            "Epoch 514/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9215 - val_loss: 82.4542\n",
            "Epoch 515/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9781 - val_loss: 82.3415\n",
            "Epoch 516/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.8340 - val_loss: 83.0964\n",
            "Epoch 517/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6278 - val_loss: 82.4942\n",
            "Epoch 518/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4453 - val_loss: 80.7367\n",
            "Epoch 519/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8621 - val_loss: 79.6329\n",
            "Epoch 520/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.1290 - val_loss: 79.1353\n",
            "Epoch 521/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0847 - val_loss: 79.3071\n",
            "Epoch 522/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1508 - val_loss: 81.3212\n",
            "Epoch 523/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.0090 - val_loss: 83.5854\n",
            "Epoch 524/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6400 - val_loss: 85.1731\n",
            "Epoch 525/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.4903 - val_loss: 85.4406\n",
            "Epoch 526/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.8300 - val_loss: 82.2350\n",
            "Epoch 527/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2334 - val_loss: 81.0754\n",
            "Epoch 528/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2910 - val_loss: 81.5273\n",
            "Epoch 529/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9619 - val_loss: 82.1827\n",
            "Epoch 530/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9052 - val_loss: 82.3334\n",
            "Epoch 531/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.4191 - val_loss: 81.9733\n",
            "Epoch 532/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6168 - val_loss: 82.2558\n",
            "Epoch 533/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.9615 - val_loss: 81.8291\n",
            "Epoch 534/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.7872 - val_loss: 80.6520\n",
            "Epoch 535/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 5.8922 - val_loss: 79.4238\n",
            "Epoch 536/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.1332 - val_loss: 78.4602\n",
            "Epoch 537/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4184 - val_loss: 77.7933\n",
            "Epoch 538/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6711 - val_loss: 77.2203\n",
            "Epoch 539/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.6699 - val_loss: 77.3398\n",
            "Epoch 540/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.3488 - val_loss: 77.7646\n",
            "Epoch 541/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8934 - val_loss: 77.4579\n",
            "Epoch 542/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.8712 - val_loss: 77.9192\n",
            "Epoch 543/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.5461 - val_loss: 78.2737\n",
            "Epoch 544/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2121 - val_loss: 78.8403\n",
            "Epoch 545/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.7731 - val_loss: 79.5410\n",
            "Epoch 546/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.8376 - val_loss: 79.4891\n",
            "Epoch 547/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6609 - val_loss: 80.5747\n",
            "Epoch 548/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6086 - val_loss: 82.2794\n",
            "Epoch 549/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1574 - val_loss: 82.3775\n",
            "Epoch 550/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.3491 - val_loss: 81.3947\n",
            "Epoch 551/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6802 - val_loss: 80.9030\n",
            "Epoch 552/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.6976 - val_loss: 80.1893\n",
            "Epoch 553/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.9141 - val_loss: 79.7157\n",
            "Epoch 554/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.8929 - val_loss: 79.3250\n",
            "Epoch 555/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1605 - val_loss: 78.9449\n",
            "Epoch 556/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4914 - val_loss: 78.9053\n",
            "Epoch 557/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6063 - val_loss: 79.5643\n",
            "Epoch 558/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3948 - val_loss: 79.7121\n",
            "Epoch 559/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.1027 - val_loss: 79.7785\n",
            "Epoch 560/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.0883 - val_loss: 80.9120\n",
            "Epoch 561/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5321 - val_loss: 80.9609\n",
            "Epoch 562/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.5907 - val_loss: 80.2118\n",
            "Epoch 563/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9114 - val_loss: 80.5025\n",
            "Epoch 564/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7495 - val_loss: 82.0276\n",
            "Epoch 565/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.7157 - val_loss: 83.2503\n",
            "Epoch 566/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.9456 - val_loss: 84.7855\n",
            "Epoch 567/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0070 - val_loss: 86.3971\n",
            "Epoch 568/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.4088 - val_loss: 86.1218\n",
            "Epoch 569/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4950 - val_loss: 85.2488\n",
            "Epoch 570/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8094 - val_loss: 82.0405\n",
            "Epoch 571/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.0376 - val_loss: 80.1742\n",
            "Epoch 572/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2932 - val_loss: 79.6956\n",
            "Epoch 573/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.7078 - val_loss: 79.6952\n",
            "Epoch 574/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.6803 - val_loss: 80.2570\n",
            "Epoch 575/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.1416 - val_loss: 81.0091\n",
            "Epoch 576/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.4896 - val_loss: 80.9247\n",
            "Epoch 577/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.0002 - val_loss: 80.1330\n",
            "Epoch 578/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4864 - val_loss: 79.7755\n",
            "Epoch 579/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.2290 - val_loss: 80.0698\n",
            "Epoch 580/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.9224 - val_loss: 81.0390\n",
            "Epoch 581/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1738 - val_loss: 81.9706\n",
            "Epoch 582/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.8735 - val_loss: 81.4548\n",
            "Epoch 583/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 5.8760 - val_loss: 80.5667\n",
            "Epoch 584/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.1803 - val_loss: 80.5812\n",
            "Epoch 585/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.7154 - val_loss: 80.9212\n",
            "Epoch 586/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.0191 - val_loss: 79.8291\n",
            "Epoch 587/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 4.6219 - val_loss: 80.9144\n",
            "Epoch 588/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3546 - val_loss: 81.0731\n",
            "Epoch 589/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8642 - val_loss: 80.2852\n",
            "Epoch 590/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0425 - val_loss: 80.6913\n",
            "Epoch 591/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.6528 - val_loss: 82.9716\n",
            "Epoch 592/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3324 - val_loss: 87.1821\n",
            "Epoch 593/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8709 - val_loss: 89.8663\n",
            "Epoch 594/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3241 - val_loss: 89.1900\n",
            "Epoch 595/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.8408 - val_loss: 85.4358\n",
            "Epoch 596/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.1850 - val_loss: 82.5434\n",
            "Epoch 597/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.8534 - val_loss: 82.9589\n",
            "Epoch 598/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.1175 - val_loss: 83.2083\n",
            "Epoch 599/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9199 - val_loss: 82.8789\n",
            "Epoch 600/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8070 - val_loss: 83.1135\n",
            "Epoch 601/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.6744 - val_loss: 82.7596\n",
            "Epoch 602/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6315 - val_loss: 82.7235\n",
            "Epoch 603/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.1599 - val_loss: 81.8971\n",
            "Epoch 604/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0153 - val_loss: 82.2678\n",
            "Epoch 605/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.7261 - val_loss: 83.5367\n",
            "Epoch 606/1000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 5.0550 - val_loss: 84.2481\n",
            "Epoch 607/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.7858 - val_loss: 83.9735\n",
            "Epoch 608/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0800 - val_loss: 82.3504\n",
            "Epoch 609/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1431 - val_loss: 82.2529\n",
            "Epoch 610/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.0314 - val_loss: 81.6434\n",
            "Epoch 611/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6320 - val_loss: 80.4174\n",
            "Epoch 612/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1546 - val_loss: 80.0195\n",
            "Epoch 613/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4194 - val_loss: 80.5225\n",
            "Epoch 614/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2201 - val_loss: 80.3240\n",
            "Epoch 615/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0365 - val_loss: 79.5909\n",
            "Epoch 616/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.7452 - val_loss: 80.0528\n",
            "Epoch 617/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.1448 - val_loss: 80.3652\n",
            "Epoch 618/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.6412 - val_loss: 80.7769\n",
            "Epoch 619/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.1274 - val_loss: 81.0243\n",
            "Epoch 620/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7948 - val_loss: 81.0248\n",
            "Epoch 621/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4419 - val_loss: 80.6191\n",
            "Epoch 622/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.9818 - val_loss: 79.3656\n",
            "Epoch 623/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9741 - val_loss: 78.9053\n",
            "Epoch 624/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.1393 - val_loss: 79.0354\n",
            "Epoch 625/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.7887 - val_loss: 79.8165\n",
            "Epoch 626/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9096 - val_loss: 80.4750\n",
            "Epoch 627/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3917 - val_loss: 80.9681\n",
            "Epoch 628/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3839 - val_loss: 80.9945\n",
            "Epoch 629/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.6028 - val_loss: 81.1665\n",
            "Epoch 630/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4665 - val_loss: 81.0960\n",
            "Epoch 631/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.8281 - val_loss: 80.4965\n",
            "Epoch 632/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.6691 - val_loss: 80.7612\n",
            "Epoch 633/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2129 - val_loss: 81.2155\n",
            "Epoch 634/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.9078 - val_loss: 79.9448\n",
            "Epoch 635/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.8069 - val_loss: 79.7323\n",
            "Epoch 636/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.0666 - val_loss: 79.0376\n",
            "Epoch 637/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9095 - val_loss: 78.3104\n",
            "Epoch 638/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.6528 - val_loss: 78.1778\n",
            "Epoch 639/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.2139 - val_loss: 79.4169\n",
            "Epoch 640/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.1341 - val_loss: 80.1794\n",
            "Epoch 641/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.6622 - val_loss: 79.7900\n",
            "Epoch 642/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.1979 - val_loss: 79.4100\n",
            "Epoch 643/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4327 - val_loss: 78.7980\n",
            "Epoch 644/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9019 - val_loss: 78.1589\n",
            "Epoch 645/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7929 - val_loss: 77.7748\n",
            "Epoch 646/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.6811 - val_loss: 77.8064\n",
            "Epoch 647/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3626 - val_loss: 77.9645\n",
            "Epoch 648/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 3.3358 - val_loss: 78.5897\n",
            "Epoch 649/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.7851 - val_loss: 79.0389\n",
            "Epoch 650/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.0806 - val_loss: 78.9579\n",
            "Epoch 651/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2288 - val_loss: 80.6650\n",
            "Epoch 652/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.5923 - val_loss: 82.3100\n",
            "Epoch 653/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.6404 - val_loss: 81.1307\n",
            "Epoch 654/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1335 - val_loss: 80.0081\n",
            "Epoch 655/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9374 - val_loss: 78.0931\n",
            "Epoch 656/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7336 - val_loss: 78.0779\n",
            "Epoch 657/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.2295 - val_loss: 77.9060\n",
            "Epoch 658/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6992 - val_loss: 77.3665\n",
            "Epoch 659/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9713 - val_loss: 77.6870\n",
            "Epoch 660/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0126 - val_loss: 78.7612\n",
            "Epoch 661/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.5950 - val_loss: 79.1552\n",
            "Epoch 662/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.6913 - val_loss: 78.1887\n",
            "Epoch 663/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9732 - val_loss: 78.9177\n",
            "Epoch 664/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7858 - val_loss: 79.4416\n",
            "Epoch 665/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6843 - val_loss: 78.8422\n",
            "Epoch 666/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9187 - val_loss: 78.4146\n",
            "Epoch 667/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.2775 - val_loss: 77.7423\n",
            "Epoch 668/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.0175 - val_loss: 77.0828\n",
            "Epoch 669/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 5.8433 - val_loss: 77.4325\n",
            "Epoch 670/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.4052 - val_loss: 77.3468\n",
            "Epoch 671/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6884 - val_loss: 76.0322\n",
            "Epoch 672/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0055 - val_loss: 74.8550\n",
            "Epoch 673/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.6876 - val_loss: 76.1441\n",
            "Epoch 674/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.3386 - val_loss: 79.7713\n",
            "Epoch 675/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.1559 - val_loss: 89.4634\n",
            "Epoch 676/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2870 - val_loss: 96.1668\n",
            "Epoch 677/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 4.6349 - val_loss: 90.1635\n",
            "Epoch 678/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.7415 - val_loss: 79.3892\n",
            "Epoch 679/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.3021 - val_loss: 76.7945\n",
            "Epoch 680/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.4254 - val_loss: 80.8049\n",
            "Epoch 681/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.8115 - val_loss: 85.5451\n",
            "Epoch 682/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3073 - val_loss: 84.2450\n",
            "Epoch 683/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.2603 - val_loss: 80.0155\n",
            "Epoch 684/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.6415 - val_loss: 77.8982\n",
            "Epoch 685/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9979 - val_loss: 78.6734\n",
            "Epoch 686/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.3975 - val_loss: 79.7683\n",
            "Epoch 687/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3463 - val_loss: 79.7009\n",
            "Epoch 688/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9154 - val_loss: 79.4420\n",
            "Epoch 689/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.5748 - val_loss: 79.6950\n",
            "Epoch 690/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6091 - val_loss: 80.2946\n",
            "Epoch 691/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6601 - val_loss: 80.7316\n",
            "Epoch 692/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.0207 - val_loss: 80.3039\n",
            "Epoch 693/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9620 - val_loss: 78.5695\n",
            "Epoch 694/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.0933 - val_loss: 77.7808\n",
            "Epoch 695/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1563 - val_loss: 77.2160\n",
            "Epoch 696/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6294 - val_loss: 77.2356\n",
            "Epoch 697/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 3.0908 - val_loss: 77.6415\n",
            "Epoch 698/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.0853 - val_loss: 77.4725\n",
            "Epoch 699/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.0955 - val_loss: 77.6013\n",
            "Epoch 700/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.9769 - val_loss: 77.5844\n",
            "Epoch 701/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.7039 - val_loss: 77.3864\n",
            "Epoch 702/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6312 - val_loss: 76.2765\n",
            "Epoch 703/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.3237 - val_loss: 76.2142\n",
            "Epoch 704/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.5712 - val_loss: 77.2387\n",
            "Epoch 705/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7588 - val_loss: 78.8249\n",
            "Epoch 706/1000\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 3.7721 - val_loss: 80.4250\n",
            "Epoch 707/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.3312 - val_loss: 80.1923\n",
            "Epoch 708/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.9070 - val_loss: 78.0573\n",
            "Epoch 709/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.4301 - val_loss: 78.1397\n",
            "Epoch 710/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.6169 - val_loss: 80.0453\n",
            "Epoch 711/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2634 - val_loss: 80.6609\n",
            "Epoch 712/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6345 - val_loss: 78.9136\n",
            "Epoch 713/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0496 - val_loss: 78.6481\n",
            "Epoch 714/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.3190 - val_loss: 78.3365\n",
            "Epoch 715/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2021 - val_loss: 78.1560\n",
            "Epoch 716/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.4776 - val_loss: 78.1251\n",
            "Epoch 717/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.8170 - val_loss: 77.6308\n",
            "Epoch 718/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6586 - val_loss: 76.6628\n",
            "Epoch 719/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4605 - val_loss: 76.5841\n",
            "Epoch 720/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9603 - val_loss: 75.9919\n",
            "Epoch 721/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.7334 - val_loss: 76.2101\n",
            "Epoch 722/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 4.2089 - val_loss: 76.7020\n",
            "Epoch 723/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1063 - val_loss: 77.2635\n",
            "Epoch 724/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.6173 - val_loss: 78.0174\n",
            "Epoch 725/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.3385 - val_loss: 78.6872\n",
            "Epoch 726/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.5634 - val_loss: 79.5584\n",
            "Epoch 727/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6667 - val_loss: 80.3610\n",
            "Epoch 728/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.8613 - val_loss: 82.5036\n",
            "Epoch 729/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6696 - val_loss: 84.9303\n",
            "Epoch 730/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.8004 - val_loss: 85.2305\n",
            "Epoch 731/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.8092 - val_loss: 84.4872\n",
            "Epoch 732/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.4280 - val_loss: 81.8251\n",
            "Epoch 733/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.7830 - val_loss: 80.6377\n",
            "Epoch 734/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.5736 - val_loss: 79.1473\n",
            "Epoch 735/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.8067 - val_loss: 78.8481\n",
            "Epoch 736/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7299 - val_loss: 79.5723\n",
            "Epoch 737/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.2571 - val_loss: 80.9921\n",
            "Epoch 738/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9386 - val_loss: 80.2963\n",
            "Epoch 739/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.1248 - val_loss: 80.1334\n",
            "Epoch 740/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.0259 - val_loss: 79.0603\n",
            "Epoch 741/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1642 - val_loss: 77.7309\n",
            "Epoch 742/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.9894 - val_loss: 76.8593\n",
            "Epoch 743/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.2701 - val_loss: 77.6580\n",
            "Epoch 744/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.5381 - val_loss: 79.5916\n",
            "Epoch 745/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.0981 - val_loss: 79.7621\n",
            "Epoch 746/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 4.0862 - val_loss: 78.2011\n",
            "Epoch 747/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.8083 - val_loss: 77.5664\n",
            "Epoch 748/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1548 - val_loss: 76.9100\n",
            "Epoch 749/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8422 - val_loss: 77.4780\n",
            "Epoch 750/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.0544 - val_loss: 78.2317\n",
            "Epoch 751/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3389 - val_loss: 78.1953\n",
            "Epoch 752/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9752 - val_loss: 80.1695\n",
            "Epoch 753/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.7458 - val_loss: 82.2023\n",
            "Epoch 754/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 5.0751 - val_loss: 81.3915\n",
            "Epoch 755/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.1378 - val_loss: 78.8549\n",
            "Epoch 756/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.3579 - val_loss: 77.3805\n",
            "Epoch 757/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8936 - val_loss: 77.3112\n",
            "Epoch 758/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1218 - val_loss: 76.9645\n",
            "Epoch 759/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.8701 - val_loss: 77.3537\n",
            "Epoch 760/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.7281 - val_loss: 76.8040\n",
            "Epoch 761/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.6739 - val_loss: 76.4368\n",
            "Epoch 762/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.9385 - val_loss: 77.0483\n",
            "Epoch 763/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0388 - val_loss: 78.2754\n",
            "Epoch 764/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.2987 - val_loss: 77.6003\n",
            "Epoch 765/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.6113 - val_loss: 76.9429\n",
            "Epoch 766/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.9113 - val_loss: 77.4536\n",
            "Epoch 767/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.7309 - val_loss: 76.7810\n",
            "Epoch 768/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.5118 - val_loss: 76.4679\n",
            "Epoch 769/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.3585 - val_loss: 77.0303\n",
            "Epoch 770/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.0838 - val_loss: 78.1753\n",
            "Epoch 771/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.0880 - val_loss: 79.9343\n",
            "Epoch 772/1000\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 4.9030 - val_loss: 80.5965\n",
            "Epoch 773/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 4.1718 - val_loss: 76.9815\n",
            "Epoch 774/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.6192 - val_loss: 76.3623\n",
            "Epoch 775/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.7120 - val_loss: 77.9469\n",
            "Epoch 776/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.2236 - val_loss: 82.7921\n",
            "Epoch 777/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.8394 - val_loss: 82.1118\n",
            "Epoch 778/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6414 - val_loss: 78.8667\n",
            "Epoch 779/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.8485 - val_loss: 76.9379\n",
            "Epoch 780/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.9252 - val_loss: 76.9936\n",
            "Epoch 781/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 4.0759 - val_loss: 76.8843\n",
            "Epoch 782/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.2809 - val_loss: 77.1209\n",
            "Epoch 783/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6801 - val_loss: 78.0775\n",
            "Epoch 784/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.8088 - val_loss: 78.8564\n",
            "Epoch 785/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.1990 - val_loss: 77.8504\n",
            "Epoch 786/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9889 - val_loss: 77.0080\n",
            "Epoch 787/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.3060 - val_loss: 78.5923\n",
            "Epoch 788/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.6538 - val_loss: 82.9927\n",
            "Epoch 789/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.3356 - val_loss: 85.2369\n",
            "Epoch 790/1000\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.7387 - val_loss: 86.3119\n",
            "Epoch 791/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.5804 - val_loss: 82.6014\n",
            "Epoch 792/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4387 - val_loss: 77.2330\n",
            "Epoch 793/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0100 - val_loss: 75.5823\n",
            "Epoch 794/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.5862 - val_loss: 75.9836\n",
            "Epoch 795/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4294 - val_loss: 76.2787\n",
            "Epoch 796/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.4208 - val_loss: 76.5658\n",
            "Epoch 797/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.4309 - val_loss: 78.7465\n",
            "Epoch 798/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.8306 - val_loss: 80.3752\n",
            "Epoch 799/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.4761 - val_loss: 79.7650\n",
            "Epoch 800/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.8551 - val_loss: 78.7730\n",
            "Epoch 801/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.5909 - val_loss: 77.5247\n",
            "Epoch 802/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.8585 - val_loss: 76.5984\n",
            "Epoch 803/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6750 - val_loss: 77.5319\n",
            "Epoch 804/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.4376 - val_loss: 79.8031\n",
            "Epoch 805/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.2562 - val_loss: 77.6842\n",
            "Epoch 806/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9848 - val_loss: 75.4161\n",
            "Epoch 807/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.0780 - val_loss: 75.2132\n",
            "Epoch 808/1000\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 3.0073 - val_loss: 75.6970\n",
            "Epoch 809/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.2346 - val_loss: 74.7677\n",
            "Epoch 810/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.5586 - val_loss: 73.9190\n",
            "Epoch 811/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 3.0781 - val_loss: 74.1763\n",
            "Epoch 812/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2692 - val_loss: 75.0095\n",
            "Epoch 813/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.1863 - val_loss: 75.5712\n",
            "Epoch 814/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8185 - val_loss: 76.0441\n",
            "Epoch 815/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7946 - val_loss: 77.3168\n",
            "Epoch 816/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.2826 - val_loss: 77.9501\n",
            "Epoch 817/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.0115 - val_loss: 77.1657\n",
            "Epoch 818/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6544 - val_loss: 75.8136\n",
            "Epoch 819/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.8004 - val_loss: 75.5633\n",
            "Epoch 820/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.6989 - val_loss: 75.3721\n",
            "Epoch 821/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4797 - val_loss: 75.0414\n",
            "Epoch 822/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.1222 - val_loss: 74.8206\n",
            "Epoch 823/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3351 - val_loss: 75.8484\n",
            "Epoch 824/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7810 - val_loss: 78.8877\n",
            "Epoch 825/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.5630 - val_loss: 79.0456\n",
            "Epoch 826/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.0972 - val_loss: 77.1578\n",
            "Epoch 827/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.7976 - val_loss: 76.3294\n",
            "Epoch 828/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.4846 - val_loss: 76.0098\n",
            "Epoch 829/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.2969 - val_loss: 76.6504\n",
            "Epoch 830/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0581 - val_loss: 78.2268\n",
            "Epoch 831/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7148 - val_loss: 82.0397\n",
            "Epoch 832/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4286 - val_loss: 84.5366\n",
            "Epoch 833/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9640 - val_loss: 83.9677\n",
            "Epoch 834/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 6.1698 - val_loss: 80.7616\n",
            "Epoch 835/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.3188 - val_loss: 79.0218\n",
            "Epoch 836/1000\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 3.0131 - val_loss: 76.6164\n",
            "Epoch 837/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7551 - val_loss: 77.0859\n",
            "Epoch 838/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3951 - val_loss: 80.0547\n",
            "Epoch 839/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.7720 - val_loss: 83.4055\n",
            "Epoch 840/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.4770 - val_loss: 83.4606\n",
            "Epoch 841/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8946 - val_loss: 80.1443\n",
            "Epoch 842/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.6783 - val_loss: 76.6535\n",
            "Epoch 843/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.0095 - val_loss: 75.6895\n",
            "Epoch 844/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.6748 - val_loss: 75.6963\n",
            "Epoch 845/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9551 - val_loss: 76.0384\n",
            "Epoch 846/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1625 - val_loss: 78.4041\n",
            "Epoch 847/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6223 - val_loss: 81.3254\n",
            "Epoch 848/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.0456 - val_loss: 83.9834\n",
            "Epoch 849/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.4651 - val_loss: 85.5440\n",
            "Epoch 850/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9060 - val_loss: 90.0845\n",
            "Epoch 851/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5693 - val_loss: 88.5262\n",
            "Epoch 852/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7868 - val_loss: 82.0931\n",
            "Epoch 853/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4213 - val_loss: 78.8515\n",
            "Epoch 854/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.3453 - val_loss: 77.5379\n",
            "Epoch 855/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 5.1090 - val_loss: 76.3766\n",
            "Epoch 856/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.1638 - val_loss: 75.6178\n",
            "Epoch 857/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0329 - val_loss: 75.4021\n",
            "Epoch 858/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1455 - val_loss: 73.5540\n",
            "Epoch 859/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 4.5983 - val_loss: 72.8673\n",
            "Epoch 860/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0108 - val_loss: 72.5128\n",
            "Epoch 861/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.4926 - val_loss: 72.7578\n",
            "Epoch 862/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.7580 - val_loss: 74.5359\n",
            "Epoch 863/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.6649 - val_loss: 77.8390\n",
            "Epoch 864/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.5542 - val_loss: 83.3926\n",
            "Epoch 865/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.1020 - val_loss: 82.3878\n",
            "Epoch 866/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.5737 - val_loss: 75.3764\n",
            "Epoch 867/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.3584 - val_loss: 73.1434\n",
            "Epoch 868/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.5713 - val_loss: 73.3924\n",
            "Epoch 869/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.0037 - val_loss: 74.4366\n",
            "Epoch 870/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.8519 - val_loss: 75.0129\n",
            "Epoch 871/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.9651 - val_loss: 74.9536\n",
            "Epoch 872/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0458 - val_loss: 73.6474\n",
            "Epoch 873/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.9444 - val_loss: 72.2769\n",
            "Epoch 874/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.8305 - val_loss: 71.1405\n",
            "Epoch 875/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.2404 - val_loss: 73.2782\n",
            "Epoch 876/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9653 - val_loss: 77.9132\n",
            "Epoch 877/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9040 - val_loss: 82.8673\n",
            "Epoch 878/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.4618 - val_loss: 84.6598\n",
            "Epoch 879/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.0003 - val_loss: 80.0816\n",
            "Epoch 880/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.1356 - val_loss: 77.4777\n",
            "Epoch 881/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3071 - val_loss: 75.5596\n",
            "Epoch 882/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.2572 - val_loss: 76.1348\n",
            "Epoch 883/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.2097 - val_loss: 76.0188\n",
            "Epoch 884/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 2.9019 - val_loss: 75.6303\n",
            "Epoch 885/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.6643 - val_loss: 76.0305\n",
            "Epoch 886/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.0780 - val_loss: 76.4146\n",
            "Epoch 887/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.8686 - val_loss: 78.5810\n",
            "Epoch 888/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.0435 - val_loss: 80.6908\n",
            "Epoch 889/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8124 - val_loss: 81.9414\n",
            "Epoch 890/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.7251 - val_loss: 83.0043\n",
            "Epoch 891/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.3712 - val_loss: 85.8473\n",
            "Epoch 892/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.4569 - val_loss: 86.0793\n",
            "Epoch 893/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.3379 - val_loss: 84.0798\n",
            "Epoch 894/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1234 - val_loss: 81.7822\n",
            "Epoch 895/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.8038 - val_loss: 79.5444\n",
            "Epoch 896/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2247 - val_loss: 78.0862\n",
            "Epoch 897/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.7588 - val_loss: 78.7482\n",
            "Epoch 898/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.1660 - val_loss: 76.2787\n",
            "Epoch 899/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.5426 - val_loss: 74.4169\n",
            "Epoch 900/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 5.4895 - val_loss: 73.0957\n",
            "Epoch 901/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.8756 - val_loss: 72.9384\n",
            "Epoch 902/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.1405 - val_loss: 73.5532\n",
            "Epoch 903/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.2280 - val_loss: 73.4981\n",
            "Epoch 904/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.1522 - val_loss: 73.6191\n",
            "Epoch 905/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.3245 - val_loss: 76.7119\n",
            "Epoch 906/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.7995 - val_loss: 81.7344\n",
            "Epoch 907/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8791 - val_loss: 83.3547\n",
            "Epoch 908/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.5897 - val_loss: 82.2320\n",
            "Epoch 909/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.7435 - val_loss: 80.5997\n",
            "Epoch 910/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.7392 - val_loss: 80.6517\n",
            "Epoch 911/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.1005 - val_loss: 78.7700\n",
            "Epoch 912/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.6335 - val_loss: 78.2517\n",
            "Epoch 913/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.7567 - val_loss: 80.9738\n",
            "Epoch 914/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.0069 - val_loss: 83.0987\n",
            "Epoch 915/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.2862 - val_loss: 87.6599\n",
            "Epoch 916/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.7151 - val_loss: 90.8086\n",
            "Epoch 917/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.4123 - val_loss: 93.5306\n",
            "Epoch 918/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1075 - val_loss: 92.1815\n",
            "Epoch 919/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.5425 - val_loss: 88.3000\n",
            "Epoch 920/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.0874 - val_loss: 88.4046\n",
            "Epoch 921/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.7630 - val_loss: 88.2795\n",
            "Epoch 922/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 4.0915 - val_loss: 82.2364\n",
            "Epoch 923/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.1196 - val_loss: 79.0279\n",
            "Epoch 924/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.9714 - val_loss: 76.0382\n",
            "Epoch 925/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.6486 - val_loss: 74.9776\n",
            "Epoch 926/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.8416 - val_loss: 74.2851\n",
            "Epoch 927/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.2582 - val_loss: 74.6577\n",
            "Epoch 928/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.6557 - val_loss: 75.0792\n",
            "Epoch 929/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.8804 - val_loss: 77.1499\n",
            "Epoch 930/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.8716 - val_loss: 80.3023\n",
            "Epoch 931/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.6320 - val_loss: 77.9852\n",
            "Epoch 932/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.4332 - val_loss: 77.3490\n",
            "Epoch 933/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.8827 - val_loss: 76.4823\n",
            "Epoch 934/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.1269 - val_loss: 79.6745\n",
            "Epoch 935/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.6774 - val_loss: 82.5529\n",
            "Epoch 936/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.1138 - val_loss: 84.5026\n",
            "Epoch 937/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2345 - val_loss: 84.4123\n",
            "Epoch 938/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.7728 - val_loss: 86.9640\n",
            "Epoch 939/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.2107 - val_loss: 86.9738\n",
            "Epoch 940/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2015 - val_loss: 84.2393\n",
            "Epoch 941/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 2.8221 - val_loss: 81.3651\n",
            "Epoch 942/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.9574 - val_loss: 76.7689\n",
            "Epoch 943/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.3149 - val_loss: 74.5042\n",
            "Epoch 944/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.4814 - val_loss: 73.5830\n",
            "Epoch 945/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.0406 - val_loss: 72.9156\n",
            "Epoch 946/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.6895 - val_loss: 73.6396\n",
            "Epoch 947/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 4.3688 - val_loss: 74.9964\n",
            "Epoch 948/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.5801 - val_loss: 78.1785\n",
            "Epoch 949/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.4657 - val_loss: 78.3203\n",
            "Epoch 950/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 5.0398 - val_loss: 74.7815\n",
            "Epoch 951/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.2846 - val_loss: 71.5547\n",
            "Epoch 952/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.9488 - val_loss: 71.0288\n",
            "Epoch 953/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.8341 - val_loss: 71.1478\n",
            "Epoch 954/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.8491 - val_loss: 72.2274\n",
            "Epoch 955/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.4949 - val_loss: 74.1076\n",
            "Epoch 956/1000\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 3.2476 - val_loss: 76.5800\n",
            "Epoch 957/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.7996 - val_loss: 79.0984\n",
            "Epoch 958/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.7805 - val_loss: 79.7523\n",
            "Epoch 959/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.9780 - val_loss: 84.1881\n",
            "Epoch 960/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1845 - val_loss: 86.3986\n",
            "Epoch 961/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 4.0340 - val_loss: 84.0578\n",
            "Epoch 962/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 2.6923 - val_loss: 78.5481\n",
            "Epoch 963/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9356 - val_loss: 73.7509\n",
            "Epoch 964/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.2798 - val_loss: 72.6638\n",
            "Epoch 965/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.7760 - val_loss: 75.4941\n",
            "Epoch 966/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.1977 - val_loss: 76.9665\n",
            "Epoch 967/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.5158 - val_loss: 75.4492\n",
            "Epoch 968/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 2.9010 - val_loss: 72.8108\n",
            "Epoch 969/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.6874 - val_loss: 72.2285\n",
            "Epoch 970/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 3.2243 - val_loss: 72.6582\n",
            "Epoch 971/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.8468 - val_loss: 73.8844\n",
            "Epoch 972/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.2947 - val_loss: 75.1615\n",
            "Epoch 973/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 3.2594 - val_loss: 79.3707\n",
            "Epoch 974/1000\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 4.5032 - val_loss: 82.9190\n",
            "Epoch 975/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.8755 - val_loss: 78.8559\n",
            "Epoch 976/1000\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 4.1920 - val_loss: 74.1611\n",
            "Epoch 977/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 3.7797 - val_loss: 71.9965\n",
            "Epoch 978/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 2.9548 - val_loss: 71.1999\n",
            "Epoch 979/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.0909 - val_loss: 71.2092\n",
            "Epoch 980/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.6079 - val_loss: 71.5991\n",
            "Epoch 981/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 4.5314 - val_loss: 74.5587\n",
            "Epoch 982/1000\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.8982 - val_loss: 80.0147\n",
            "Epoch 983/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.6275 - val_loss: 84.7713\n",
            "Epoch 984/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 3.1454 - val_loss: 87.6188\n",
            "Epoch 985/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.6205 - val_loss: 83.8102\n",
            "Epoch 986/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.8737 - val_loss: 81.5975\n",
            "Epoch 987/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 3.3265 - val_loss: 79.9493\n",
            "Epoch 988/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 3.4896 - val_loss: 79.7849\n",
            "Epoch 989/1000\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 4.6858 - val_loss: 80.5230\n",
            "Epoch 990/1000\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 5.4036 - val_loss: 80.7113\n",
            "Epoch 991/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.1441 - val_loss: 79.1495\n",
            "Epoch 992/1000\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 2.9385 - val_loss: 77.4826\n",
            "Epoch 993/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 2.9107 - val_loss: 77.0347\n",
            "Epoch 994/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 2.9630 - val_loss: 77.7115\n",
            "Epoch 995/1000\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 3.6959 - val_loss: 80.6710\n",
            "Epoch 996/1000\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 4.5951 - val_loss: 81.8190\n",
            "Epoch 997/1000\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 3.2389 - val_loss: 83.5485\n",
            "Epoch 998/1000\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 3.0693 - val_loss: 88.0572\n",
            "Epoch 999/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 2.9020 - val_loss: 92.6000\n",
            "Epoch 1000/1000\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 3.1139 - val_loss: 94.1455\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1efd1b3950>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}
